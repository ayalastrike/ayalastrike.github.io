[{"id":0,"href":"/about/","title":"About","section":"Rick's Blog","content":"Email: tianjiawei@gmail.com\n"},{"id":1,"href":"/docs/MySQL/InnoDB/1_overview/","title":"1 Overview","section":"Inno Db","content":"Heikki Tuuri是InnoDB存储引擎的创始人，1964年生于芬兰赫尔辛基。与著名Linux操作系统的创始人Linus一样毕业于芬兰赫尔辛基大学。从入学时间来看，Heikki Tuuri还是Linus的学长。在1990年取得赫尔辛基大学的数理逻辑博士学位后。\n所以，innodb的代码大部分都是Created mm/dd/YYYY Heikki Tuuri。\nMySQL大事时间表：\n 1995：Heikki Tuuri成立Innobase Oy公司并担任CEO。同年，由David Axmark、Allan Larsson和Michael Monty Widenius在瑞典创办MySQL AB公司。 2001：Innobase公司开始与MySQL AB公司进行合作并开源InnoDB存储引擎的代码。 2005：Oracle公司收购了Innobase公司。 2008：Sun收购MySQL AB公司。 2009：2009年4月20日，Sun 公司董事会通过决议，同意以每股9.5美元的价格将公司出售给Oracle。  "},{"id":2,"href":"/docs/MySQL/InnoDB/2_source/","title":"2 Source","section":"Inno Db","content":"typora-root-url: ../../../../static\n在MySQL源代码中，每个模块都有自己单独的目录存放，里面按照模块名0子模块名.cc来组织。所有头文件都放在include目录下，同时include目录下还有*.ic的文件，这个文件中存放定义的内联函数。\n如果要在*.ic中使用宏UNIV_INLINE定义内联，需要#include \u0026ldquo;univ.i\u0026rdquo;，即\n#include \u0026#34;univ.i\u0026#34;UNIV_INLINE return_value function foo(param1, ...) ``// 函数声明或实现 { ``... } 注意，这种风格只是适用于c函数，对于ic文件中的类成员函数定义，还是需要手动写inline  univ.i中UNIV_INLINE的宏定义\n#ifndef UNIV_MUST_NOT_INLINE /* Definition for inline version */ #define UNIV_INLINE static inline #else /* !UNIV_MUST_NOT_INLINE *//* If we want to compile a noninlined version we use the following macro definitions: */ #define UNIV_NONINL #define UNIV_INLINE #endif /* !UNIV_MUST_NOT_INLINE */阅读源码层次\n推荐从下至上进行逐层阅读\n最下一层是基础管理模块：\n File Manager主要封装了InnoDB对于文件的各类操作，如读、写、异步I/O等。 Concurrency Manager模块主要封装了引擎内部使用的各类mutex和latch。 Common Utility模块用于一些基本数据结构与算法的定义，如链表、哈希表等。  图中间虚线标注的部分为InnoDB的内核实现，也就是InnoDB存储引擎中的事务、锁、缓冲区、日志、存储管理、资源管理、索引、change buffer模块，这部分是整个存储引擎的核心。\n图最上面的两层是接口层，通过这些接口实现server层与存储引擎的交互。InnoDB存储引擎可以不依赖MySQL数据库，而作为一个嵌入式数据库存在，因此还存在嵌入式的API接口。\n详细的目录（模块）说明如下：\n   目录 说明 文件      ut 基本数据结构和算法 ut0byteut0crc32ut0dbgut0listut0lstut0memut0newut0rbtut0rndut0vecut0wqueue 内存双向链表 ib_list内存双向链表 ut_list   mem 内存管理 mem0mem 内存管理   os 进程控制 univos0atomicos0eventos0fileos0procos0thread 定义了POD、编译器hint、代码段宏Atomic Read-Modify-WriteOS Event getpid、大页分配内存PSI key、进程控制原语   sync 同步机制 ut0mutexsync0arrsync0debugsync0rwsync0syncsync0policy 定义了mutex的宏、mutex_init()和mutex_destroy()、MutexMonitor MutexDebug   log 日志及恢复 log0loglog0recv 重做日志恢复   mtr mini-transaction mtr0typemtr0mtrmtr0logdyn0buf mtr相关定义mtr基本操作mtr日志操作mtr_buf_t   fsp 存储管理 fsp0filefsp0fspfsp0spacefsp0sysspace 数据文件物理文件结构与实现表空间系统表空间   fil 文件管理 fil0filos0file 文件内存数据结构及相关文件操作底层文件操作实现   fut  fut0lstfut0fut 磁盘双向链表 flst   data 逻辑记录 data0datadata0typedata0types 逻辑记录逻辑记录的操作逻辑记录数据结构   rem 物理记录 rem0recrem0cmprem0types 物理记录物理记录的比较物理记录数据结构   page 索引页 page0curpage0pagepage0typespage0sizepage0zip 索引页中记录的定位、插入、删除索引页的维护类型定义   lock 锁 lock0locklock0iterlock0prdtlock0waitlock0typeslock0priv 锁模式   btr B+树 btr0btrbtr0bulkbtr0curbtr0pcurbtr0sea    buf 缓冲池 buf0buddybuf0bufbuf0checksumbuf0dblwrbuf0dumpbuf0flubuf0lrubuf0rea    dict 数据字典 dict0bootdict0creadict0dictdict0loaddict0memdict0statsdict0stats_bg    ibuf change buffer ibuf0ibuf    row  row0extrow0ftsortrow0importrow0insrow0logrow0mergerow0mysqlrow0purgerow0quiescerow0rowrow0selrow0truncrow0uninsrow0umodrow0undorow0updrow0vars    trx 事务 trx0i_strx0purgetrx0rectrx0rolltrx0rsegtrx0systrx0trxtrx0undo    handler  ha_innodbha_innoparthandler0alteri_s    read  read0read    api  api0apiapi0misc    eval  eval0evaleval0misc    ha  ha0haha0storagehash0hash    mach  mach0data    pars  lexyypars0grmpars0lexpars0optpars0parspars0sym    que  que0que    srv  srv0concsrv0monsrv0srvsrv0start    usr  usr0sess    gis  gis0geogis0rtreegis0sea    fts  fts0astfts0blexfts0configfts0ftsfts0optfts0parsfts0pluginfts0quefts0sqlfts0tlex        目录 文件 说明     fut fut0fut File-based utilities   fu0lst File-based list utilities    ha ha0ha The hash table with external chains   ha0storage Hash storage    hash0hash The simple hash table utility    mem mem0mem The memory management   ut ut0byte Byte utilities        ut0crc32 CRC32    ut0dbg Debug utilities for Innobase.    ut0list A double-linked list    ut0mem Memory primitives    ut0new Instrumented memory allocator.    ut0rbt Red-Black tree implementation    ut0rnd Random numbers and hashing    ut0ut Various utilities for Innobase.    ut0vec A vector of pointers to data items    ut0wqueue work queue.          db0err Error Codes\neval\nFile Name What Name Stands For Size Comment Inside File --------- -------------------- ------ ------------------- eval0eval.c Evaluating/Evaluating 17,061 SQL evaluator eval0proc.c Evaluating/Procedures 5,001 Executes SQL procedures The evaluating step is a late part of the process of interpreting an SQL statement \u0026mdash; parsing has already occurred during \\pars (PARSING).\nThe ability to execute SQL stored procedures is an InnoDB feature, but MySQL handles stored procedures in its own way, so the eval0proc.c program is unimportant.\n代码风格 #  InnoDB的代码缩进风格更接近于K\u0026amp;R风格：所有的非函数语句块（if、switch、for、while、do），起始大括号放在行尾，而把结束大括号放在行首。函数开头的左花括号放到最左边。\n此外，每个文件都包含一段简短说明其功能的注释开头，同时每个函数也注释说明函数的功能，需要哪些种类的参数，参数可能值的含义以及用途。最后，对于变量的声明，使用下画线以分隔单词，坚持使用小写，并把大写字母留给宏和枚举常量。\n"},{"id":3,"href":"/docs/MySQL/InnoDB/5_record/","title":"5 Record","section":"Inno Db","content":"设计 #  MySQL主要面向的是OLTP场景，所以数据记录采用行存（NSM - n-ary storage model）。\n基于行进行存储有以下几个好处：\n 记录存放在一个页中，存储一条记录需要访问的页面较少 符合传统机械硬盘的访问方式 易于理解，数据的存取就像是对一张二维表进行访问  在整体上看，表中的数据是按照如下形式组织的：\n那我们如何来理解记录呢？\n首先，在关系数据库系统理论中，通常用元组（tuple）描述记录，用字段（field）描述列，每个元组由多个字段组成，每个表由多个元组组成。\n行和元组在意义上是相等的。但是更愿意将行（row）理解为物理记录，将元组（tuple）理解为逻辑记录。物理记录为行实际存放在物理存储中的格式，其内容由二进制字符串组成，可读性差。逻辑记录则容易理解的多，每张表中的多个记录就像是一个数组。由于其只是“逻辑”上的含义，因此逻辑记录只是物理记录在内存中的表现形式，实际并不占用任何的物理存储空间。\n关系如下图所示：\n物理记录和逻辑记录的差异如下：\n    物理记录 逻辑记录     可读性 差 好   存储位置 磁盘 内存   亲和性 对存储友好（更紧凑） 对查找友好（更易寻址）   存储内容 除记录中的列数据外，还有一些额外信息 元组    这两种记录之间本身可以互相转换。比如，在插入一条记录时，原来没有数据，首先需要根据插入的记录构造一个逻辑记录，然后再存放到磁盘上。对于读取，要从磁盘上seek出来相应的数据页，再将页中的物理记录转换成逻辑记录展现给用户。\n除此之外，在MySQL server层也需要在binlog中记录数据的变化，也需要一种行格式。因此，在MySQL中，行格式一共有3种存储方式：\n Server层格式：与存储引擎无关，server层的binlog行格式（Row-Base Replication下的binlog格式） 逻辑记录格式：tuple，也称为索引元组格式（因为InnoDB是IOT）。在同一个表中，不同索引对应的元组是不同的 物理记录格式：record，也称为physical record  物理记录的设计 #  物理记录承载着数据的最终存储，因此，我们首先讨论物理记录。\n磁盘上的物理记录需要面向计算机友好，更紧凑、强调IO性能，以及在此基础上支持事务语义。\n目标：\n 描述行存的数据 适配存储引擎的结构 查找快 DML快 事务语义 更少的资源占用（disk、buffer pool、update I/O）  逻辑记录的设计 #  磁盘上的物理记录面向的是计算机友好的，更紧凑、高IO性能。同时，为了性能的考虑，数据也需要常驻内存（buffer pool），所以需要设计数据结构用于表述记录，这被称为tuple（元组），也称为逻辑记录。\n实现 #  InnoDB存储引擎中的表使用的是索引组织表（Index Organized Table - IOT），这意味着表中的所有数据是按照B+树的方式进行存储的，行数据存在在B+树的叶子节点上，即使创建表时没有显式指定主键索引，也会自动创建一个6字节的隐藏列，用作主键索引。\n2.1 Redundant行格式 #  从上面我们可以得知，物理记录由3部分组成：\n2.1.1 sdfs #  sdfs\n"},{"id":4,"href":"/docs/MySQL/InnoDB/6_page/","title":"6 Page","section":"Inno Db","content":"索引页 #  InnoDB存储引擎是索引组织表，因此聚簇索引页的叶子节点中存放完整的数据记录，辅助索引页的叶子节点中存放指向聚簇索引页叶子节点的书签（bookmark），也可以称为路标。\n主要是两部分：\n page layout scan rec with cursor, and then insert, update, delete  1. 页 #  页是InnoDB存储引擎的最小存储单位。页的大小可以设置为4K、8K、16K、32K、64K，默认为16K，页的大小设置要考虑IO性能，也会影响到区的分配大小和重做日志缓冲的大小，详见innodb_page_size。\n"},{"id":5,"href":"/docs/MySQL/InnoDB/","title":"Inno Db","section":"MySQL","content":"InnoDB存储引擎 #  从InnoDB的发展历史作为起点，了解InnoDB一路走来的历程。\n然后在全局视角下先了解整体的模块构成及其功能。\n再按照以下的路径深入细节：\n 概览 源码结构 基本数据结构与算法 os records 索引页 storage management 同步机制 缓冲池 数据字典 B+树索引 change buffer lock 事务处理 mini-transaction redo log 服务管理 row  一路下来，应该已经对各个模块的功能和细节了然于心，然后再回头再重温一下整体架构，做到融会贯通。\n"},{"id":6,"href":"/docs/MySQL/Server/8.0_net_optimize/","title":"8.0 Net Optimize","section":"Server","content":"Administrative Connection Management #  如果MySQL连接连接被打满，有时甚至连root也无法登录去kill。\n对于这个问题，目前已有的解法有：\n 各家的线程池提供了extra_port。 Alibaba RDS MySQL的做法是把connection的个数拆分成不同的使用目的，例如系统维护账户占用一部分，用户账户占用一部分，两者不互相影响。  MySQL 8.0提供了administrative-connection-interface的机制（由facebook贡献），即提供单独的network interface并且可以单独配置一个pthread用于listen。\n参数如下：\n admin_address admin_port create_admin_listener_thread：是否创建一个单独的listener线程来监听admin的链接请求（默认OFF，建议打开）  worklog：WL#12138: Add Admin Port\n代码\nMultiple addresses for the –bind-address #  bind-address支持绑定多个网络地址。比如：\n// The server listens on the 198.51.100.20 IPv4 address and the 2001:db8:0:f101::1 IPv6 address. bind_address=198.51.100.20,2001:db8:0:f101::1 worklog：WL#11652: Support multiple addresses for the \u0026ndash;bind-address command option\n代码\nconnect/disconnect performance #  目前MySQL里是使用一个全局大锁（LOCK_thd_list、LOCK_thd_remove）来保护thd_list。\n优化的思路其实很简单直接：分区，将LOCK_thd_list、LOCK_thd_remove根据thread id来分成8个分区（hardcode）来减少冲突，负面影响就是PS的监控数据需要聚合。\nworklog：WL#9250: Split LOCK_thd_list and LOCK_thd_remove mutexes\n代码\ntransfer metadata optional #  MySQL的结果集格式如下，点查下metadata在结果集包中的占比很大。\nRESULTSET contains a bunch of packets: - metadata; - EOF_PACKET if not CLIENT_DEPRECATE_EOF flag set; - data rows; - OK_PACKET (or EOF_PACKET if not CLIENT_DEPRECATE_EOF flag set) or ERR_PACKET MySQL 8.0提供了resultset_metadata，可以有选择的不传输metadata，以提升TPS和吞吐。\nC client driver代码示例\n阿里的同学之前做过相应的对比测试：\nAfter porting twitter's patch ( Great thanks to Davi Arnaut) to MySQL5.6.16, I slightly changed it to make protocol_mode support more options: 0/METADATA_FULL: return all metadata, default value. 1/METADATA_REAL_COLUMN: only column name; 2/METADATA_FAKE_COLUMN: fake column name ,use 1,2...N instead of real column name 3/METADATA_NULL_COLUMN: use NULL to express the metadata information 4/METADATA_IGNORE: ignore metadata information, just for test.. CREATE TABLE `test_meta_impact` ( `abcdefg1` int(11) NOT NULL AUTO_INCREMENT, `abcdefg2` int(11) DEFAULT NULL, `abcdefg3` int(11) DEFAULT NULL, `abcdefg4` int(11) DEFAULT NULL, ...... ...... `abcdefg40` int(11) DEFAULT NULL, PRIMARY KEY (`abcdefg1`) ) ENGINE=InnoDB AUTO_INCREMENT=229361 DEFAULT CHARSET=utf8 mysqlslap --no-defaults -uxx --create-schema=test -h$host -P $port --number-of-queries=1000000000 --concurrency=100 --query='SELECT * FROM test.test_meta_impact where abcdefg1 = 2' METADATA_FULL : 3.48w TPS, Net send 113M METADATA_REAL_COLUMN: 7.2W TPS, Net send 111M METADATA_FAKE_COLUMN: 9.2W TPS , Net send 116M METADATA_NULL_COLUMN: 9.6w TPS , Net send 115M METADATA_IGNORE: 13.8w TPS, Net send 30M worklog：WL#8134: Make metadata information transfer optional\n代码\nMySQL protocol support async #  目前的MySQL C client APIs是synchronous，即在MySQL server处理请求返回完成前，只能等待。MySQL 8.0增加了protocol的异步支持，增加以下异步函数（原有api+_nonblocking）：\n mysql_real_connect_nonblocking mysql_send_query_nonblocking mysql_real_query_nonblocking mysql_store_result_nonblocking mysql_next_result_nonblocking mysql_fetch_row_nonblocking mysql_free_result_nonblocking  worklog：WL#11381: Add asynchronous support into the mysql protocol\n代码\nC client driver代码示例\n"},{"id":7,"href":"/docs/MySQL/Server/8.0_resource_group/","title":"8.0 Resource Group","section":"Server","content":"ＭySQL8.0增加了一个新功能resource group，可以对不同的用户进行资源控制，例如对用户线程和后台系统线程给予不同的CPU优先级。\n用户可以通过SQL接口创建不同的分组，这些分组可以作为sql的hit，也可以动态的绑定过去。本文主要简单介绍下用法，至于底层如何实现的，其实比较简单：创建的分组被存储到系统表中；在linux系统底层通过CPU_SET来绑定CPU，通过setpriority来设置线程的nice值\nworklog: WL#9467: Resource Groups\n创建resource group #  系统自带两个resource group（不可修改）：\n FOREGROUND (FG) - \u0026ldquo;user\u0026rdquo; threads BACKGROUND (BG) - \u0026ldquo;system\u0026rdquo; threads (internal Engine threads, e.g. \u0026ldquo;purge\u0026quot;in InnoDB, etc.)  mysql\u0026gt; SELECT * FROM INFORMATION_SCHEMA.RESOURCE_GROUPS\\G *************************** 1. row *************************** RESOURCE_GROUP_NAME: USR_default RESOURCE_GROUP_TYPE: USER RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 *************************** 2. row *************************** RESOURCE_GROUP_NAME: SYS_default RESOURCE_GROUP_TYPE: SYSTEM RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 2 rows in set (0.00 sec) 只有超级账户启动mysqld才能设置thread priority，否则只能降低而不能提升优先级。（-20最高，20最低）\n对于system threads，cpu priority只能从-20 ~ 0，user threads在0 ~ 19之间，这样就保证了系统线程的优先级肯定比用户线程高。\n使用resource group #  有两种方式来使用resource group，一种是SET RESOURCE GROUP，一种是通过SQL HINT的方式。\n设置当前session：\nmysql\u0026gt; SET RESOURCE GROUP test_user_rg; Query OK, 0 rows affected (0.00 sec) 也可以指定hint的方式来设置：\nmysql\u0026gt; select /* + RESOURCE_GROUP(test_user_rg) */ * from sbtest1 where id \u0026lt;10; 还可以通过thread id来设置其他运行中的session，注意这里的thread id不是THD id，而是通过pthread id（performance_schema.threads表）。\nmysql\u0026gt; SELECT THREAD_ID, TYPE FROM performance_schema.threads WHERE PROCESSLIST_ID = 26\\G *************************** 1. row *************************** THREAD_ID: 71 TYPE: FOREGROUND 1 row in set (0.00 sec) mysql\u0026gt; SET RESOURCE GROUP test_user_rg for 71; Query OK, 0 rows affected (0.00 sec) 可以看到，通过resource group，我们可以为任何线程指定不同的计算资源。\n"},{"id":8,"href":"/docs/MySQL/Server/connection_handler/","title":"Connection Handler","section":"Server","content":"概述 #  在MySQL中，对于client发来的请求，其处理流程分为建链和请求处理两部分，这两个阶段分别称为connection phase和command phase。\nMySQL的server-client protocol交互如下：\n从上图中可以看出，connection phase负责连接的建立，而日常的query处理，则称为command phase，command phase的结束，以COM_QUIT query的到来作为标志。\n一般典型的交互过程是connect，query，query，query\u0026hellip; quit，其中query可以是dml、ddl、multi-statement或是prepared statement。\n下面我们先看一下connection phase。\n建链 #  connection phase用于在client-server间建立连接，而建链分为TCP建链和应用建链。\nTCP建链是指TCP socket的listen、accept。\n应用建链是在TCP建链的基础上，通过应用层协议进行认证：server发送handshake（initial handshake）、客户端回username/pwd（handshake response），server回应是否通过认证（OK/Error）。\n我们接下来首先看一下connection phase，即在MySQL中如何处理TCP建链和应用建链的。\nTCP建链 #  TCP连接处理分为两步：\n 初始化，创建conn_mgr和conn_handler，acceptor和listener 监听建链，由acceptor+listener负责 对已建链连接进行线程分发处理，由conn_mgr+conn_handler负责  整体流程如下图所示：\n代码实现\nmysqld_main init_common_variables Connection_handler_manager::init() // 初始化conn_mgr和conn_handler  network_init()\t// 初始化网络 \tset_ports();\t// 设置port  // 初始化acceptor、listener \tMysqld_socket_listener *mysqld_socket_listener= new (std::nothrow) Mysqld_socket_listener(bind_addr_str, mysqld_port, back_log, mysqld_port_timeout, unix_sock_name); Connection_acceptor\u0026lt;Mysqld_socket_listener\u0026gt; *mysqld_socket_acceptor= new (std::nothrow) Connection_acceptor\u0026lt;Mysqld_socket_listener\u0026gt;(mysqld_socket_listener); mysqld_socket_acceptor-\u0026gt;init_connection_acceptor(); ... mysqld_socket_acceptor-\u0026gt;connection_event_loop();\t// 监听、接受、处理连接 监听建链 #  MySQL的连接方式支持多种方式，常见的有：socket、TCP/IP、named_pipe和shared_memory。因为我们一般都在Unix-like系统上编程，所以这里只展开讨论socket，其余连接方式的处理类似。\n连接处理分为分为监听（listen）和接受（accept）两部分：\n listener：Mysqld_socket_listener acceptor：Connection_acceptor  我们先看一下listener\nlistener #  Mysqld_socket_listener用于处理监听（listen）和建链（accept），包括：\n 监听信息 ：ip、port、backlog、socket、socket_map 处理 ：POLL（tcp socket、unix sock file） 状态信息 ：错误（select、accept、tcpwrap产生的状态）  Mysqld_socket_listener\n   方法 说明     ctor/dtor /   setup_listener 建链准备（初始化listen socket，POLL、socket_map）   listen_for_connection_event 建链处理（处理poll/select，accept，创建channel_info）   close_listener 关闭连接（socket_shutdown、socket_close、unlink_socket_file）    acceptor #  Connection_acceptor是一个模板类，根据type展开不同的listener（Mysqld_socket_listener、Named_pipe_listener、Shared_mem_listener），负责将listener TCP监听、建链的连接（channel_info）交给conn_mgr处理。\n核心函数如下：\n/** Connection acceptor loop to accept connections from clients. */ void connection_event_loop() { Connection_handler_manager *mgr= Connection_handler_manager::get_instance(); while (!abort_loop) { Channel_info *channel_info= m_listener-\u0026gt;listen_for_connection_event(); if (channel_info != NULL) mgr-\u0026gt;process_new_connection(channel_info); } } Connection_acceptor\n   方法 说明     ctor/dtor 传入listener   init_connection_acceptor 调用listener-\u0026gt;setup_listener()   connection_event_loop 调用listener监听建链，然后交给conn_mgr处理连接   close_listener 调用listener-\u0026gt;close_listener    LibWrap #  TCP Wrappers作为服务程序安全增强工具，提供 IP 层存取过滤控制，扩展了 inetd (xinetd ) 对服务程序的控制能力，其作用相当于给 xinetd 增加了一道防火墙。最常用的场景如下：通过配置/etc/hosts.allow和/etc/hosts.deny ，以允许或阻止指定客户端对指定服务的访问。\n处理连接 #  经过上面的处理后，用户的建链请求已经经过listen+accept，下面交给conn_mgr+conn_handler。\n在MySQL中，为了支持多种的连接处理方式（单线程only-once、多线程1:1、线程池m:n），通过Connection_handler基类来定义连接处理所需要的函数，具体的处理方式则由子类实现。\nconn_mgr和conn_handler的关系：\nconnection manager #  conn_mgr采用单例模式，进行全局的连接资源管理，这些资源包括：\n conn_handler的创建 将lisenter创建的连接（channel_info）转交给conn_handler 连接相关计数：当前、历史、中止、错误 提供callback接口用于在相关连接线程等待时进行回调  Connection_handler_manager\n   方法 说明     ctor/dtor 由init调用   init 根据thread_handler的配置，实例化conn_handler,调用conn_mgr ctor实例化conn_mgr，注册callbacks   destroy_instance 销毁conn_handler和conn_mgr   get_instance 返回conn_mgr instance   process_new_connection 移交连接   wait_till_no_connection 关闭MySQL时等待连接清零   load_connection_handlerunload_connection_handler 为企业版线程池（plugin）准备的钩子    这里的核心函数为process_new_connection。需要注意一点：channel_info连接信息的所有权转移，由listener转移给conn_handler。\nvoid Connection_handler_manager::process_new_connection(Channel_info* channel_info) { // 连接控制  if (abort_loop || !check_and_incr_conn_count()) { channel_info-\u0026gt;send_error_and_close_channel(ER_CON_COUNT_ERROR, 0, true); delete channel_info; return; } // 转交连接  if (m_connection_handler-\u0026gt;add_connection(channel_info)) { inc_aborted_connects(); delete channel_info; } } conn_mgr的生命周期：初始化和销毁的时机分别为MySQL启动和停止，代码如下：\n// 初始化 mysqld_main init_embedded_erver init_common_variables get_options Connection_handler_manager::init() // 停止 lib_sql.cc end_embedded_server unireg_clear cleanup Connection_handler_manager::destroy_instance(); mysqld.cc mysqld.cc mysqld_main unireg_abort clean_up Connection_handler_manager::destroy_instance(); connection handler #  Connection_handler\n   方法 说明     ctor/dtor /   add_connection 处理连接   get_max_threads 获取conn_handler可以创建的最大线程数    从上面的conn_handler类图可以看到，Connection_handler一共有三个子类，这里主要看Per_thread_connection_handler。\nPer_thread_connection_handler的功能是新起一个线程（handle_connection）1:1处理连接，即进行应用协议的处理。\n请求处理 #  请求分发 #  MySQL请求处理的详细过程如下：\n// 监听socket事件  mysqld_socket_acceptor-\u0026gt;connection_event_loop() { Connection_handler_manager *mgr= Connection_handler_manager::get_instance(); while (!abort_loop) { Channel_info *channel_info= m_listener-\u0026gt;listen_for_connection_event(); if (channel_info != NULL) mgr-\u0026gt;process_new_connection(channel_info); } } Channel_info* Mysqld_socket_listener::listen_for_connection_event() { int retval= poll(\u0026amp;m_poll_info.m_fds[0], m_socket_map.size(), -1); // POLL  int retval= select((int) m_select_info.m_max_used_connection, \u0026amp;m_select_info.m_read_fds, 0, 0, 0); // 或者SELECT  for (uint i= 0; i \u0026lt; m_socket_map.size(); ++i) { if (m_poll_info.m_fds[i].revents \u0026amp; POLLIN) { listen_sock= m_poll_info.m_pfs_fds[i]; is_unix_socket= m_socket_map[listen_sock]; break; } } MYSQL_SOCKET connect_sock; connect_socket= mysql_socket_accept(key_socket_client_connection, listen_sock, (struct sockaddr *)(\u0026amp;cAddr), \u0026amp;length); Channel_info* channel_info= new (std::nothrow) Channel_info_tcpip_socket(connect_sock); return channel_info; } void Connection_handler_manager::process_new_connection(Channel_info* channel_info) { check_and_incr_conn_count(); // 检查max_connections  m_connection_handler-\u0026gt;add_connection(channel_info); } // One_thread_connection_handler 一个线程处理所有连接  // Per_thread_connection_handler 一个线程处理一个连接  bool Per_thread_connection_handler::add_connection(Channel_info* channel_info) { // 检查thread cache是否有空闲  check_idle_thread_and_enqueue_connection(channel_info); // 没有空闲，创建用户线程  mysql_thread_create(key_thread_one_connection, \u0026amp;id, \u0026amp;connection_attrib, handle_connection, (void*) channel_info); } extern \u0026#34;C\u0026#34; void *handle_connection(void *arg) { my_thread_init(); // 线程初始化  for (;;) { THD *thd= init_new_thd(channel_info); // 初始化THD对象  thd_manager-\u0026gt;add_thd(thd); if (thd_prepare_connection(thd)) { // connection phase  lex_start(thd); // 初始化sqlparser  rc= login_connection(thd); check_connection(thd); acl_authenticate(thd, COM_CONNECT); // auth认证  thd-\u0026gt;send_statement_status(); prepare_new_connection_state(thd); // 准备接受QUERY  } else {\t// command phase  while (thd_connection_alive(thd)) // 判活  { if (do_command(thd)) // 处理query sql/sql_parser.c  break; } end_connection(thd); } close_connection(thd, 0, false, false); thd-\u0026gt;release_resources(); // 进入thread cache，等待新连接复用  channel_info= Per_thread_connection_handler::block_until_new_connection(); } my_thread_end(); my_thread_exit(0); } command phase #  具体SQL处理流程：\nbool do_command(THD *thd) { // 新建连接，或者连接没有请求时，会block在这里等待网络读包  NET *net= thd-\u0026gt;get_protocol_classic()-\u0026gt;get_net(); my_net_set_read_timeout(net, thd-\u0026gt;variables.net_wait_timeout); net_new_transaction(net); rc= thd-\u0026gt;get_protocol()-\u0026gt;get_command(\u0026amp;com_data, \u0026amp;command); dispatch_command(thd, \u0026amp;com_data, command); } int Protocol_classic::get_command(COM_DATA *com_data, enum_server_command *cmd) { read_packet(); // 网络读包  my_net_read(\u0026amp;m_thd-\u0026gt;net); raw_packet= m_thd-\u0026gt;net.read_pos; *cmd= (enum enum_server_command) raw_packet[0]; // 获取命令号  parse_packet(com_data, *cmd); } bool dispatch_command(THD *thd, const COM_DATA *com_data, enum enum_server_command command) { switch (command) { case COM_QUERY: alloc_query(thd, com_data-\u0026gt;com_query.query, com_data-\u0026gt;com_query.length); // 从网络读Query并存入thd-\u0026gt;query  mysql_parse(thd, \u0026amp;parser_state); // 解析  } } // sql/sql_parse.cc void mysql_parse(THD *thd, Parser_state *parser_state) { mysql_reset_thd_for_next_command(thd); lex_start(thd); parse_sql(thd, parser_state, NULL); // 解析SQL语句  mysql_execute_command(thd, true); // 执行SQL语句  LEX *const lex= thd-\u0026gt;lex; TABLE_LIST *all_tables= lex-\u0026gt;query_tables; trans_commit_implicit(thd); // 隐式提交 sql/transaction.cc  switch (lex-\u0026gt;sql_command) { case SQLCOM_INSERT: { res= lex-\u0026gt;m_sql_cmd-\u0026gt;execute(thd); break; } case SQLCOM_DELETE: { res= lex-\u0026gt;m_sql_cmd-\u0026gt;execute(thd); break; } case SQLCOM_UPDATE: { res= lex-\u0026gt;m_sql_cmd-\u0026gt;execute(thd); break; } case SQLCOM_SELECT: { res= select_precheck(thd, lex, all_tables, first_table); // 检查privileges  res= execute_sqlcom_select(thd, all_tables); } case SQLCOM_COMMIT: // 显式提交  { trans_commit(thd); ha_commit_trans(thd, TRUE); Transaction_ctx *trn_ctx= thd-\u0026gt;get_transaction(); tc_log-\u0026gt;commit(thd, all)); // MYSQL_BIN_LOG::commit sql/binlog.cc  ordered_commit(thd, all, skip_commit); } ... } } 网络模型 #  MySQL对于网络处理模型做了非常好的抽象分层。\n网络处理模型 #  MySQL对于网络通信的封装层次如下：\n| Channel_info\t连接 | THD\t线程 | Protocol\t应用协议 | NET\t网络缓冲 | VIO\t网络I/O | SOCKET\tsocket fd Channel_info封装了连接信息。\nTHD封装了线程相关的数据结构。\nProtocol封装了应用协议，一共有5种，其中2种最常用，统称为classic protocol：\n PROTOCOL_TEXT：用于plain SQL PROTOCOL_BINARY：用于prepared statement，也称为prepared statement protocol。  NET封装了网络缓冲区，包括buffer、packet、read/write点位。\nVIO封装了网络I/O，包括sockaddr等待。\nSOCKET封装了socket fd，里面只有fd信息。\n这些对象的创建时机如下：\n创建对象的函数调用链如下：\nmysqld_socket_acceptor-\u0026gt;connection_event_loop() Mysqld_socket_listener::listen_for_connection_event() mysql_socket_accept new Channel_info_tcpip_socket // accept \u0026amp; 封装 Channel_Info  Connection_handler_manager::process_new_connection() Per_thread_connection_handler::add_connection // 交给具体的conn_handler处理连接  create pthread(handle_connection) for loop init_new_thd // 初始化VIO, THD, Protocol和VIO  channel_info-\u0026gt;create_thd() delete channel_info thd_manager-\u0026gt;add_thd // 加thd  thd_prepare_connection // connection phase  login_connection while thd_connection_alive // command phase  do_command dispatch_command create_thd() create_and_init_vio mysql_socket_vio_new // malloc，初始化VIO  VIO malloc vio_init THD malloc // malloc，初始化THD，Protocol  thd-\u0026gt;get_protocol_classic()-\u0026gt;init_net // 初始化NET  my_net_init my_net_local_init // 设置net_read_timeout, net_write_timeout 从上面我们可以看出，TCP建链后主线程只封装了Channel_nfo用于存放连接的信息，后续的THD、NET、VIO等信息的创建和初始化都（connections and disconnects）是在用户线程完成的。通过这种方式，主线程可以更高效的accept新的连接请求，从而优化在短连接场景下的性能。\n参见Improving connect/disconnect performance和WL#6606: Offload THD initialization and network initialization to worker thread。\n短连接的性能优化效果如下：\n我们先看一下Channel_info。\nChannel_info 连接 #  Channel_info对象封装了连接信息，以区分处理不同的连接方式：local、TCP/IP、named pipes和shared memory，并负责整个网络模型层次中各个对象的初始化。类和类关系图如下：\nChannel_info_local_socket\nChannel_info_shared_mem\nChannel_info_named_pipe\nChannel_info_tcpip_socket\n属性\n   属性 说明     prior_thr_create_utime 连接的创建时间    方法\n   方法 说明     ctor/dtor /   create_thd 创建THD   create_and_init_vio 创建并初始化VIO（只针对local、TCP/IP）   send_error_and_close_channel 发送错误包并关闭socket   prior_thr_create_utime getter/setter Per_thread_connection_handler::add_connection时设置    THD 线程 #  THD\nProtocol 应用协议 #  Protocol\nNET 网络缓冲 #  NET\nVIO 网络 #  VIO\nSOCKET socket fd #  SOCKET最简单，直接代码说话。\n/** An instrumented socket. */ struct st_mysql_socket { /** The real socket descriptor. */ my_socket fd; /** The instrumentation hook. Note that this hook is not conditionally defined, for binary compatibility of the @c MYSQL_SOCKET interface. */ struct PSI_socket *m_psi; }; /** An instrumented socket. @c MYSQL_SOCKET is a replacement for @c my_socket. */ typedef struct st_mysql_socket MYSQL_SOCKET; thread cache #  pthread复用可以通过thread_cache_size配置：默认值为8 + (max_connections / 100)。\nMySQL提供如下status可以查看thread的数量信息：\n Threads_cached：缓存的 thread数量 Threads_connected：已连接的thread数量 Threads_created：建立的thread数量 Threads_running：running状态的 thread 数量  Threads_created = Threads_cached + Threads_connected\nThreads_running \u0026lt;= Threads_connected\n创建pthread新连接非常消耗资源，特别是在短连接频繁场景下，如果又没有其他组件实现连接池，通过观察Connections/Threads_created的比例，适当提高 thread_cache_size，可以降低新建连接的开销。\nmysql\u0026gt; show status like 'Thread%'; +-------------------+-------+ | Variable_name | Value | +-------------------+-------+ | Threads_cached | 1 | | Threads_connected | 1 | | Threads_created | 2 | | Threads_running | 1 | +-------------------+-------+ 4 rows in set (0.00 sec) auth连接限制 #  除了参数 max_user_connections 限制每个用户的最大连接数，还可以对每个用户制定更细致的限制。以下四个限制保存在mysql.user表中：\n MAX_QUERIES_PER_HOUR 每小时最大请求数（语句数量） MAX_UPDATES_PER_HOUR 每小时最大更新数（更新语句的数量） MAX_CONNECTIONS_PER_HOUR 每小时最大连接数 MAX_USER_CONNECTIONS 这个用户的最大连接数  GRANT priv_type [(column_list)] [, priv_type [(column_list)]] ... ON [object_type] priv_level TO user [auth_option] [, user [auth_option]] ... [REQUIRE {NONE | tls_option [[AND] tls_option] ...}] [WITH {GRANT OPTION | resource_option} ...] resource_option: { | MAX_QUERIES_PER_HOUR count | MAX_UPDATES_PER_HOUR count | MAX_CONNECTIONS_PER_HOUR count | MAX_USER_CONNECTIONS count } ALTER USER 'jeffrey'@'localhost' WITH MAX_QUERIES_PER_HOUR 90; 源码分析 #  typedef struct user_resources { uint questions; /* MAX_QUERIES_PER_HOUR */ uint updates; /* MAX_UPDATES_PER_HOUR */ uint conn_per_hour; /* MAX_CONNECTIONS_PER_HOUR */ uint user_conn; /* MAX_USER_CONNECTIONS */ /* Values of this enum and specified_limits member are used by the parser to store which user limits were specified in GRANT statement. */ enum {QUERIES_PER_HOUR= 1, UPDATES_PER_HOUR= 2, CONNECTIONS_PER_HOUR= 4, USER_CONNECTIONS= 8}; uint specified_limits; } USER_RESOURCES; ACL_USER #  ACL_USER 是保存用户认证相关信息的类 USER_RESOURCES 是它的成员属性\nclass ACL_USER :public ACL_ACCESS { public: USER_RESOURCES user_resource; ... } ACl_USER 对象保存在数组 acl_users 中，每次mysqld启动时，从mysql.user表中读取数据，初始化 acl_users，初始化过程在函数 acl_load 中\n调用栈如下：\nmain() mysqld_main() acl_init(opt_noacl); acl_reload(thd); acl_load(thd, tables); USER_CONN #  保存用户资源使用的结构体，建立连接时，调用 get_or_create_user_conn 为 THD 绑定 USER_CONN 对象：\n// 请求第一次处理时 acl_authenticate() if ((acl_user-\u0026gt;user_resource.questions || acl_user-\u0026gt;user_resource.updates || acl_user-\u0026gt;user_resource.conn_per_hour || acl_user-\u0026gt;user_resource.user_conn || global_system_variables.max_user_connections) \u0026amp;\u0026amp; get_or_create_user_conn(thd, (opt_old_style_user_limits ? sctx-\u0026gt;user().str : sctx-\u0026gt;priv_user().str), (opt_old_style_user_limits ? sctx-\u0026gt;host_or_ip().str : sctx-\u0026gt;priv_host().str), \u0026amp;acl_user-\u0026gt;user_resource)) -------\u0026gt; thd-\u0026gt;set_user_connect(uc); 每个用户第一个连接创建时，建立一个新对象，存入 hash_user_connections。\n第二个连接开始，从 hash_user_connections 取出 USER_CONN 对象和 THD 绑定。\n同一个用户的连接，THD 都和同一个 USER_CONN 对象绑定。\ntypedef struct user_conn { /* hash_user_connections hash key: user+host key */ char *user; char *host; /* Total length of the key. */ size_t len; ulonglong reset_utime; uint connections; uint conn_per_hour, updates, questions; USER_RESOURCES user_resources; } USER_CONN; 资源限制在源码中的位置\n   资源名称 函数     MAX_USER_CONNECTIONS check_for_max_user_connections()   MAX_CONNECTIONS_PER_HOUR check_for_max_user_connections()   MAX_QUERIES_PER_HOUR check_mqh()   MAX_UPDATES_PER_HOUR check_mqh()    调用链\nhandle_connection thd_prepare_connection(thd) login_connection check_connection acl_authenticate check_for_max_user_connections do_command dispatch_command mysql_parse check_mqh 权限存储与管理 #  MySQL用户权限信息都存储在以下系统表中，用户权限的创建、修改和回收都会同步更新到系统表中。\n   系统表 存储的权限信息     mysql.user 用户权限   mysql.db 库权限   mysql.tables_priv 表权限   mysql.columns_priv 列权限   mysql.procs_priv 存储过程和UDF的权限信息   mysql.proxies_priv proxy权限    mysql.db存储是库的权限信息，并不存储实例有哪些库（ls查找目录）。  information_schema表的查询接口：\n USER_PRIVILEGES SCHEMA_PRIVILEGES TABLE_PRIVILEGES COLUMN_PRIVILEGES  权限缓存 #  用户在连接数据库的过程中，为了加快权限的验证过程，系统表中的权限会缓存到内存中。\n mysql.user → acl_users mysql.db → acl_dbs mysql.tables_priv和mysql.columns_priv → column_priv_hash mysql.procs_priv → proc_priv_hash和func_priv_hash  另外acl_cache缓存db级别的权限信息。例如执行use db时，会尝试从acl_cache中查找并更新当前数据库权限（thd-\u0026gt;security_ct→db_access）。\n权限更新 #  以grant select on test.t1为例:\n 更新系统表mysql.user，mysql.db，mysql.tables_priv 更新缓存acl_users，acl_dbs，column_priv_hash 清空acl_cache  flush privileges #  重新从系统表中加载权限信息来构建缓存。\nMariaDB Role体系 #  从MairaDB 10.0.5开始，MariaDB开始提供Role（角色）的功能，补全了大家一直吐槽的MySQL不能像 Oracle 一样支持角色定义的功能。\n一个角色就是把一堆的权限捆绑在一起授权，这个功能对于有很多用户拥有相同权限的情况可以显著提高管理效率。在有角色之前，这种情况只能为每个用户都做一大堆的授权操作，或者是给很多个需要相同权限的用户提供同一个账号去使用，这又会导致你要分析用户行为的时候不知道哪个操作是哪个具体用户发起的。\n有了角色，这样的管理就太容易了。例如，可以把权限需求相同的用户赋予同一个角色，只要定义好这个角色的权限就行，要更改这类用户的权限，只需要更改这个角色的权限就可以了，变化会影响到所有这个角色的用户。\n使用方法 #  创建角色需要使用CREATE ROLE语句，删除角色使用DROP ROLE语句。然后再通过GRANT语句给角色增加授权，也可以把角色授权给用户，然后这个角色的权限就会分配给这个用户。同样，REVOKE语句也可以用来移除角色的授权，或者把一个用户移除某个角色。\n一旦用户连接上来，他可以执行SET ROLE语句来把自己切换到某个被授权的角色下，从而使用这个角色的权限。通过CURRENT_ROLE函数可以显示当前用户执行在哪个角色下，没有就是NULL。\n只有直接被授予用户的角色才可以使用SET ROLE语句，间接授予的角色并不能被SET ROLE设置。例如角色B被授予角色A，而角色A被授予用户A，那么用户A只能 SET ROLE 角色A，而不能设置角色B。（角色B-\u0026gt;角色A-\u0026gt;用户A）\n从MariaDB 10.1.1开始，可以利用SET DEFAULT ROLE语句来给某个用户设置默认的角色。当用户链接的时候，会默认使用这个角色，其实就是连接后自动做了一个SET ROLE语句。\n创建一个角色并给他赋权:\nCREATE ROLE journalist; GRANT SHOW DATABASES ON *.* TO journalist; GRANT journalist to hulda; 这里hulda并不马上拥有SHOW DATABASES权限，他还需要先执行一个SET ROLE语句启用这个角色：\n// 一开始只能看到IS库 SHOW DATABASES; +--------------------+ | Database | +--------------------+ | information_schema | +--------------------+ // 当前用户没有对应的角色 SELECT CURRENT_ROLE; +--------------+ | CURRENT_ROLE | +--------------+ | NULL | +--------------+ // 启用角色 SET ROLE journalist; SELECT CURRENT_ROLE; +--------------+ | CURRENT_ROLE | +--------------+ | journalist | +--------------+ SHOW DATABASES; +--------------------+ | Database | +--------------------+ | ... | | information_schema | | mysql | | performance_schema | | test | | ... | +--------------------+. SET ROLE NONE; 角色也可以授权给另一个角色（角色累加）：\nCREATE ROLE writer; GRANT SELECT ON db1.* TO writer; GRANT writer TO journalist; 但是只能SET ROLE直接给用户的角色。像这里hulda只能SET ROLE journalist，而不能SET ROLE writer，并且只要启用了journalist角色，hulda也自动获得了writer角色的权限：\nSELECT CURRENT_ROLE; +--------------+ | CURRENT_ROLE | +--------------+ | NULL | +--------------+ SHOW TABLES FROM data; Empty set (0.01 sec) // 启用角色 SET ROLE journalist; SELECT CURRENT_ROLE; +--------------+ | CURRENT_ROLE | +--------------+ | journalist | +--------------+ // 叠加了wirter角色，可以访问db1中的表 SHOW TABLES FROM db1; +------------------------------+ | Tables_in_db1 | +------------------------------+ | set1 | | ... | +------------------------------+ 限制 #  角色和视图、存储过程\n当用户设置启用了一个角色，从某种意义上说他有两个身份的权限集合（用户本身和他的角色）但是一个视图或者存储过程只能有一个定义者。所以，当一个视图或者存储过程通过SQL SECURITY DEFINER创建时，只能指定CURRENT_USER或者CURRENT_ROLE中的一个。所以有些情况下，你创建了一个视图，但是你却可能没法使用它。\nCREATE ROLE r1; GRANT ALL ON db1.* TO r1; GRANT r1 TO foo@localhost; GRANT ALL ON db.* TO foo@localhost; SELECT CURRENT_USER; +---------------+ | current_user | +---------------+ | foo@localhost | +---------------+ SET ROLE r1; CREATE TABLE db1.t1 (i int); CREATE VIEW db.v1 AS SELECT * FROM db1.t1; SHOW CREATE VIEW db.v1; +------+------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ | View | Create View | character_set_client | collation_connection | +------+------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ | v1 | CREATE ALGORITHM=UNDEFINED DEFINER=`foo`@`localhost` SQL SECURITY DEFINER VIEW `db`.`v1` AS SELECT `db1`.`t1`.`i` AS `i` from `db1`.`t1` | utf8 | utf8_general_ci | +------+------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ CREATE DEFINER=CURRENT_ROLE VIEW db.v2 AS SELECT * FROM db1.t1; SHOW CREATE VIEW db.b2; +------+-----------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ | View | Create View | character_set_client | collation_connection | +------+-----------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ | v2 | CREATE ALGORITHM=UNDEFINED DEFINER=`r1` SQL SECURITY DEFINER VIEW `db`.`v2` AS select `db1`.`t1`.`a` AS `a` from `db1`.`t1` | utf8 | utf8_general_ci | +------+-----------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ 相关文件 #  源代码文件按照文章顺序整理：\n源代码文件按照文章顺序整理： sql/conn_handler/named_pipe_connection.h\tNamed_pipe_listener sql/conn_handler/named_pipe_connection.cc\tChannel_info_named_pipe sql/conn_handler/shared_memory_connection.h\tShared_mem_listener sql/conn_handler/shared_memory_connection.cc\tChannel_info_shared_mem sql/conn_handler/socket_connection.h\tMysqld_socket_listener sql/conn_handler/socket_connection.cc\tChannel_info_local_socket Channel_info_tcpip_socket TCP_socket Unix_socket sql/conn_handler/channel_info.h\tChannel_info sql/conn_handler/channel_info.cc sql/conn_handler/connection_acceptor.h\tConnection_acceptor sql/conn_handler/connection_handler_manager.h\tConnection_handler_manager sql/conn_handler/connection_handler_manager.cc sql/conn_handler/connection_handler.h\tConnection_handler sql/conn_handler/connection_handler_impl.h\tPer_thread_connection_handler One_thread_connection_handler sql/conn_handler/plugin_connection_handler.h\tPlugin_connection_handler sql/conn_handler/connection_handler_one_thread.cc sql/conn_handler/connection_handler_per_thread.cc "},{"id":9,"href":"/docs/MySQL/Server/mariadb_maxscale_proxy_protocol/","title":"Mariadb Maxscale Proxy Protocol","section":"Server","content":"MariaDB MaxScale 是一款数据库中间件，可以按照语义分发语句到多个数据库服务器上。它对应用程序透明，可以提供读写分离、负载均衡和高可用服务。\nproxy protocol 是 MaxScale 引入，为了解决使用proxy作为中间件连接mysql时，mysql获取client ip用 client通过proxy中间价连接mysql时，mysql server接收到认证报文中，包含的是proxy节点的IP。如果mysql.user表中指定了client的IP，无法通过认证。\n一种传统处理方式是在proxy节点上保存client的ip和密码，用于client的认证，而在mysql server上使用另一套ip和密码用于proxy 节点到mysql server的认证。\nMariaDB MaxScale引入了proxy protocol来解决client ip透传的问题。proxy节点获取到client ip后，把client ip包装在proxy protocol报文中发给server，server解析到了proxy protocol报文，再用报文中的ip替换proxy节点的ip\n因为 proxy protocol 本身不包含鉴权，同时可能影响数据库的鉴权行为，所以在数据库 server 端设置了一个ip白名单，只有白名单ip发送的 proxy protocol 报文才会被接受。\n报文格式 #  proxy protocol 有两个版本 v1 和 v2 通过报文签名区分\nv1 #  v1 报文是字符串形式 “PROXY %s %s %s %d %d”\n   字段 内容     签名 PROXY   %s.1 address family   %s.2 client address   %s.3 server address   %d.1 client port   %d.2 server port    v2 #     字段 内容     报文签名12字节 \\x0D\\x0A\\x0D\\x0A\\x00\\x0D\\x0A\\x51\\x55\\x49\\x54\\x0A   ver_cmd 1 字节 version 高四位 0x2 « 4， command 0x1(PROXY) 0x0 (LOCAL)   family 1 字节 IPV4 0x11，IPV6 0x21，AF_UNIX 0x21   length 2字节 addr 部分的数据长度，IPV4 12， IPV6 36， AF_UNIX 216   addr 以IPV4为例 client地址4字节，server地址4字节，client port 2字节， server port 2字节    客户端改造 #  MaxScale 使用场景下，Proxy Protocol Header 由 MaxScale 发送，这里暂不分析\nMariaDB 为了测试，也改造了 client，可以通过 mysql_option 设置 Proxy Protocol\n使用方法：在mysql_real_connect之前，调用 mysql_option\nmysql_optionsv(mysql, MARIADB_OPT_PROXY_HEADER, header_data, header_lengths);\n第一个参数是 MYSQL 句柄，第二个参数是 PROXY_HEADER 标志位，第三个参数是 Proxy Protocol Header，第四个参数是 Header length\nProxy Protocol Header 按照上述规则传入即可\n/* st_mysql_options_extension 结构体对应 mysql-\u0026gt;options-\u0026gt;extension */ struct st_mysql_options_extension { ... /* */ char *proxy_header; size_t proxy_header_len; } int mysql_optionsv(MYSQL *mysql,enum mysql_option option, ...) { ... switch (option) { case MARIADB_OPT_PROXY_HEADER: { size_t arg2 = va_arg(ap, size_t); /* 把 proxy_header 和 proxy_header_len 保存到extension中 */ OPT_SET_EXTENDED_VALUE(\u0026amp;mysql-\u0026gt;options, proxy_header, (char *)arg1); OPT_SET_EXTENDED_VALUE(\u0026amp;mysql-\u0026gt;options, proxy_header_len, arg2); } break; } } /* mysql_real_connect 过程中发送 proxy header 发送时机在建连后，接收挑战码之前 这样在鉴权时可以使用 proxy header 中保存的 ip port */ MYSQL *mthd_my_real_connect(MYSQL *mysql, const char *host, const char *user, const char *passwd, const char *db, uint port, const char *unix_socket, unsigned long client_flag) { ... /* 如果extension中保存了 proxy_header，则把header发送给server */ if (mysql-\u0026gt;options.extension \u0026amp;\u0026amp; mysql-\u0026gt;options.extension-\u0026gt;proxy_header) { char *hdr = mysql-\u0026gt;options.extension-\u0026gt;proxy_header; size_t len = mysql-\u0026gt;options.extension-\u0026gt;proxy_header_len; if (ma_pvio_write(pvio, (unsigned char *)hdr, len) \u0026lt;= 0) { ma_pvio_close(pvio); goto error; } } } 服务端改造\n我们知道，server 通过对比自己的 net-\u0026gt;pkt_nr 和 client 发送过来的 net-\u0026gt;pkt_nr 来保证包没有乱序。而proxy header 没有包含正确的 pkt_nr，就可以通过判断 pkt_nr 乱序来识别 proxy header。\n对于一对client和server线程，pkt_nr是共享的。\n假设 server 发送的第一个包 pkt_nr == 1，下一个包是 client 回包 pkt_nr == 2，那么server再发给client 的包 pkt_nr == 3 以此类推。\n/* 正常的 mysql 都包含4字节 header，前三字节是size，第四字节是 pkt_nr */ my_bool my_net_write(NET *net, const uchar *packet, size_t len) { ... /* 如果大于最大包长度，则分成多个包发送 */ while (len \u0026gt;= MAX_PACKET_LENGTH) { const ulong z_size = MAX_PACKET_LENGTH; /* 前三个字节保存size */ int3store(buff, z_size); /* 第四字节保存pkt_nr */ buff[3]= (uchar) net-\u0026gt;pkt_nr++; if (net_write_buff(net, buff, NET_HEADER_SIZE) || net_write_buff(net, packet, z_size)) { MYSQL_NET_WRITE_DONE(1); return 1; } packet += z_size; len-= z_size; } /* Write last packet */ int3store(buff,len); buff[3]= (uchar) net-\u0026gt;pkt_nr++; ... } /* my_real_read 里面处理 proxy header */ static ulong my_real_read(NET *net, size_t *complen, my_bool header __attribute__((unused))) { retry: /* 收到的包不满足 pkt_nr 约束，可能是 proxy header，跳转到 packets_out_of_order */ if (net-\u0026gt;buff[net-\u0026gt;where_b + 3] != (uchar) net-\u0026gt;pkt_nr) goto packets_out_of_order; packets_out_of_order: /* 判断是否是 proxy protocol header 判断标准是报文前几位是否符合 proxy protocol header 的 signature 前面已经提到 v1 signature 五字节：PROXY v2 signature 12字节：\\x0D\\x0A\\x0D\\x0A\\x00\\x0D\\x0A\\x51\\x55\\x49\\x54\\x0A */ if (has_proxy_protocol_header(net) \u0026amp;\u0026amp; net-\u0026gt;thd \u0026amp;\u0026amp; ((THD *)net-\u0026gt;thd)-\u0026gt;get_command() == COM_CONNECT) { /* Proxy information found in the first 4 bytes received so far. Read and parse proxy header , change peer ip address and port in THD. */ /* 处理 proxy header，修改 THD 中的 ip port */ if (handle_proxy_header(net)) { /* error happened, message is already written. */ len= packet_error; goto end; } /* proxy protocol header 处理成功，跳到函数头重新读取 */ goto retry; } static int handle_proxy_header(NET *net) { /* 判断 proxy protocol header 的来源 ip 是否在白名单中 白名单是一个全局变量 proxy_protocol_networks 白名单 ip 以逗号分隔保存在全局变量中 */ if (!is_proxy_protocol_allowed((sockaddr *)\u0026amp;(thd-\u0026gt;net.vio-\u0026gt;remote))) { /* proxy-protocol-networks variable needs to be set to allow this remote address */ my_printf_error(ER_HOST_NOT_PRIVILEGED, \u0026#34;Proxy header is not accepted from %s\u0026#34;, MYF(0), thd-\u0026gt;main_security_ctx.ip); return 1; } /* 根据格式解析 proxy protocol header，格式在上文中已做介绍 解析结果保存在 peer_info 中 */ if (parse_proxy_protocol_header(net, \u0026amp;peer_info)) { /* Failed to parse proxy header*/ my_printf_error(ER_UNKNOWN_ERROR, \u0026#34;Failed to parse proxy header\u0026#34;, MYF(0)); return 1; } /* Change peer address in THD and ACL structures.*/ /* 将 peer_info 中的信息转存到 thd 中 */ return thd_set_peer_addr(thd, \u0026amp;(peer_info.peer_addr), NULL, peer_info.port, false); } "},{"id":10,"href":"/docs/MySQL/Server/mdl/","title":"Mdl","section":"Server","content":"历史 #  为了解这个著名的bug#989：\nDML和DDL如果并发执行，binlog序错乱：主库并发执行了DDL（T → T'）和DML（T’），但是提交到了binlog中顺序是DDL+DML，这样在从库上回放时，先执行DDL，后执行DML，但此时表结构已经变为T‘，DML执行失败  因此，在MySQL 5.5中，引入了MDL（Meta Data Lock）来控制DDL和DML的并发，保证元数据的一致性。\n设计思理：\n WL#3726：DDL locking for all metadata objects WL#4284：Transactional DDL locking  谈到MDL，需要先谈谈MySQL的锁定机制设计以及thr_lock\nMySQL locking #  为了保证数据的一致性和完整性，数据库系统普遍存在封锁机制，而封锁机制的优劣直接关系到数据库系统的并发处理能力和性能，所以封锁机制的实现也成为了各种数据库的核心技术之一。\nMySQL的封锁机制有三种：\n row-level locking：InnoDB、NDB Cluster table-level locking：MyISAM、MEMORY、MERGE、CSV等非事务存储引擎 page-level locking：BerkeleyDB  MySQL采用如此多样的封锁机制是由其产品定位和发展历史共同决定的。首先，MySQL的产品定位是通过plugin机制可以接入多个存储引擎。在早期的存储引擎（MyISAM和MEMORY）设计中，设计原则建立在\u0026quot;任何表在同一时刻都只允许单个线程（无论读写）对其访问\u0026quot;之上。随后，MySQL3.23修正了之前的假设：MyISAM支持Concurrent Insert：如果没有hole，可以多个读线程并发读同一张表，同时多个写线程以队列的形式进行尾部insert。之后，BerkeleyDB和InnoDB的引入也挑战了之前的设计假设，要求page-level、和row-level locking。此时，之前的设计方式已经和存储引擎所提供的能力不相衬了。因此MySQL做出了改变，允许存储引擎自己改变MySQL 通过接口传入的锁定类型（也就是上面的3种）而自行决定该怎样封锁数据。\nMySQL加锁的顺序\nSQL → open table → 加MDL锁 → 加表锁 → 加InnoDB锁 → SQL执行 → 释放MDL锁 → 释放表锁 → 释放InnoDB锁\n其中表锁是通过thr_lock提供的，在MySQL 5.7.5中，thr_lock被MDL替换：\nScalability for InnoDB tables was improved by avoiding THR_LOCK locks. As a result of this change, DML statements for InnoDB tables that previously waited for a THR_LOCK lock will wait for a metadata lock:\n Explicitly or implicitly started transactions that update any table (transactional or nontransactional) will block and be blocked by LOCK TABLES \u0026hellip; READ for that table. This is similar to how LOCK TABLES \u0026hellip; WRITE works. Tables that are implicitly locked by LOCK TABLES now will be locked using metadata locks rather than THR_LOCK locks (for InnoDB tables), and locked using metadata locks in addition to THR_LOCK locks (for all other storage engines). Implicit locks occur for underlying tables of a locked view, tables used by triggers for a locked table, or tables used by stored programs called from such views and triggers. Multiple-table updates now will block and be blocked by concurrent LOCK TABLES \u0026hellip; READ statements on any table in the update, even if the table is used only for reading. HANDLER \u0026hellip; READ for any storage engine will block and be blocked by a concurrent LOCK TABLES \u0026hellip; WRITE, but now using a metadata lock rather than a THR_LOCK lock.   相关WorkLog：WL#6671: Improve scalability by not using thr_lock.c locks for InnoDB tables\nTable Locking #  MySQL的表级锁定最开始使用thr_lock，主要分为两种类型，一种是读锁定，另一种是写锁定。table lock模块为每个表维护了四个队列来表示这两种锁定：\n granted read/write waiting read/write  如下： • Current read-lock queue (lock-\u0026gt;read) • Pending read-lock queue (lock-\u0026gt;read_wait) • Current write-lock queue (lock-\u0026gt;write) • Pending write-lock queue (lock-\u0026gt;write_wait)\n对于DQL，锁类型一般是TL_READ；对于普通的DML，是TL_WRITE_ALLOW_WRITE\n代码路径：\nlock_tables mysql_lock_tables thr_multi_lock thr_lock MDL locking #  MDL Locking通过多层次、多粒度的locking，在满足一致性和完整性的前提下保证并发性能。\n锁的获取 #  等待中的锁，按照锁优先级编排锁的获取。默认写者优先，但读者在配置了max_write_lock_count（一般不会出现）后，可以优先处理。\nMDL锁是依次申请的（one by one），并进行死锁检测：\n DML：按照语句中table的出现顺序获取 DDL：按照table的字母序申请  比如\nRENAME TABLE tbla TO tbld, tblc TO tbla; // 按照a-\u0026gt;c-\u0026gt;d顺序申请MDL锁（name order） RENAME TABLE tbla TO tblb, tblc TO tbla; // 按照a-\u0026gt;b-\u0026gt;c顺序申请MDL锁（name order） 这样可以保证表按同序申请 但如果DML、DDL并发执行，则先后顺序有差异，见官方文档中的示例。\n锁的释放 #  为了保证事务的可序列化，需要保证保证DML和DDL的互斥，MDL锁只能在事务提交后释放（S2PL）。\n锁的状态变更 #  观测\n可以通过performance_schema.metadata_locks查看MDL信息\nUPDATE performance_schema.setup_consumers SET ENABLED = 'YES' WHERE NAME ='global_instrumentation'; UPDATE performance_schema.setup_instruments SET ENABLED = 'YES' WHERE NAME ='wait/lock/metadata/sql/mdl'; select* from performance_schema.metadata_locks MDL状态转换如下图所示：\n死锁检测 #  造成死锁是因为：\n 访问共享资源 多个线程访问 互斥冲突采用等待策略 不能按同一固定顺序请求锁  从当前线程开始，转换到全局锁列表，然后在深度遍历，当wait_for和当前THD相同时，形成环；然后递归返回时，通过权重确定victim。\nctx::find_deadlock while (1) { Deadlock_detection_visitor dvisitor(this); // ctx  ctx::visit_subgraph(); 当前线程是否有锁等待MDL_context::m_waiting_for，有的话就沿着ticket搜下去，没有就退出。 ticket-\u0026gt;accept_visitor 搜索视角的转换，从 MDL_context 经过 MDL_ticket 进入到 MDL_lock lock-\u0026gt;visit_subgraph 核心逻辑 } visit_subgraph\n先给搜索深度加1，然后判断是否超过最大搜索深度（MAX_SEARCH_DEPTH= 32），超过就无条件认为有死锁，退出； 遍历当前锁的ticket链表，看ticket对应的线程是否和死锁检测的发起线程是同一个，如果是则说明有回路，退出（相当于做了一层的广度搜索）；\n从头开始遍历当前锁的ticket链表，对每个ticket对应的线程，递归调用MDL_context::visit_subgraph（深度搜索）。 整个死锁检测逻辑是一个加了深度限制的深搜，中间同时多了一层广搜。\nDeadlock_detection_visitor 是死锁检测中重要的辅助类，主要负责：\n 记录死锁检测的起始线程 记录被选做victim的线程 在检测到死锁，深搜一层层退出的时候，会依次检查回路上各线程的死锁权重，选择权重最小的做为最终的victim（权重由锁的类型决定）  死锁权重：\n DDL：100 USER_LEVEL_LOCK：50 DML：0  即优先回滚DDL\nMDL子系统 #  锁子系统的核心功能：\n 由用户侧提交锁请求 提供一个中心化的锁管理（锁对象、granted、waiting、停等通知、死锁检测） 通过ticket关联用户和锁对象  锁子系统交互 #  在MDL子系统中，体现在THD和MDL锁子系统的交互上，如下图所示：加锁是用户线程（THD）向MDL子系统申请并获得对应锁的ticket的过程，加锁成功标志是MDL模块返回一个对应的ticket，大致逻辑如下：\n 解析SQL语句，根据语义对每一个表对象设置TABLE_LIST.mdl_request，如对普通的select语句 TABLE_lsit.mdl_request.type 就是MDL_SHARED_READ（st_select_lex::set_lock_for_tables()） 用户线程在打开每个表之前，会请求和这个表对应的MDL锁，通过 thd→mdl_context.acquire_lock()接口将mdl_request请求发给MDL子系统 MDL模块根据请求类型和已有的锁来判断请求能否满足，如果可以就返回一个ticket；如果不可以就等待，等待结果可以是成功（别的线程释放了阻塞的MDL锁）、失败（超时、连接被kill或者被死锁检测选为victim） 用户线程根据MDL模块的返回结果，决定继续往下走还是报错退出。  DL锁并不是对表加锁，而是在加表锁前的一个预检查，如果能拿到MDL锁，下一步加相应的表锁。  MDL子系统内部加锁流程\nMDL子系统内部类关系图\n生命周期 #  整个锁系统各个对象的生命周期如下：\n数据结构 #  MDL_key 锁对象标识 #  Metadata lock object key用于标识MDL对象，由三元组组成：namespace、db、table，作为全局锁表（MDL_map）、锁请求（MDL_request）、锁对象（MDL_lock）的成员变量。\n其数据结构（POD）如下：ctor namespace, db, name *MDL_key reset 置空 is_equal bit equal cmp memcmp 禁止拷贝 MDL lock提供多粒度锁，分为scoped lock和object lock，namespace层次如下：![MySQL_MDL_key namespace](/MySQL_MDL_key namespace.png)\nnamespace的详细说明（这里颠倒了枚举定义的顺序，按scoped lock和object lock顺序论述）：\n   enum_mdl_namespace 说明     enum_mdl_namespace 说明   GLOBAL 全局唯一，防止DDL和写操作的过程中执行 set golbal_read_only =on 或flush tables with read lock;IX+S(EXPLICIT) 显式释放   COMMIT 全局唯一，执行flush table with read lock后，防止在途写事务的提交IX+S(EXPLICIT) 显式释放   TABLESPACE 表空间锁   SCHEMA 库锁   TABLE 表锁   FUNCTION 用于UDF   PROCEDURE 用于SP   TRIGGER 用于TRIGGER   EVENT 用于event-scheduler   USER_LEVEL_LOCK 用于test sync，GET_LOCK(str,timeout)，RELEASE_LOCK(str)   LOCKING_SERVICE plugin service    其中具体的应用场景：\nMDL_key::TABLESPACE X/IX TRX 用于 CREATE or ALTER TABLESPACE DISCARD or IMPORT TABLESPACE CREATE TABLE LIKE MDL_key::SCHEMA X/IX TRX 用于 lock_schema_name GLOBAL+IX+STMT SCHEMA+X+TRX lock_object_name GLOBAL+IX+STMT SCHEMA+IX+TRX OBJECT+X+TRX lock_table_names SCHEMA+IX+TRX MDL_key::GLOBAL IX STMT S EXPLICIT MDL_key::COMMIT IX STMT IX EXPLICIT S EXPLICIT 示例：\n锁的申请由上到下，由大到小，由意向到具体：\nsession A: begin transaton and select\nsession B: ALTER TABLE \u0026hellip;\n   GLOBAL IX STMT     SCHEMA test IX TRX   TABLE test t SU TRX    session A: commit\nsession B:\n   TABLE test t X TRX            锁信息 #  在MDL_request和MDL_ticket中，都需要描述锁信息（key+type+duration）\ntype表示MDL锁的类型，enum_mdl_type\n   锁类型 简写 说明     MDL_INTENTION_EXCLUSIVE IX 意向X锁，只用于scoped lock   MDL_SHARED S    MDL_SHARED_HIGH_PRIO SH    MDL_SHARED_READ SR    MDL_SHARED_WRITE SW    MDL_SHARED_WRITE_LOW_PRIO SWLP    MDL_SHARED_UPGRADABLE SU    MDL_SHARED_READ_ONLY SRO    MDL_SHARED_NO_WRITE SNR    MDL_SHARED_NO_READ_WRITE SNRW    MDL_EXCLUSIVE X     * MDL_INTENTION_EXCLUSIVE IX // 意向X锁，只用于scope 锁\n* MDL_SHARED S // 只能读metadata，当能读写数据，如检查表是否存在时用这个锁\n* MDL_SHARED_HIGH_PRIO SH // 高优先级S锁，可以抢占X锁，只能读metadata，不能读写数据，用于填充INFORMATION_SCHEMA，或者show create table时\n* MDL_SHARED_READ SR // 可以读表数据，select语句，lock table xxx read 都用这个\n* MDL_SHARED_WRITE SW // 可以更新表数据，insert，update，delete，lock table xxx write, select for update，\n* MDL_SHARED_UPGRADABLE SU // 可升级锁，可以升级为SNW或者X锁，ALTER TABLE第一阶段会用到\n* MDL_SHARED_NO_WRITE SNW // 可升级锁，其它线程能读metadata，数据可读不能读，持锁者可以读写，可以升级成X锁，ALTER TABLE的第一阶段\n* MDL_SHARED_NO_READ_WRITE SNRW // 可升级锁，其它线程能读metadata，数据不能读写，持锁者可以读写，可以升级成X锁，LOCK TABLES xxx WRITE\n* MDL_EXCLUSIVE X // 排它锁，禁止其它线程的所有请求，CREATE/DROP/RENAME TABLE\n MDL_INTENTION_EXCLUSIVE(IX) 意向排他锁，锁定一个范围，用在GLOBAL/SCHEMA/COMMIT粒度。 MDL_SHARED(S) 用在只访问元数据信息，不访问数据。例如CREATE TABLE t LIKE t1; MDL_SHARED_HIGH_PRIO(SH) 也是用于只访问元数据信息，但是优先级比排他锁高，用于访问information_schema的表。例如：select * from information_schema.tables; MDL_SHARED_READ(SR) 访问表结构并且读表数据，例如：SELECT * FROM t1; LOCK TABLE t1 READ LOCAL; MDL_SHARED_WRITE(SW) 访问表结构且写表数据， 例如：INSERT/DELETE/UPDATE t1 … ;SELECT * FROM t1 FOR UPDATE;LOCK TALE t1 WRITE MDL_SHARED_WRITE_LOW_PRIO(SWLP) 优先级低于MDL_SHARED_READ_ONLY。语句INSER/DELETE/UPDATE LOW_PRIORITY t1 …; LOCK TABLE t1 WRITE LOW_PRIORITY。 MDL_SHARED_UPGRADABLE(SU) 可升级锁，允许并发update/read表数据。持有该锁可以同时读取表metadata和表数据，但不能修改数据。可以升级到SNW、SNR、X锁。用在alter table的第一阶段，使alter table的时候不阻塞DML，防止其他DDL。 MDL_SHARED_READ_ONLY(SRO) 持有该锁可读取表数据，同时阻塞所有表结构和表数据的修改操作，用于LOCK TABLE t1 READ。 MDL_SHARED_NO_WRITE(SNW) 持有该锁可以读取表metadata和表数据，同时阻塞所有的表数据修改操作，允许读。可以升级到X锁。用在ALTER TABLE第一阶段，拷贝原始表数据到新表，允许读但不允许更新。 MDL_SHARED_NO_READ_WRITE(SNRW) 可升级锁，允许其他连接读取表结构但不可以读取数据，阻塞所有表数据的读写操作，允许INFORMATION_SCHEMA访问和SHOW语句。持有该锁的的连接可以读取表结构，修改和读取表数据。可升级为X锁。使用在LOCK TABLE WRITE语句。 MDL_EXCLUSIVE(X) 排他锁，持有该锁连接可以修改表结构和表数据，使用在CREATE/DROP/RENAME/ALTER TABLE 语句。  duration表示MDL锁的持有时长，enum_mdl_duration\n   锁时长 说明     MDL_STATEMENT 语句结束自动释放   MDL_TRANSACTION 事务结束自动释放   MDL_EXPLICIT 显示申请，显示释放（unlock tables）    锁矩阵 #  MDL的锁矩阵根据scoped lock和object lock分为两类，其中有根据加锁策略分为granted matrix和waiting matrix。\nMDL_scoped_lock只使用3种锁类型：IX、S、X\nscoped_lock granted matrix\n | Type of active | Request | scoped lock | type | IX S X | ---------+----------------+ IX | + - - | S | - + - | X | - - - | scoped_lock waiting matrix\n | Pending | Request | scoped lock | type | IX S X | ---------+---------------+ IX | + - - | S | + + - | X | + + + | MDL_object_lock使用除IX外的所有锁类型\nobject_lock granted matrix\nRequest | Granted requests for lock | type | S SH SR SW SWLP SU SRO SNW SNRW X | ----------+---------------------------------------------+ S | + + + + + + + + + - | SH | + + + + + + + + + - | SR | + + + + + + + + - - | SW | + + + + + + - - - - | SWLP | + + + + + + - - - - | SU | + + + + + - + - - - | SRO | + + + - - + + + - - | SNW | + + + - - - + - - - | SNRW | + + - - - - - - - - | X | - - - - - - - - - - | SU -\u0026gt; X | - - - - - 0 0 0 0 0 | SRO -\u0026gt; X | - - - - 0 0 0 0 0 0 | SNW -\u0026gt; X | - - - 0 0 0 0 0 0 0 | SNRW -\u0026gt; X | - - 0 0 0 0 0 0 0 0 | 0：不可能出现的情况，比如对于SU锁来说其和自身是不兼容的，不可能有2个线程对同一个对象都持有SU锁，所以就不存在当一个线程进行锁升级时，另一个线程持有SU\nobject_lock waiting matrix\nRequest | Pending requests for lock | type | S SH SR SW SWLP SU SRO SNW SNRW X | ----------+--------------------------------------------+ S | + + + + + + + + + - | SH | + + + + + + + + + + | SR | + + + + + + + + - - | SW | + + + + + + + - - - | SWLP | + + + + + + - - - - | SU | + + + + + + + + + - | SRO | + + + - + + + + - - | SNW | + + + + + + + + + - | SNRW | + + + + + + + + + - | X | + + + + + + + + + + | SU -\u0026gt; X | + + + + + + + + + + | SRO -\u0026gt; X | + + + + + + + + + + | SNW -\u0026gt; X | + + + + + + + + + + | SNRW -\u0026gt; X | + + + + + + + + + + | SH 比 X 锁的优先级还高，正是其高优先级(high priority)的体现。\nMDL_map 全局锁信息 #  static，在MySQL启动时初始化，并预分配两个全局唯一的scoped lock（GLOBAL+COMMIT），MDL_map是MDL子系统的内部对象，外部不可见。\n作为全局MDL锁的存储，其必定会成为热点，之前采用partition mutex的方式解决热点，后改进采用xxx。并且采用lazy random re-org的方式进行内存整理。\nMDL_context #  作为THD和MDL子系统的交互接口，提供锁的管理功能（申请、释放、升级、clone、回滚、死锁检测）。\nMDL_context的生命周期如下（和THD同生命周期）：\n声明定义 class THD { MDL_context mdl_context; }; 初始化 THD::THD mdl_context.init(this); 使用：申请锁 acquire lock thd-\u0026gt;mdl_context.acquire_lock(\u0026amp;mdl_request, thd-\u0026gt;variables.lock_wait_timeout)) 释放 THD::release_resources if (!cleanup_down) THD::cleanup mdl_context.release_transactional_locks(); mdl_context::release_locks_stored_before(MDL_STATEMENT, NULL); mdl_context::release_locks_stored_before(MDL_TRANSACTION, NULL); mdl_context.destroy(); MDL_context.m_tickets[]中存储了3个ticket链表：\n STMT TRX EXPLICIT  其中STMT和TRX属于automiatc release，EXPLICIT属于manual release，有以下4种锁使用explicit显示锁：\nLOCK TABLES locks User-level locks HANDLER locks GLOBAL READ LOCK locks 数据结构\nm_tickets 指针数组（里面是3个ticket链表，分别代表STMT,TRX,EXPLICIT） m_owner 指向THD m_wait 实现锁等待（MDL_wait） m_waiting_for 当前线程正在等待的锁（MDL_wait_for_subgraph*） find_ticket 在当前线程的ticket链表中查找一个ticket(和request-\u0026gt;key同一对象\u0026amp;强度\u0026gt;=request-\u0026gt;type) clone_ticket clone ticket mdl_savepoint 生成savepoint rollback_to_savepoint MDL锁回滚到某个savepoint release_locks_stored_before 释放ticket链表上在某个ticket之前所有ticket release_lock 释放单个MDL锁（全局和自己） release_locks release_all_locks_for_name 把当前线程对某个对象加的所有MDL锁都释放掉 acquire_lock 申请锁 acquire_locks 一次性申请多个X锁，要么全部成功要么全部失败，用于RENAME, DROP和其他DDL语句 try_acquire_lock 尝试申请锁，失败就返回out_ticket，没有死锁检测 upgrade_shared_lock 升级共享锁 owns_equal_or_stronger_lock 当前线程是否已持有更强的锁 find_lock_owner 找到持有锁的第一个owner has_lock 当前线程是否在savepoint之前持有指定的锁 has_locks 当前线程是否没有持有任何锁（3个链表都为空） has_locks_waited_for set_explicit_duration_for_all_locks 在LOCK TABLES时使用，因为trx lock生命周期长于explicit，所以将stmt和trx链表中的锁移到explicit链表中 set_transaction_duration_for_all_locks 上面的反操作 set_lock_duration 将当前线程的某个ticket在链表中移动 release_statement_locks 释放所有语句范围的锁 release_transactional_locks 释放所有事务范围的锁 get_deadlock_weight 死锁时拿一个权重值，以此来判断对应线程是否要做为victim set_force_dml_deadlock_weight set_needs_thr_lock_abort get_needs_thr_lock_abort find_deadlock 检测是否有死锁 visit_subgraph 和死锁检测相关 acquire_locks：一次性申请多个X锁，要么全部成功要么全部失败，用于RENAME, DROP和其他DDL语句 如果后续的锁grant失败，会通过savepoint将前面已经申请到的锁也rollback。\n比如drop table test.t1这个DDL会一次加3个锁：\n GLOBAL，MDL_INTENTION_EXCLUSIVE test 库, MDL_INTENTION_EXCLUSIVE test.t1 表，MDL_EXCLUSIVE  MDL_context::acquire_lock\n主加锁函数，调试MDL锁相关问题时，给这个函数加断点比较有效。先调用MDL_context::try_acquire_lock_impl，如果加锁失败就进入等待加锁逻辑：\n 将MDL_context::try_acquire_lock_impl返回的ticket放进MDL_lock的等待队列 触发一次死锁检测 进入等待，等待又分为2种：  定时检查等待: 如果当前请求的锁是比较高级的（对于MDL_object_lock是比MDL_SHARED_NO_WRITE类型更高，对于MDL_scoped_lock是MDL_SHARED类型），就会每秒给其它持有当前锁的线程（并且这些连接持有的锁等级比较低）发信号，通知其释放锁，然后再检查是否锁已拿到 一直等待，直到超时   检查步骤3的等待结果，可以是GRANTED（拿到锁）、VICTIM（被死锁检测算法选为受害者）、TIMEOUT（加锁超时）、KILLED（连接被kill）。拿到锁返回成功，其它返回失败  MDL_context::upgrade_shared_lock\n锁升级，从共享锁升级到互斥锁，实现方式是重新申请一个目标锁，拿到新的ticket后替换老的ticket，用在alter table和create table场景中。\n如create table test.t1(id int) engine = innodb，会先拿test.t1的MDL_SHARED共享锁，检查表是否存在，如果不存在就把锁升级到MDL_EXCLUSIVE锁，然后开始建表。\n对于alter table test.t1 add column name varchar(10), algorithm=copy;，alter用copy到临时的方式来做。整个过程中MDL顺序是这样的：\n 刚开始打开表的时候，用的是 MDL_SHARED_UPGRADABLE 锁； 拷贝到临时表过程中，需要升级到 MDL_SHARED_NO_WRITE 锁，这个时候其它连接可以读，不能更新； 拷贝完在交换表的时候，需要升级到是MDL_EXCLUSIVE，这个时候是禁止读写的。  所以在用copy算法alter表过程中，会有2次锁升级。\nMDL_ticket::downgrade_lock 和MDL_context::upgrade_shared_lock对应的锁降级，从互斥锁降级到共享锁，实现比较简单，直接把锁类型改为目标类型（不用重新申请）。\n对于alter table test.t1 add column name varchar(10), algorithm=inplace，如果alter使用inplace算法的话，整个过程中MDL加锁顺序是这样的：\n 和copy算法一样，刚开始打开表的时候，用的是 MDL_SHARED_UPGRADABLE 锁； 在prepare前，升级到MDL_EXCLUSIVE锁； 在prepare后，降级到MDL_SHARED_UPGRADABLE（其它线程可以读写）或者MDL_SHARED_NO_WRITE（其它线程只能读不能写），降级到哪种由表的引擎决定； 在alter结束后，commit前，升级到MDL_EXCLUSIVE锁，然后commit。  可以看到inplace有2次锁升级，1次降级，不过在alter最耗时的阶段是有可能降级到MDL_SHARED_UPGRADABLE的，对其它线程的影响小。\nMDL_request #  MDL_request用于描述THD当前SQL的MDL锁请求语义（请求什么对象什么类型多长时间的MDL锁），负责THD → MDL的交互数据，由6元组组成：MDL_request是POD，通过MDL_REQUEST_INIT宏来完成初始化\nMDL_request mdl_request; MDL_REQUEST_INIT(\u0026amp;mdl_request, mdl_type, db, name, MDL_EXCLUSIVE, MDL_TRANSACTION); MDL_ticket #  MDL子系统内部对锁请求的表示，可以想象成一张\u0026quot;门票\u0026quot;。\n创建点：由MDL_ticket::create()统一创建ticket\n申请锁时 MDL_context::try_acquire_lock_impl ticket= MDL_ticket::create(this, mdl_request-\u0026gt;type, mdl_request-\u0026gt;duration); MDL_context::clone_ticket ticket= MDL_ticket::create(this, mdl_request-\u0026gt;type, mdl_request-\u0026gt;duration); 也可以复用ticket（MDL_context.find_ticket()）：\n 查找ticket MDL_context.find_ticket()：遍历当前线程的3个ticket链表，查找当前锁对象（key）是否有\u0026gt;=duration的ticket 如果duration不相同，或者为显式锁（explicit），则clone ticket；否则复用  其中#2，因为duration不同，锁的释放时机不同，这会破坏锁的严格性；explicit为manual release，所以必须单独一个；而可以复用锁的场景更为普遍，如下：\nSTART TRANSACTION; insert into t1 values (1); insert into t1 values (2); 第二条insert不需要再走一遍复杂的加锁逻辑，因为第一条insert已经成功拿到t1表的ticket，类型都是MDL_SHARED_WRITE，并且MDL锁时间范围也一样（transaction），这个时候直接用已有的ticket。\nticket有三个用途：\n 向THD描述锁申请的结果：通过挂在MDL_request上的ticket指针表示，有指向则granted/waiting，没有指向则是没有申请到锁资源 作为THD和MDL子系统的桥梁，构建线程的锁等待图，用于死锁检测  其中第二点再展开一下：\n要构建锁线程的锁等待图：\n 连接线程和全局锁对象：作为双方（MDL_context，MDL_lock）的共同链表元素，提供路径可以access 实现锁等待算法：作为MDL_wait_for_subgraph的子类，实现accept_visitor()  内部的数据结构\nm_ctx*, m_lock*, type, duration MDL_lock中的2个ticket链表节点(next,prev) MDL_context中的3个ticket链表节点(next,prev) ctor dtor create destroy 禁止copy has_pending_conflicting_lock 当前ticket的锁类型是否和对应MDL锁的等待队列中的锁冲突 is_upgradable_or_exclusive 是否是可升级锁或者X锁（SU、SNW、SNRW、X） downgrade_lock 锁降级（X/SNR -\u0026gt; ???） has_stronger_or_equal_type 当前ticket对应的锁和指定的锁比较是否更强 granted matrix is_incompatible_when_granted 是否和granted matrix冲突 is_incompatible_when_waiting 是否和waiting matrix冲突 /** Implement MDL_wait_for_subgraph interface. */ accept_visitor get_deadlock_weight() 获取死锁权重 MDL_lock MDL锁对象 #  MDL子系统内部用于描述MDL锁对象的表示。\nm_rwlock 保护MDL_lock锁对象的读写锁（采用读者优先） key 锁标识（MDL_key） m_granted granted ticket链表（Ticket_list） m_waiting waiting ticket链表（Ticket_list） Ticket_list 表示当前锁（key）对应的ticket链表，内部类 add_ticket remove_ticket bitmap 当前ticket list中的所有锁类型（bitmap），用于快速检测要申请的ticket和grant matrix和waiting matrix是否冲突 struct MDL_lock_strategy create destroy remove_ticket 从MDL_lock中的granted/waiting链表释放指定的ticket reschedule_waiters 当锁的ticket释放/降级时，从等待队列中选择ticket看能否grant incompatible_granted_types_bitmap incompatible_waiting_types_bitmap get_incompatible_waiting_types_bitmap_idx switch_incompatible_waiting_types_bitmap_if_needed - has_pending_conflicting_lock // 已经授权的ticket是否和等待队列中的ticket不兼容 - can_grant_lock // 能否加锁，先和等待队列进行优先级比较，然后看和已授权的锁是否兼容 - visit_subgraph // 死锁检测相关 - needs_notification // 是否需要通知其它线程，当前ticket的锁情况 - notify_conflicting_locks // 通知其它线程，有一个高级的锁请求 needs_connection_check needs_hton_notification is_affected_by_max_write_lock_count count_piglets_and_hogs get_unobtrusive_lock_increment is_obtrusive_lock fast_path_granted_bitmap - hog_lock_types_bitmap // 标识哪种锁是高级锁 * m_hog_lock_count // 高级锁可以连接拿得锁的个数，超过这个数目就要给低级锁让路，防止低级锁饿死 m_piglet_lock_count m_current_waiting_incompatible_idx MDL_wait #  锁等待的实现类，作为MDL_context的成员变量\nenum_wait_status 锁等待退出时的状态 timed_wait 锁等待，mutex+cond+timeout MDL_savepoint #  因为explicit锁不会在savepoint rollback释放，所以只需记录THD对应的stmt和trx的ticket point，供MDL_context生成savepoint使用\nm_stmt_ticket 指向创建savepoint前的最后一个stmt ticket m_trans_ticket 指向创建savepoint前的最后一个stmt ticket global read lock #  MySQL为了获得全局一致性的点位，通过FTWRL（FLUSH TABLES WITH READ LOCK）来阻止变化：\n 新的变更进不来（有且只能有一人抢到全局唯一的锁） 已有变更提交不了  做到这样需要：\n 有且只能有一人抢到全局唯一的锁，并进行范围锁定 两把锁：阻止老的，阻止新的  锁定范围\n GLOBAL+S+EXPLICIT（通过Global_read_lock::lock_global_read_lock） COMMIT+S+EXPLICIT（通过Global_read_lock::make_global_read_lock_block_commit）  并清空表缓存（逼迫更新表元信息必须先走open table获取GLOBAL+IX+STMT），以及其他元信息更新入口 阻止元数据修改和表数据更改（S和IX不兼容）：\n 更新表元信息必须先走open table获取GLOBAL+IX+STMT） 事务和xa事务提交（数据变更，写入binlog先获取COMMIT+IX+STMT）  实现：\n当FLUSH TABLES table_list [WITH READ LOCK]时，Lex-\u0026gt;type添加REFRESH_TABLES和REFRESH_READ_LOCK标记\nsql_yacc.cc\nflush_options: table_or_tables { Lex-\u0026gt;type|= REFRESH_TABLES; /* Set type of metadata and table locks for FLUSH TABLES table_list [WITH READ LOCK]. */ YYPS-\u0026gt;m_lock_type= TL_READ_NO_INSERT; YYPS-\u0026gt;m_mdl_type= MDL_SHARED_HIGH_PRIO; opt_flush_lock: /* empty */ {} | WITH READ_SYM LOCK_SYM { TABLE_LIST *tables= Lex-\u0026gt;query_tables; Lex-\u0026gt;type|= REFRESH_READ_LOCK; for (; tables; tables= tables-\u0026gt;next_global) { tables-\u0026gt;mdl_request.set_type(MDL_SHARED_NO_WRITE); tables-\u0026gt;required_type= FRMTYPE_TABLE; /* Don\u0026#39;t try to flush views. */ tables-\u0026gt;open_type= OT_BASE_ONLY; /* Ignore temporary tables. */ } } sql_parse.cc\ncase SQLCOM_FLUSH: reload_acl_and_cache thd-\u0026gt;global_read_lock.lock_global_read_lock(thd); thd-\u0026gt;global_read_lock.make_global_read_lock_block_commit(thd)) flush table cache blocking其他请求\nGlobal_read_lock::lock_global_read_lock GLOBAL+S+EXPLICIT Global_read_lock::make_global_read_lock_block_commit COMMIT+S+EXPLICIT open_table GLOBAL+IX+STMT ha_commit_trans 事务提交 COMMIT+IX+EXPLICIT xa_transaction xa事务提交 prepare COMMIT+IX+STMT commit COMMIT+IX+STMT rollback COMMIT+IX+STMT TODO:\nFAST PATH（unobtrusive） OR SLOW PATH（obtrusive）\nLF_HASH\n"},{"id":11,"href":"/docs/MySQL/Server/net/","title":"Net","section":"Server","content":"MySQL packet的结构如下：\npacket length (3 bytes) // 数据\npacket number (1 byte) // 保序\ncompression length (3 bytes) optional // 压缩\ncompression packet number （1 byte） optional // 保序\npacket data\n 因为采用3个字节存储包的长度，所以支持的包最大为 MAX_PACKET_LENGTH (256L256L256L-1)。如果数据流超过包最大值（16M），则通过packet number（ne→pkt_nr）保序。\n发包 #  my_net_write #  发包，Write a logical packet with packet header.\nnet_write_buff #  发送缓冲区，Caching the data in a local buffer before sending it.\n每个Net对象有一个buffer(net-\u0026gt;buff)，即将发送的数据被拷贝到这个buffer中。如果buffer未满则进行memcpy，并更新写入点位（net-\u0026gt;write_pos）；满了当Buffer满时需要立刻发出到客户端（net_write_packet）。\nnet_write_packet #  socket写数据，Write a MySQL protocol packet to the network handler.\nnet_write_raw_loop #  Write a determined number of bytes to a network handler. 调用vio_write进行socket写\nnet_flush #  Flush write_buffer if not empty. 也是调用net_write_packet进行socket写数据\n收包 #  my_net_read #  收包\nnet_read_packet #  读单包，Read one (variable-length) MySQL protocol packet. A MySQL packet consists of a header and a payload.\nnet_read_packet_header #  读包头，Read the header of a packet. 校验包头中的packet number，确认保序\n"},{"id":12,"href":"/docs/MySQL/Server/protocol/","title":"Protocol","section":"Server","content":"MySQL client-server protocol：https://dev.mysql.com/doc/internals/en/client-server-protocol.html\nMySQL 5.7重构了Protocol模块\n我们在这里主要聚焦在command phase，即MySQL server和client如何处理query的交互。\n我们从MySQL协议可以知道，在query的交互上，一般采用ping-pong模型，即：\n client-\u0026gt;server：发query server-\u0026gt;client：回包  所以我们在下面详细拆解这两个阶段。\n读取query #  当client发送一条query后，server对query进行以下处理：\n 读包 解析包体 根据命令指派执行  数据报文包括包头+包体，包头已在读包内部验证后丢弃（read_packet），然后包体返回给Protocol_classic::get_command封装为raw_packet。从raw_packet[0]中判断query的命令号，进行报文解析（parse_packet），拆解为COM_DATA（根据命令号封装了不同的struct）。\ndo_command // conn_handler Protocol_classic::get_command // 读包 Protocol_classic::read_packet my_net_read // 处理多包、压缩包 net_read_packet // 将读到的数据填充到NET中 Protocol_classic::parse_packet // 解析包体 dispatch_command // 根据命令指派执行 回包 #  返回的报文类型有：OK Packet，Error Packet和结果集包（Data Packet，EOF Packet）。\nOK Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_ok // 回OK包 Error Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_error // 回错误包 结果集包 #  结果集包的结构如下:\n   数据 说明     ResultSet Header 列数量   Field 列（多个）   EOF    Row 行（多个）   EOF     Server层的SQL执行器拼装结果集：\n// sql_executor Query_result_send::send_result_set_metadata thd-\u0026gt;send_result_metadata Protocol_classic::start_result_metadata() // 列数量  Protocol_classic::send_field_metadata() // 列（多个）  Protocol_classic::end_result_metadata() // EOF Query_result_send::send_data(List\u0026lt;Item\u0026gt; \u0026amp;items) // 行（多个）  protocol-\u0026gt;start_row(); thd-\u0026gt;send_result_set_row(\u0026amp;items) for loop : items protocl-\u0026gt;store() thd-\u0026gt;inc_sent_row_count(1); protocol-\u0026gt;end_row() Query_result_send::send_eof // EOF  net_send_ok 注意最后两行：send_eof调用了send_ok？？？\nbool Protocol_classic::send_eof(uint server_status, uint statement_warn_count) { DBUG_ENTER(\u0026#34;Protocol_classic::send_eof\u0026#34;); bool retval; /* Normally end of statement reply is signaled by OK packet, but in case of binlog dump request an EOF packet is sent instead. Also, old clients expect EOF packet instead of OK */ #ifndef EMBEDDED_LIBRARY  if (has_client_capability(CLIENT_DEPRECATE_EOF) \u0026amp;\u0026amp; (m_thd-\u0026gt;get_command() != COM_BINLOG_DUMP \u0026amp;\u0026amp; m_thd-\u0026gt;get_command() != COM_BINLOG_DUMP_GTID)) retval= net_send_ok(m_thd, server_status, statement_warn_count, 0, 0, NULL, true); else #endif  retval= net_send_eof(m_thd, server_status, statement_warn_count); DBUG_RETURN(retval); } 这是因为在MySQL 5.7.5中，有一个worklog：WL#7766: Deprecate the EOF packet，认为EOF and OK packets serve the same purpose (to mark the end of a query execution result.\n将ok和eof报文的发送放在了同一块逻辑中，client/server支持一个flag：CLIENT_DEPRECATE_EOF，EOF包说明里也有提到。\n如果我们要自己组装结果集包，则按照如下API组装即可：\nthd-\u0026gt;send_result_metadata protocol-\u0026gt;start_row(); protocol-\u0026gt;store(); protocol-\u0026gt;end_row(); my_eof(thd); 下面是一个实际的组装示例：\nmysql\u0026gt; show sql_filters; +--------+---------+----------+----------+---------+-------------+ | type | item_id | cur_conc | max_conc | key_num | key_str | +--------+---------+----------+----------+---------+-------------+ | SELECT | 4 | 0 | 1 | 2 | +,1,a=1~a=2 | +--------+---------+----------+----------+---------+-------------+ void mysqld_list_sql_filters(THD *thd) { List\u0026lt;Item\u0026gt; field_list; field_list.push_back(new Item_empty_string(\u0026#34;type\u0026#34;, 21)); field_list.push_back(new Item_return_int(\u0026#34;item_id\u0026#34;, 21, MYSQL_TYPE_LONGLONG)); field_list.push_back(new Item_return_int(\u0026#34;cur_conc\u0026#34;, 21, MYSQL_TYPE_LONGLONG)); field_list.push_back(new Item_return_int(\u0026#34;max_conc\u0026#34;, 21, MYSQL_TYPE_LONGLONG)); field_list.push_back(new Item_return_int(\u0026#34;key_num\u0026#34;, 21, MYSQL_TYPE_LONGLONG)); field_list.push_back(new Item_empty_string(\u0026#34;key_str\u0026#34;, SQL_FILTER_STR_LEN)); if (thd-\u0026gt;send_result_metadata(\u0026amp;field_list, Protocol::SEND_NUM_ROWS | Protocol::SEND_EOF)) return; mysql_rwlock_rdlock(\u0026amp;LOCK_filter_list); if (list_one_sql_filter(thd, select_filter_list, \u0026#34;SELECT\u0026#34;) || list_one_sql_filter(thd, update_filter_list, \u0026#34;UPDATE\u0026#34;) || list_one_sql_filter(thd, delete_filter_list, \u0026#34;DELETE\u0026#34;)) { ; } mysql_rwlock_unlock(\u0026amp;LOCK_filter_list); my_eof(thd); } int list_one_sql_filter(THD *thd, LIST *filter_list, const char *type) { CHARSET_INFO *cs= system_charset_info; filter_item *item= NULL; Protocol *protocol= thd-\u0026gt;get_protocol(); while (filter_list) { protocol-\u0026gt;start_row(); item= (filter_item*)filter_list-\u0026gt;data; protocol-\u0026gt;store(type, cs); protocol-\u0026gt;store((longlong)item-\u0026gt;id); protocol-\u0026gt;store(__sync_fetch_and_add(\u0026amp;(item-\u0026gt;cur_conc), 0)); protocol-\u0026gt;store(item-\u0026gt;max_conc); protocol-\u0026gt;store((longlong)item-\u0026gt;key_num); protocol-\u0026gt;store(item-\u0026gt;orig_str, cs); if (protocol-\u0026gt;end_row()) return 1; //no cover line  filter_list= filter_list-\u0026gt;next; } return 0; } MySQL 5.7的协议重构 #  MySQL 5.7大幅重构了Protocol模块代码, 采用了OO的设计方式：WL#7126: Refactoring of protocol class：\nNew Protocol ``class` `hierarchy ============================ The ``new` `hierarchy consists of 4 classes: Protocol | Protocol_classic | |---Protocol_text |---Protocol_binary Protocol is an abstract ``class` `that defines the ``new` `API. Protocol_classic is ex-Protocol ``class``, implements core of both classic protocols - text and binary. Protocol_text and Protocol_binary are implementations of appropriate classic protocols.   Protocol作为一个注释丰满且只有纯虚函数的抽象类, 非常容易理顺protocol模块能够提供的API。细节实现主要在Protocol_classic中（所以上文的调用栈可以看到, 实际逻辑是走到Protocol_classic中的）, 而逻辑上还划分出的两个类:\n Protocol_binary是Prepared Statements使用的协议 Protocol_text场景  上面提到了MySQL 5.7.5引入的Deprecate EOF，实际上MySQL 5.7上对OK/EOF报文做了大量修改，使得client可以通过报文拿到更多的会话状态信息。方便中间层会话保持，主要涉及几个worklog：\nWL#4797: Extending protocol’s OK packet\nWL#6885: Flag to indicate session state\nWL#6128: Session Tracker: Add GTIDs context to the OK packet\nWL#6972: Collect GTIDs to include in the protocol’s OK packet\nWL#7766: Deprecate the EOF packet\nWL#6631: Detect transaction boundaries\n同时新增变量控制报文行为:\n  session_track_schema = [ON | OFF] ON时, 如果session中变更了当前database, OK报文中回返回新的database\n  session_track_state_change = [ON | OFF] ON时, 当发生会话环境改变时, 会给CLIENT返回一个FLAG(1)，会话环境变化包括：\n当前database\n系统变量\nUser-defined 变量\n临时表的变更\nprepare xxx\n 但是只通知变更发生，具体值是多少，还需要配合session_track_schema、session_track_system_variables使用，所以限制还是很多…\n  session_track_system_variables = [“list of string, seperated bt ‘,’”] 这个参数用来追踪的变量, 目前只有time_zone, autocommit, character_set_client, character_set_results, character_set_connection可选。当这些变量的值变动时，client可以收到variable_name: new_value的键值对\n  session_track_gtids = [OFF | OWN_GTID | ALL_GTIDS] OWN_GTID：在会话中产生新GTIDs（当然只读操作不会后推GTID位点）时，以字符串形式返回新增的GTIDs ALL_GTIDS：在每个包中返回当前的executed_gtid值，但是这样报文的payload很高，不推荐\n  session_track_transaction_info = [ON | OFF] 打开后, 通过标志位表示当前会话状态，有8bit可以表示状态信息（其中使用字符’_‘表示FALSE）：\n  T: 显示开启事务; I: 隐式开启事务（autocommit = 0）\n  r: 有非事务表读\n  R: 有事务表读\n  w: 非事务表写\n  W: 事务表写\n  s: 不安全函数（比如 select uuid()）\n  S: server返回结果集\n  L: 显示锁表(LOCK TABLES) 一个事务内，返回的状态值是累加的\n示例 表t1是InnoDB，表t2是MyISAM\nSTART TRANSACTION; // T_______ INSERT INTO t1 VALUES (1); // T___W___ INSERT INTO t2 VALUES (1); // T__wW___ SELECT f1 FROM t1; // T_RwW_S_ ... COMMIT/ROLLBACK;     OK和EOF报文在MySQL 5.6上是走不同的逻辑构造报文，但实际上都是返回一些执行状态。MySQL 5.7中的Deprecated EOF报文，实际上是复用了OK报文中新增的状态，但是实际上这两个报文还是不同的：\nOK Packet： header = 0 and length of packet \u0026gt; 7\nEOF Packet：header = 0xfe and length of packet \u0026lt; 9\n只是复用了在net_send_ok里的扩充逻辑。\n有了以上这些信息，我们可以做很多中间层的开发工作，比如读写分离就用状态追踪对外提供透明的读写分离。\n"},{"id":13,"href":"/docs/MySQL/Server/returning/","title":"Returning","section":"Server","content":"背景 #  MySQL对于statement执行结果报文通常分为两类：Resultset和OK/ERR，针对 DML语句则返回OK/ERR报文，其中包括几个影响记录，扫描记录等属性。但在很多业务场景下，通常 INSERT/UPDATE/DELETE 这样的DML语句后，都会跟随SELECT查询当前记录内容，以进行接下来的业务处理， 为了减少一次 Client \u0026lt;-\u0026gt; DB Server 交互，类似 PostgreSQL / Oracle 都提供了 returning clause 支持 DML 返回 Resultset。\nAliSQL 为了减少对 MySQL 语法兼容性的侵入，并支持 returning 功能， 采用了 native procedure 的方式，使用DBMS_TRANS package，统一使用 returning procedure 来支持 DML 语句返回 Resultset。\n语法 #  DBMS_TRANS.returning(Field_list=\u0026gt;, Statement=\u0026gt;); 其中:\n Field list : 代表期望的返回字段，以 “,” 进行分割，支持 * 号表达； Statement ：表示要执行的DML 语句， 支持 INSERT / UPDATE / DELETE；  INSERT Returning #  针对 insert 语句， returning proc 返回插入到表中的记录内容；\nmysql\u0026gt; CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `col1` int(11) NOT NULL DEFAULT '1', `col2` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`) ) ENGINE=InnoDB; mysql\u0026gt; call dbms_trans.returning(\u0026quot;*\u0026quot;, \u0026quot;insert into t(id) values(NULL),(NULL)\u0026quot;); +----+------+---------------------+ | id | col1 | col2 | +----+------+---------------------+ | 1 | 1 | 2019-09-03 10:39:05 | | 2 | 1 | 2019-09-03 10:39:05 | +----+------+---------------------+ 2 rows in set (0.01 sec) 如果没有填入任何 Fields, returning 将退化成 OK/ERR 报文：\nmysql\u0026gt; call dbms_trans.returning(\u0026quot;\u0026quot;, \u0026quot;insert into t(id) values(NULL),(NULL)\u0026quot;); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t; +----+------+---------------------+ | id | col1 | col2 | +----+------+---------------------+ | 1 | 1 | 2019-09-03 10:40:55 | | 2 | 1 | 2019-09-03 10:40:55 | | 3 | 1 | 2019-09-03 10:41:06 | | 4 | 1 | 2019-09-03 10:41:06 | +----+------+---------------------+ 4 rows in set (0.00 sec) 注意：INSERT returning 只支持 insert values 形式的语法，类似create as， insert select 不支持：\nmysql\u0026gt; call dbms_trans.returning(\u0026quot;\u0026quot;, \u0026quot;insert into t select * from t\u0026quot;); ERROR 7527 (HY000): Statement didn't support RETURNING clause UPDATE Returning #  针对 update 语句， returning 返回更新后的记录：\nmysql\u0026gt; call dbms_trans.returning(\u0026quot;id, col1, col2\u0026quot;, \u0026quot;update t set col1 = 2 where id \u0026gt;2\u0026quot;); +----+------+---------------------+ | id | col1 | col2 | +----+------+---------------------+ | 3 | 2 | 2019-09-03 10:41:06 | | 4 | 2 | 2019-09-03 10:41:06 | +----+------+---------------------+ 2 rows in set (0.01 sec) 注意: UPDATE returning 不支持多表 update 语句。\nDELETE Returning #  针对 delete 语句， returning 返回删除的记录前映像：\nmysql\u0026gt; call dbms_trans.returning(\u0026quot;id, col1, col2\u0026quot;, \u0026quot;delete from t where id \u0026lt; 3\u0026quot;); +----+------+---------------------+ | id | col1 | col2 | +----+------+---------------------+ | 1 | 1 | 2019-09-03 10:40:55 | | 2 | 1 | 2019-09-03 10:40:55 | +----+------+---------------------+ 2 rows in set (0.00 sec) 注意 #  1. 事务上下文 DBMS_TRANS.returning() 不是事务性语句，根据 DML statement 来继承 事务上下文， 结束事务需要显式的 COMMIT 或者 ROLLBACK。\n2. 字段不支持计算 Field list 中，只支持表中原生的字段，或者 * 号， 不支持进行计算或者聚合等操作。\n"},{"id":14,"href":"/docs/MySQL/Server/startup/","title":"Startup","section":"Server","content":"MySQL启动过程\nmain() // 入口 sql/main.cc mysqld_main() // sql/mysqld.cc // 记录入参 my_progname = argv[0]; orig_argc = argc; orig_argv = argv; // 处理配置文件my.cnf及启动参数 load_defaults(MYSQL_CONFIG_NAME, load_default_groups, \u0026amp;argc, \u0026amp;argv, \u0026amp;argv_alloc); // 继续处理启动参数，为初始化系统表做准备 sys_var::m_parse_flag == PARSE_EARLY handle_early_options(); // 为status统计计数做准备 init_sql_statement_names(); // 初始化system variables哈希表,链表sys_var_chain sys_var,遍历链表后,加入到system_variable_hash哈希表 // sys_var_chain链表已经通过sys_vars.cc的sys_var()构造函数static初始化 sys_var_init(); // 计算打开文件数并初始化table cache adjust_related_options(\u0026amp;requested_open_files); // init error log global variables init_error_log(); // init audit global variables mysql_audit_initialize(); // 初始化query log和slow log query_logger.init(); // 初始化system variables init_common_variables(); default_storage_engine= const_cast\u0026lt;char *\u0026gt;(\u0026quot;InnoDB\u0026quot;); // 设置默认storage engine add_status_vars(status_vars); // 初始化status变量(show status), status_vars为全局变量 set_server_version(); get_options(\u0026amp;remaining_argc, \u0026amp;remaining_argv); // sys_var::m_parse_flag == PARSE_NORMAL // 设置thread_cache_size init_client_errs(); // 读出给client返回出错信息的文件 lex_init(); // 初始化词法分析 item_create_init(); // 初始化函数列表 func_array为全局变量 // 设置默认字符集和校验字符集 global_system_variables.collation_connection= default_charset_info; global_system_variables.character_set_results= default_charset_info; global_system_variables.character_set_client= default_charset_info; // 设置默认storage engine lex_init(); // 初始化信号量 my_init_signals(); // 启动核心模块 init_server_components(); mdl_init();\t// mdl元数据锁 table_def_init(); // 表定义缓存 init_server_query_cache();\t// Query Cache init binlog relaylog\t// Binlog Relaylog gtid_server_init();\t// GTID plugin_register_builtin_and_init_core_se(); // Load builtin plugins, initialize MyISAM, CSV and InnoDB // 初始化并创建GTID init_server_auto_options(); // 初始化SSL init_ssl(); // 初始化网络 network_init(); // 创建PID文件 create_pid_file(); // 初始化status variables init_status_vars(); // binlog相关检查初始化 check_binlog_cache_size(NULL); check_binlog_stmt_cache_size(NULL); binlog_unsafe_map_init(); // 初始化Slave init_slave(); // 创建线程处理信号量 start_signal_handler(); // 如果是安装初始化，创建handle_bootstrap线程进行初始化datadir,系统表 if (opt_bootstrap) bootstrap(mysql_stdin); // 创建manager线程 start_handle_manager(); // 执行DDL crash recovery execute_ddl_log_recovery(); // 监听socket事件 mysqld_socket_acceptor-\u0026gt;connection_event_loop(); if (signal_thread_id.thread != 0) ret= my_thread_join(\u0026amp;signal_thread_id, NULL); clean_up(1); mysqld_exit(MYSQLD_SUCCESS_EXIT); 其中，load_defaults()会寻找my.cnf，并根据load_default_groups，使用search_default_file_with_ext()解析每一行配置，并进行标准化（配置项名称前加上\u0026ndash;）\n// sql/mysqld.cc 2325 const char *load_default_groups[]= { ... 2329 \u0026quot;mysqld\u0026quot;,\u0026quot;server\u0026quot;, MYSQL_BASE_VERSION, 0, 0}; // mysys_ssl/my_default.cc my_load_defaults my_search_option_files my_search_option_files search_default_file_with_ext 配置项会被handle_default_option()缓存在内存中\n// mysys_ssl/my_default.cc handle_default_option() struct handle_option_ctx { MEM_ROOT *alloc; My_args *m_args; TYPELIB *group; }; "},{"id":15,"href":"/docs/MySQL/Server/thd/","title":"Thd","section":"Server","content":"THD对象 #  THD封装了线程相关的数据，可以视作一个处理单元。\nThe size of the THD is ~10K and its definition is found in sql_class.h.\nThe THD is a large data structure which is used to keep track of various aspects of execution state. Memory rooted in the THD will grow significantly during query execution, but exactly how much it grows will depend upon the query. For memory planning purposes we recommend to plan for ~10MB per connection on average.\nFor each client connection we create a separate thread with THD serving as a thread/connection descriptor class THD { NET net; // client connection descriptor  Vio* active_vio; Protocol *m_protocol; // Current protocol  Protocol_text protocol_text; // Normal protocol  Protocol_binary protocol_binary; // Binary protocol  ... } Global_THD_manager #  Global_THD_manager作为thd管理器，统一提供thd资源的管控，提供thd的全局查找、计数、执行操作。\n生命周期 #  create_instance() // 创建thd_mgr，mysqld启动时 destroy_instance() // 销毁thd_mgr，mysqld关闭时 get_instance() // 在mysqld运行时获取thd_mgr，以调用其api API #  add_thd() // 添加thd remove_thd() // 移除thd wait_till_no_thd // 移除所有thd thd操作 #  查找 #  提供Find_THD_Impl函数模板，并由以下方法调用：\n find_thd  函数模板\nFind_THD_variable 在PS查看thd信息时提供并发控制（thd-\u0026gt;LOCK_thd_data） Find_thd_user_var 在PS查看thd信息时提供并发控制（thd-\u0026gt;LOCK_thd_data） ... 计数 #  num_thread_running thread_created\n执行操作 #  提供Do_THD_Impl函数模板，并由以下方法调用：\n do_for_all_thd_copy ：提供LOCK_thd_remove对remove thd进行并发控制 do_for_all_thd ：不做并发控制  函数模板\nSet_kill_conn // kill thd List_process_list // 列出所有thd ... kill process_id #  kill命令格式\nKILL [CONNECTION | QUERY] processlist_id 其中：\n CONNECTION：中止processlist_id对应的查询中止，连接退出 QUERY ：中止processlist_id对应的查询中止，连接保持 Ctrl+C ：MySQL client Ctrl+C会新建立一个临时的connection，将kill query的命令发送给MySQL，停止之前的命令，再回收掉临时的connection  处理kill #  kill的执行是异步的，分为标记kill和中止执行两阶段。\n标记kill #  当MySQL Server收到kill命令时，会根据命令中指定的process_id，查找到对应的THD，设置kill标记\nstatic uint kill_one_thread(THD *thd, my_thread_id id, bool only_kill_query) { THD *tmp= NULL; uint error=ER_NO_SUCH_THREAD; Find_thd_with_id find_thd_with_id(id); DBUG_ENTER(\u0026#34;kill_one_thread\u0026#34;); DBUG_PRINT(\u0026#34;enter\u0026#34;, (\u0026#34;id=%u only_kill=%d\u0026#34;, id, only_kill_query)); tmp= Global_THD_manager::get_instance()-\u0026gt;find_thd(\u0026amp;find_thd_with_id); ... tmp-\u0026gt;awake(only_kill_query ? THD::KILL_QUERY : THD::KILL_CONNECTION); ... } 中止执行 #   空闲的process_id立即退出  void THD::awake(THD::killed_state state_to_set) { ... if (this-\u0026gt;m_server_idle \u0026amp;\u0026amp; state_to_set == KILL_QUERY) { /* nothing */ } else { killed= state_to_set; } ... }  在SQL的执行过程中，会在各种位置检测THD上的kill标记，中止执行，清理后退出\n  等待中响应\n如果查询此时等待在某个condition_variable上，那么短时间内可能很难唤醒，如果出现了死锁的情况，那么就更不可能唤醒了。因此，kill实现了针对等待的特殊响应，其主要思路是：在某个查询进入等待状态之前，在THD上记录下当前查询等待的condition_variable对象及其对应的mutex。\nvoid enter_cond(mysql_cond_t *cond, mysql_mutex_t* mutex, const PSI_stage_info *stage, PSI_stage_info *old_stage, const char *src_function, const char *src_file, int src_line) { DBUG_ENTER(\u0026#34;THD::enter_cond\u0026#34;); mysql_mutex_assert_owner(mutex); /* Sic: We don\u0026#39;t lock LOCK_current_cond here. If we did, we could end up in deadlock with THD::awake() which locks current_mutex while LOCK_current_cond is locked. */ current_mutex= mutex; current_cond= cond; enter_stage(stage, old_stage, src_function, src_file, src_line); DBUG_VOID_RETURN; } 在等待的条件上增加对thd-\u0026gt;killed状态的判断，即检测到killed时退出等待\nlonglong Item_func_sleep::val_int() { THD *thd= current_thd; Interruptible_wait timed_cond(thd); mysql_cond_t cond; timeout= args[0]-\u0026gt;val_real(); mysql_cond_init(key_item_func_sleep_cond, \u0026amp;cond); mysql_mutex_lock(\u0026amp;LOCK_item_func_sleep); thd-\u0026gt;ENTER_COND(\u0026amp;cond, \u0026amp;LOCK_item_func_sleep, \u0026amp;stage_user_sleep, NULL); error= 0; thd_wait_begin(thd, THD_WAIT_SLEEP); while (!thd-\u0026gt;killed) { error= timed_cond.wait(\u0026amp;cond, \u0026amp;LOCK_item_func_sleep); if (error == ETIMEDOUT || error == ETIME) break; error= 0; } thd_wait_end(thd); mysql_mutex_unlock(\u0026amp;LOCK_item_func_sleep); thd-\u0026gt;EXIT_COND(NULL); mysql_cond_destroy(\u0026amp;cond); return MY_TEST(!error); // Return 1 killed } kill发生时, 使用THD记录的condition_variable进行pthread_cond_signal，进行唤醒，等待的线程醒来检测kill标记，发现已被标记kill快速退出。\nvoid THD::awake(THD::killed_state state_to_set) { ... /* Broadcast a condition to kick the target if it is waiting on it. */ if (is_killable) { mysql_mutex_lock(\u0026amp;LOCK_current_cond); /* This broadcast could be up in the air if the victim thread exits the cond in the time between read and broadcast, but that is ok since all we want to do is to make the victim thread get out of waiting on current_cond. If we see a non-zero current_cond: it cannot be an old value (because then exit_cond() should have run and it can\u0026#39;t because we have mutex); so it is the true value but maybe current_mutex is not yet non-zero (we\u0026#39;re in the middle of enter_cond() and there is a \u0026#34;memory order inversion\u0026#34;). So we test the mutex too to not lock 0. Note that there is a small chance we fail to kill. If victim has locked current_mutex, but hasn\u0026#39;t yet entered enter_cond() (which means that current_cond and current_mutex are 0), then the victim will not get a signal and it may wait \u0026#34;forever\u0026#34; on the cond (until we issue a second KILL or the status it\u0026#39;s waiting for happens). It\u0026#39;s true that we have set its thd-\u0026gt;killed but it may not see it immediately and so may have time to reach the cond_wait(). However, where possible, we test for killed once again after enter_cond(). This should make the signaling as safe as possible. However, there is still a small chance of failure on platforms with instruction or memory write reordering. */ if (current_cond \u0026amp;\u0026amp; current_mutex) { mysql_mutex_lock(current_mutex); mysql_cond_broadcast(current_cond); mysql_mutex_unlock(current_mutex); } mysql_mutex_unlock(\u0026amp;LOCK_current_cond); } DBUG_VOID_RETURN; }   "},{"id":16,"href":"/docs/MySQL/Server/timeout/","title":"Timeout","section":"Server","content":"背景 #  在分布式环境下，异步网络是一个挑战，当遇到网络问题时，提供超时机制可以提升系统的可用性。并且，对于事务系统，锁机制也需要超时机制来保证资源可以在有限时间内释放，避免饥饿现象的产生。\n为此，MySQL在多种场景下提供了timeout机制。\n简单一句话，MySQL Protocol ping-pong模型各个节点都有超时检测  MySQL timeout配置 #  MySQL内有多种timeout，我们先看一下有多少：\nmysql\u0026gt; show global variables like '%timeout%'; +-----------------------------+----------+ | Variable_name | Value | +-----------------------------+----------+ | connect_timeout | 5 | | net_read_timeout | 30 | | net_write_timeout | 60 | | wait_timeout | 28800 | | interactive_timeout | 28800 | | lock_wait_timeout | 31536000 | | innodb_lock_wait_timeout | 3 | | innodb_rollback_on_timeout | OFF | +-----------------------------+----------+ 通过阅读官方文档，结合我们在下面对于timeout实现的论证，这里先放上结论：\n网络超时\n connect_timeout：在connection phase阶段超时 net_read_timeout：在comamnd phase阶段网络读超时 net_write_timeout：在comamnd phase阶段网络写超时 wait_timeout、interactive_timeout：在connection phase结束后，在command phase节点，多长时间没有收到命令包。这里的wait_timeout和interactive_timeout的区别只是连接的种类不同，wait_timeout是对noninteractive的连接空闲超时，interactive_timeout是对interactive的连接空闲超时（客户端连接时设置了CLIENT_INTERACTIVE）  总结一下：\n connection phase应用建链期间，没有收到client回复，connect_timeout command phase期间没有收到请求时，net_wait_timeout/net_interactive_timeout，当收到请求后，接受一次完整的请求间，如果出现网络读包超时，net_read_timeout，回包时写socket超时，net_write_timeout  锁超时\n lock_wait_timeout：获取mdl锁的超时时间 innodb_lock_wait_timeout：InnoDB中行锁等待的超时时间（对表锁无效） innodb_rollback_on_timeout：当InnoDB锁等待超时后，OFF只rollback事务中的最后一条语句，ON则rollback整个事务  timeout配置项的值范围\n   配置项 默认值 值范围 线上默认配置     connect_timeout 10 2 ~ 1 year 10   net_read_timeout 30 1 ~ 1 year 30   net_write_timeout 60 1 ~ 1 year 60   wait_timeout 8 hour 1 ~ 1 year 28800   interactive_timeout 8 hour 1 ~ 1 year 28800   lock_wait_timeout 1 year 1 ~ 1 year 31536000   innodb_lock_wait_timeout 50 1 ~ 1073741824 5   innodb_rollback_on_timeout OFF ON/OFF OFF    实现细节 #  下面结合代码看一下这些timeout的具体含义。\nconnect_timeout net_read_timeout net_write_timeout #  两处设置网络超时 1. 网络初始化 Protocol_classic::init_net mysql client my_net_init my_net_local_init my_net_set_read_timeout my_net_set_write_timeout net-\u0026gt;read_timeout = ... net-\u0026gt;write_timeout = ... 2. 网络读写 mysql client vio_socket_connect // 根据等待的连接事件（VIO_IO_EVENT_CONNECT） vio_read vio_write vio_socket_io_wait // 根据等待的读写事件（VIO_IO_EVENT_READ/VIO_IO_EVENT_WRITE）将select超时设置为vio-\u0026gt;read_timeout或vio-\u0026gt;write_timeout vio_io_wait // timeout:-1 select 即\n 在connection phase，将connect_timeout设置为net-\u0026gt;vio-\u0026gt;read_timeout/write_timeout 在command phase，将net_read_timeout设置为net-\u0026gt;vio-\u0026gt;read_timeout，将net_write_timeoutnet-\u0026gt;vio-\u0026gt;write_timeout  其实底层都是搞的select超时，然后通过以下调用链返回\nvio-\u0026gt;read vio_read_buff vio_read mysql_socket_recv vio_socket_io_wait vio_io_wait select vio-\u0026gt;write vio_write mysql_socket_send vio_socket_io_wait vio_io_wait select Protocol_classic::write my_net_write net_write_command net_flush net_write_buff net_write_packet net_write_raw_loop vio-\u0026gt;write 当select超时时，返回-1，然后设置net-\u0026gt;error = 2\n/* On failure, propagate the error code. */ if (count) { /* Socket should be closed. */ net-\u0026gt;error= 2; /* Interrupted by a timeout? */ if (vio_was_timeout(net-\u0026gt;vio)) net-\u0026gt;last_errno= ER_NET_WRITE_INTERRUPTED; else net-\u0026gt;last_errno= ER_NET_ERROR_ON_WRITE; #ifdef MYSQL_SERVER  my_error(net-\u0026gt;last_errno, MYF(0)); #endif  } 判断net-\u0026gt;error是否为非零，非零意味着有错误，然后关闭连接。\n connection phase：close_connection command phase ：end_connection  net_wait_timeout net_interactive_timeout #  在从网络读命令包之前设置net_wait_timeout，然后在读完之后设置为net_read_timeout\nbool do_command(THD *thd) { ... if (classic) { /* This thread will do a blocking read from the client which will be interrupted when the next command is received from the client, the connection is closed or \u0026#34;net_wait_timeout\u0026#34; number of seconds has passed. */ net= thd-\u0026gt;get_protocol_classic()-\u0026gt;get_net(); my_net_set_read_timeout(net, thd-\u0026gt;variables.net_wait_timeout); net_new_transaction(net); } rc= thd-\u0026gt;get_protocol()-\u0026gt;get_command(\u0026amp;com_data, \u0026amp;command); thd-\u0026gt;m_server_idle= false; if (classic) my_net_set_read_timeout(net, thd-\u0026gt;variables.net_read_timeout); return_value= dispatch_command(thd, \u0026amp;com_data, command); ... } lock_wait_timeout #  在获取mdl锁时设置等待时长\nthd-\u0026gt;mdl_context.acquire_locks(\u0026amp;mdl_requests, thd-\u0026gt;variables.lock_wait_timeout) 实践 #  需要调整wait_timeout/interactive_timeout：\n[Warning] Aborted connection 6 to db: 'unconnected' user: 'root' host: 'localhost' (Got timeout reading communication packets) 需要调整net_write_timeout：\n[Warning] Aborted connection 12 to db: 'test' user: 'root' host: 'localhost' (Got timeout writing communication packets) 需要注意的是，MySQL的关于网络的错误，除了超时以外都认为是error，没有做进一步的细分，比如可能会看到下面这种日志，有可能是客户端异常退出了，也有可能是网络链路异常。\n[Warning] Aborted connection 8 to db: 'unconnected' user: 'root' host: 'localhost' (Got an error reading communication packets) [Warning] Aborted connection 13 to db: 'test' user: 'root' host: 'localhost' (Got an error writing communication packets) "},{"id":17,"href":"/docs/MySQL/Server/vio/","title":"Vio","section":"Server","content":"VIO模块 #  为不同的protocol提供network I/O wrapper，类似于winsock。\nVirtual I/O Library.\nThe VIO routines are wrappers for the various network I/O calls that happen with different protocols. The idea is that in the main modules one won\u0026rsquo;t have to write separate bits of code for each protocol. Thus vio\u0026rsquo;s purpose is somewhat like the purpose of Microsoft\u0026rsquo;s winsock library. https://dev.mysql.com/doc/internals/en/vio-directory.html\n SOCKET封装了socket fd，里面只有fd信息。\n目前支持的protocol：\n TCP/IP Unix domain socket Named Pipes（Windows only） Shared Memory（Windows only） Secure Sockets（SSL）  Unix domain socket\n用于实现同一主机上的进程间通信，即使用socket文件来进行通信。socket原本是为网络通讯设计的，但后来在socket的框架上发展出一种IPC机制，就是UNIX domain socket。虽然网络socket也可用于同一台主机的进程间通讯(通过loopback地址127.0.0.1)，但是UNIX domain socket用于IPC 更有效率：不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。\n使用方式：\nsocket(AF_UNIX, \u0026hellip;)\n 文件组织 #  include/violite.h VIO lite（封装了VIO的struct和对外的function） vio_priv.h VIO模块内部头文件 vio.c Declarations + open/close functions viosocket.c Send/retrieve functions viossl.c SSL variations viosslfactories.c Certification / Verification viopipe.c named pipe implemenation（windows only） vioshm.c shared memory implementation（windows only） 文件的层次关系和用途如下图所示：\n设计 #  3.1 I/O事件 #  网络I/O事件分为读、写、连接：\n VIO_IO_EVENT_CONNECT IN VIO_IO_EVENT_READ IN VIO_IO_EVENT_WRITE OUT VIO对象 #  对于建链后的连接，两端都分别分配一个VIO对象，用于描述和处理网络I/O。\nclient和server支持的连接方式和属性：\nclient Unix domain socket VIO_TYPE_SOCKET VIO_LOCALHOST | VIO_BUFFERED_READ TCP/IP VIO_TYPE_TCPIP VIO_BUFFERED_READ Shared Memory VIO_TYPE_SHARED_MEMORY VIO_LOCALHOST Named Pipes VIO_TYPE_NAMEDPIPE VIO_LOCALHOST server Channel_info_local_socket VIO_TYPE_SOCKET VIO_LOCALHOST Channel_info_tcpip_socket VIO_TYPE_TCPIP VIO对象的数据结构\nstruct st_vio { MYSQL_SOCKET mysql_socket; // socket fd (TCP/IP and Unix domain socket)  my_bool localhost; // VIO_LOCALHOST  struct sockaddr_storage local; // local internet address  struct sockaddr_storage remote; // remote internet address  size_t addrLen; // remote address len  enum enum_vio_type type; // protocol type  my_bool inactive; // 连接不再活跃（已关闭）  char desc[VIO_DESCRIPTION_SIZE]; // debug  char *read_buffer; // buffer for vio_read_buff 16k  char *read_pos; // start of unfetched data in the read buffer  char *read_end; // end of unfetched data  int read_timeout; // 读超时  int write_timeout; // 写超时  // 通过vtable interface来对不同协议下的实现进行解耦（多态）  /* viodelete is responsible for cleaning up the VIO object by freeing internal buffers, closing descriptors, handles. */ void (*viodelete)(Vio*); int (*vioerrno)(Vio*); size_t (*read)(Vio*, uchar *, size_t); size_t (*write)(Vio*, const uchar *, size_t); int (*timeout)(Vio*, uint, my_bool); int (*viokeepalive)(Vio*, my_bool); int (*fastsend)(Vio*); my_bool (*peer_addr)(Vio*, char *, uint16*, size_t); void (*in_addr)(Vio*, struct sockaddr_storage*); my_bool (*should_retry)(Vio*); my_bool (*was_timeout)(Vio*); /* vioshutdown is resposnible to shutdown/close the channel, so that no further communications can take place, however any related buffers, descriptors, handles can remain valid after a shutdown. */ int (*vioshutdown)(Vio*); my_bool (*is_connected)(Vio*); my_bool (*has_data) (Vio*); int (*io_wait)(Vio*, enum enum_vio_io_event, int); my_bool (*connect)(Vio*, struct sockaddr *, socklen_t, int); }; VIO对象的创建、初始化和销毁：\n常用函数 #  VIO模块中的常用函数如下：\nint vio_io_wait // 等待网络I/O时间通知（poll/select） vio_read // io读 vio_read_buff // io缓冲读 vio_write // io写 vio_fastsend // 尽可能设为TCP_NODELAY vio_keepalive // 尽可能设置TCP保活 SO_KEEPALIVE vio_timeout // 设置超时 vio_should_retry // 是否需要重试read/write（SOCKET_EINTR） vio_was_timeout // 是否超时（SOCKET_ETIMEDOUT） vio_is_connected // 是否处于连接中，通过vio_io_ait尝试read/write，或者通过socket_peek_read看是否有可读的数据 vio_pending // 获得缓冲区还有多少数据可以读 ioctl(FIONREAD) debug使用 vio_description // 打印socket/TCP信息 vio-\u0026gt;desc debug使用 vio_type // 获得连接的protocol类型 vio_errno // 获取socket error vio_fd // 获得socket fd vio_socket_connect // client发起connect vio_set_blocking // 设置socket fd为阻塞/非阻塞 vio_getnameinfo // 获得socket可读信息 vio_peer_addr // 获得远程socket的可读地址 vio_get_normalized_ip_string // 获得socket可读信息 vio_is_no_name_error // 是否错误为EAI_NONAME - Neither nodename nor servname provided, or not known. 即Name resolution error. Your hostname is invalid. It's not resolving through DNS to any network location. PSI观测 #  MySQL通过PSI机制观测一些关键路径和节点，在处理网络I/O时，其中的观测点是等待网络读写事件。\n入口是\nint vio_io_wait // 等待网络I/O时间通知（poll/select） 通过PSI提供状态的监测。\n宏 1. 定义变量 #define MYSQL_SOCKET_WAIT_VARIABLES(LOCKER, STATE) \\ struct PSI_socket_locker* LOCKER; \\ PSI_socket_locker_state STATE; 2. 进入socket等待 #define MYSQL_START_SOCKET_WAIT(LOCKER, STATE, SOCKET, OP, COUNT) \\ LOCKER= inline_mysql_start_socket_wait(STATE, SOCKET, OP, COUNT,\\ __FILE__, __LINE__) 3. 结束socket等待 #define MYSQL_END_SOCKET_WAIT(LOCKER, COUNT) \\ inline_mysql_end_socket_wait(LOCKER, COUNT) 使用\nMYSQL_SOCKET_WAIT_VARIABLES(locker, state) // 定义socket locker和locker state MYSQL_START_SOCKET_WAIT(locker, \u0026amp;state, vio-\u0026gt;mysql_socket, PSI_SOCKET_SELECT, 0); poll/select... MYSQL_END_SOCKET_WAIT(locker, 0); 其中函数指针的管理如下：\nstart_socket_wait_v1_t start_socket_wait; 在pfs.cc中的PFS_v1注册 pfs_start_socket_wait_v1 end_socket_wait_v1_t end_socket_wait; 在pfs.cc中的PFS_v1注册 pfs_end_socket_wait_v1 参考链接 #  https://dev.mysql.com/doc/internals/en/vio-directory.html\n"},{"id":18,"href":"/menu/","title":"Index","section":"Rick's Blog","content":" MySQL  Server  MySQL启动过程 MySQL的连接和请求处理  THD Protocol  Returning   NET VIO MySQL 8.0 对网络模块的优化 MySQL 8.0 通过Resource Group来控制线程计算资源 MariaDB MaxScale Proxy Protocol   Timeout机制 Thread Pool MDL   InnoDB  概览 源码结构 基本数据结构和算法 os record page      "}]