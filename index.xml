<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rick&#39;s Blog</title>
    <link>https://ayalastrike.github.io/</link>
    <description>Recent content on Rick&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 28 Apr 2014 00:00:00 +0000</lastBuildDate><atom:link href="https://ayalastrike.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hello, world!</title>
      <link>https://ayalastrike.github.io/posts/test/</link>
      <pubDate>Mon, 28 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/posts/test/</guid>
      <description>之前的工作积累都记录在confluence wiki上，慢慢把资料移到这里方便和大家交流。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/about/</guid>
      <description>Email: tianjiawei@gmail.com</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/10.1_mysql5.7.26_lock_issue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/10.1_mysql5.7.26_lock_issue/</guid>
      <description>线上问题 #  在MySQL 5.7.26中，线上遇到如下问题：
在insert时出现大量的用户线程等待，经排查dbproxy查询日志，发现所有的用户线程都在等待这个insert释放锁：
insert into account_m.transaction_bill_493 (transaction_id,transaction_type,business_type,amount,user_id,user_name,user_phone,partner_id,account_type,partner_user_id,partner_user_name,partner_user_phone,partner_partner_id,partner_account_type,product_line,status,create_time,freeze_time,rollback_time,commit_time,refund_time,remark,extra_field, refund_amount,origin_transaction,transaction_desc,order_amount,account_id,sub_type,partner_account_id,partner_sub_type, currency,attach) values (&amp;lsquo;251_202103112460775602597789&amp;rsquo;,3,&#39;&#39;,200,&amp;lsquo;10811426065435&amp;rsquo;,&#39;&#39;,&#39;&#39;,&amp;lsquo;2510000000&amp;rsquo;,4,&amp;lsquo;17593398603669&amp;rsquo;,&#39;&#39;,&#39;&#39;,&#39;&#39;,1,251,3,&amp;lsquo;2021-03-11 12:18:57&amp;rsquo;,&amp;lsquo;1970-01-01 08:00:00&amp;rsquo;,&amp;lsquo;1970-01-01 08:00:00&amp;rsquo;,&amp;lsquo;2021-03-11 12:18:57&amp;rsquo;,&amp;lsquo;1970-01-01 08:00:00&amp;rsquo;,&#39;&#39;,&#39;&#39;, 0,&#39;&#39;,&#39;{&amp;ldquo;title&amp;rdquo;:&amp;quot;&amp;quot;,&amp;ldquo;subTitle&amp;rdquo;:&amp;quot;&amp;quot;}&#39;,0,&amp;lsquo;10000400006810811426065435&amp;rsquo;,100,&amp;lsquo;10000100000017593398603669&amp;rsquo;,100,0,&#39;&#39;)
account_m.transaction_bill_493表结构如下：
CREATE TABLE `transaction_bill_493` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;自增主键&#39;, `transaction_type` tinyint(4) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;交易类型&#39;, `transaction_id` varchar(64) NOT NULL COMMENT &#39;交易ID，外部传入&#39;, `amount` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;金额&#39;, `refund_amount` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;退款金额&#39;, `origin_transaction` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;退款时使用，原始订单，id|type|partner_id&#39;, `user_id` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户ID&#39;, `user_name` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;, `user_phone` varchar(16) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户电话&#39;, `partner_id` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;商户ID&#39;, `account_type` tinyint(3) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;账户类型&#39;, `partner_user_id` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;交易对象ID&#39;, `partner_user_name` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;交易对象姓名&#39;, `partner_user_phone` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;交易对象电话&#39;, `partner_partner_id` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;交易对象商户ID&#39;, `partner_account_type` tinyint(3) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;交易对象类型&#39;, `product_line` smallint(6) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;产品线ID&#39;, `status` tinyint(4) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;状态（1完成；2冻结；3：解冻；）&#39;, `create_time` datetime DEFAULT NULL COMMENT &#39;记录生成时间&#39;, `freeze_time` datetime DEFAULT NULL COMMENT &#39;&amp;gt;冻结时间&#39;, `rollback_time` datetime DEFAULT NULL COMMENT &#39;解冻时间&#39;, `commit_time` datetime DEFAULT NULL COMMENT &#39;扣款时间&#39;, `refund_time` datetime DEFAULT NULL COMMENT &#39;退款时间&#39;, `remark` varchar(2048) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;备注&#39;, `extra_field` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;扩展字段&#39;, `transaction_desc` varchar(256) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;交易描述&#39;, `order_amount` bigint(20) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;订单金额分&#39;, `account_id` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;è´¦æˆ- ID&#39;, `sub_type` int(11) NOT NULL DEFAULT &#39;100&#39; COMMENT &#39;账户类型，默认是可用资金账户类型&#39;, `partner_account_id` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;partner账户ID&#39;, `partner_sub_type` int(11) NOT NULL DEFAULT &#39;100&#39; COMMENT &#39;partner账户类型，默认是可用资金账户类型&#39;, `out_order_id` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;外部订单ID&#39;, `bank_card` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;银行卡号&#39;, `business_type` varchar(32) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;业务类型&#39;, `currency` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;币种&#39;, `attach` varchar(2048) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL DEFAULT &#39;&#39; COMMENT &#39;扩展字段, 存储业务透传信息&#39;, PRIMARY KEY (`id`), UNIQUE KEY `uk_transid_accountid` (`transaction_id`,`account_id`), KEY `idx_user_id` (`user_id`), KEY `idx_create_time` (`create_time`), KEY `idx_status_freeze_time` (`status`,`freeze_time`), KEY `idx_status_commit_time` (`status`,`commit_time`), KEY `idx_freeze_time` (`freeze_time`), KEY `idx_accountid` (`account_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#39;交易单表&#39; 事后经过复盘，线上当时发生问题时，业务显式开启事务后，由于业务代码出现夯死没有发送commit，从而导致该insert事务一直持有锁而出现大量的用户线程等待。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/2_source/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/2_source/</guid>
      <description>在MySQL源代码中，每个模块都有自己单独的目录存放，里面按照模块名0子模块名.cc来组织。所有头文件都放在include目录下，同时include目录下还有*.ic的文件，这个文件中存放定义的内联函数。
如果要在*.ic中使用宏UNIV_INLINE定义内联，需要#include &amp;ldquo;univ.i&amp;rdquo;，即
#include &amp;#34;univ.i&amp;#34;UNIV_INLINE return_value function foo(param1, ...) ``// 函数声明或实现 { ``... } 注意，这种风格只是适用于c函数，对于ic文件中的类成员函数定义，还是需要手动写inline  univ.i中UNIV_INLINE的宏定义
#ifndef UNIV_MUST_NOT_INLINE /* Definition for inline version */ #define UNIV_INLINE static inline #else /* !UNIV_MUST_NOT_INLINE *//* If we want to compile a noninlined version we use the following macro definitions: */ #define UNIV_NONINL #define UNIV_INLINE #endif /* !UNIV_MUST_NOT_INLINE */阅读源码层次
推荐从下至上进行逐层阅读
最下一层是基础管理模块：
 File Manager主要封装了InnoDB对于文件的各类操作，如读、写、异步I/O等。 Concurrency Manager模块主要封装了引擎内部使用的各类mutex和latch。 Common Utility模块用于一些基本数据结构与算法的定义，如链表、哈希表等。  图中间虚线标注的部分为InnoDB的内核实现，也就是InnoDB存储引擎中的事务、锁、缓冲区、日志、存储管理、资源管理、索引、change buffer模块，这部分是整个存储引擎的核心。
图最上面的两层是接口层，通过这些接口实现server层与存储引擎的交互。InnoDB存储引擎可以不依赖MySQL数据库，而作为一个嵌入式数据库存在，因此还存在嵌入式的API接口。
代码风格 #  InnoDB的代码缩进风格更接近于K&amp;amp;R风格：所有的非函数语句块（if、switch、for、while、do），起始大括号放在行尾，而把结束大括号放在行首。函数开头的左花括号放到最左边。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/8.0_net_optimize/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/8.0_net_optimize/</guid>
      <description>（转载自阿里内核月报）
Administrative Connection Management #  如果MySQL连接连接被打满，有时甚至连root也无法登录去kill。
对于这个问题，目前已有的解法有：
 各家的线程池提供了extra_port。 Alibaba RDS MySQL的做法是把connection的个数拆分成不同的使用目的，例如系统维护账户占用一部分，用户账户占用一部分，两者不互相影响。  MySQL 8.0提供了administrative-connection-interface的机制（由facebook贡献），即提供单独的network interface并且可以单独配置一个pthread用于listen。
参数如下：
 admin_address admin_port create_admin_listener_thread：是否创建一个单独的listener线程来监听admin的链接请求（默认OFF，建议打开）  worklog：WL#12138: Add Admin Port
代码
Multiple addresses for the –bind-address #  bind-address支持绑定多个网络地址。比如：
// The server listens on the 198.51.100.20 IPv4 address and the 2001:db8:0:f101::1 IPv6 address. bind_address=198.51.100.20,2001:db8:0:f101::1 worklog：WL#11652: Support multiple addresses for the &amp;ndash;bind-address command option
代码
connect/disconnect performance #  目前MySQL里是使用一个全局大锁（LOCK_thd_list、LOCK_thd_remove）来保护thd_list。
优化的思路其实很简单直接：分区，将LOCK_thd_list、LOCK_thd_remove根据thread id来分成8个分区（hardcode）来减少冲突，负面影响就是PS的监控数据需要聚合。
worklog：WL#9250: Split LOCK_thd_list and LOCK_thd_remove mutexes</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/8.0_resource_group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/8.0_resource_group/</guid>
      <description>（转载自阿里内核月报）
ＭySQL8.0增加了一个新功能resource group，可以对不同的用户进行资源控制，例如对用户线程和后台系统线程给予不同的CPU优先级。
用户可以通过SQL接口创建不同的分组，这些分组可以作为sql的hit，也可以动态的绑定过去。本文主要简单介绍下用法，至于底层如何实现的，其实比较简单：创建的分组被存储到系统表中；在linux系统底层通过CPU_SET来绑定CPU，通过setpriority来设置线程的nice值
worklog: WL#9467: Resource Groups
创建resource group #  系统自带两个resource group（不可修改）：
 FOREGROUND (FG) - &amp;ldquo;user&amp;rdquo; threads BACKGROUND (BG) - &amp;ldquo;system&amp;rdquo; threads (internal Engine threads, e.g. &amp;ldquo;purge&amp;quot;in InnoDB, etc.)  mysql&amp;gt; SELECT * FROM INFORMATION_SCHEMA.RESOURCE_GROUPS\G *************************** 1. row *************************** RESOURCE_GROUP_NAME: USR_default RESOURCE_GROUP_TYPE: USER RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 *************************** 2. row *************************** RESOURCE_GROUP_NAME: SYS_default RESOURCE_GROUP_TYPE: SYSTEM RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 2 rows in set (0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/connection_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/connection_handler/</guid>
      <description>概述 #  在MySQL中，对于client发来的请求，其处理流程分为建链和请求处理两部分，这两个阶段分别称为connection phase和command phase。
MySQL的server-client protocol交互如下：
从上图中可以看出，connection phase负责连接的建立，而日常的query处理，则称为command phase，command phase的结束，以COM_QUIT query的到来作为标志。
一般典型的交互过程是connect，query，query，query&amp;hellip; quit，其中query可以是dml、ddl、multi-statement或是prepared statement。
下面我们先看一下connection phase。
建链 #  connection phase用于在client-server间建立连接，而建链分为TCP建链和应用建链。
TCP建链是指TCP socket的listen、accept。
应用建链是在TCP建链的基础上，通过应用层协议进行认证：server发送handshake（initial handshake）、客户端回username/pwd（handshake response），server回应是否通过认证（OK/Error）。
我们接下来首先看一下connection phase，即在MySQL中如何处理TCP建链和应用建链的。
TCP建链 #  TCP连接处理分为两步：
 初始化，创建conn_mgr和conn_handler，acceptor和listener 监听建链，由acceptor+listener负责 对已建链连接进行线程分发处理，由conn_mgr+conn_handler负责  整体流程如下图所示：
代码实现
mysqld_main init_common_variables Connection_handler_manager::init() // 初始化conn_mgr和conn_handler  network_init()	// 初始化网络 	set_ports();	// 设置port  // 初始化acceptor、listener 	Mysqld_socket_listener *mysqld_socket_listener= new (std::nothrow) Mysqld_socket_listener(bind_addr_str, mysqld_port, back_log, mysqld_port_timeout, unix_sock_name); Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt; *mysqld_socket_acceptor= new (std::nothrow) Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt;(mysqld_socket_listener); mysqld_socket_acceptor-&amp;gt;init_connection_acceptor(); .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/invisible_index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/invisible_index/</guid>
      <description>是否使用索引对性能影响很大。在数据库运维过程中，索引的删除总是慎重的，一方面是因为实际的DDL变更代价，一方面是评估对性能的影响。
为了减少删除索引的代价，MySQL 8.0引入了invisible index，用于解决这个问题。
即在索引上增加一个invisible的属性，用于optimizer可以将其忽略掉。
从这里也可以看到，引入的带动在server层，不涉及到存储引擎，所以所有的存储引擎都适用。
MySQL的实现基本参考的是Oracle 12c。
MySQL 8.0.0 Release Notes
 Optimizer Notes  MySQL now supports invisible indexes. An invisible index is not used by the optimizer at all, but is otherwise maintained normally. Indexes are visible by default. Invisible indexes make it possible to test the effect of removing an index on query performance, without making a destructive change that must be undone should the index turn out to be required.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/io_cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/io_cache/</guid>
      <description>设计理念：
 对于碎片化的IO会减少实际文件IO读写 写缓冲：对于写，可以合并IO操作，并在写缓冲满时自动调用write写入文件 读缓冲：对于读，多余读出来的数据可以给下次读使用 对于文件设备支持字符设备和块设备 支持多种IO模式，比如缓冲IO/direct IO/aio 对文件操作进行了抽象：4k对齐（按照块粒度读取IO效率最高），缓冲封装在文件操作内部  IO_CACHE初始化
// 1. seek 如果文件不支持seek，则seek_offset要求为0 // 2. 设置最小对齐块min_cache（16k/8k） // 3. 缩小cachesize：READ_CACHE/SEQ_READ_APPEND下，如果读取范围足够小，则重置cachesize为该范围，并关闭aio // 4. cachesize按照min_cache对齐，如果为SEQ_READ_APPEND，则申请2块，malloc如果失败则缩小3/4重试(128k-&amp;gt;96k)，少于等于min_cache则报错返回  int init_io_cache_ext(IO_CACHE *info, File file, size_t cachesize, enum cache_type type, my_off_t seek_offset, pbool use_async_io, myf cache_myflags, PSI_file_key file_key) { size_t min_cache; my_off_t pos; my_off_t end_of_file= ~(my_off_t) 0; info-&amp;gt;file= file; info-&amp;gt;file_key= file_key; info-&amp;gt;type= TYPE_NOT_SET; // 直到创建append_buffer_lock后才设置type  info-&amp;gt;pos_in_file= seek_offset; info-&amp;gt;pre_close = info-&amp;gt;pre_read = info-&amp;gt;post_read = 0; info-&amp;gt;arg = 0; info-&amp;gt;alloced_buffer = 0; info-&amp;gt;buffer=0; info-&amp;gt;seek_not_done= 0; if (file &amp;gt;= 0) { pos= mysql_file_tell(file, MYF(0)); // 定位文件位置  if ((pos == (my_off_t) -1) &amp;amp;&amp;amp; (my_errno() == ESPIPE)) // 文件不支持seek，再试一次，如果还不行就失败，这种情况下传入的seek_offset要求为0  { info-&amp;gt;seek_not_done= 0; DBUG_ASSERT(seek_offset == 0); } else info-&amp;gt;seek_not_done= MY_TEST(seek_offset !</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/kill_idle_transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/kill_idle_transaction/</guid>
      <description>1. 背景 #  我们在线上遇到5.7.26的锁问题，需要解决idle事务长时间挂起的问题。同时也调研了现有的mysql timeout机制，以确保其和现有的timeout机制可以吻合。
Percona从5.1.59-13.0引入了innodb_kill_idle_transaction，用于解决长事务场景，即对idle事务设定一个超时时间，对超过该时间的事务所在的用户连接进行断开。
引入该参数也可以防止purge线程的长时间阻塞（长事务会一直保持在活跃状态，则会导致purge长时间的等待，从而导致undo无法清理从而造成磁盘空间的不断增加）。
在实现上，开始是通过扫描InnoDB事务列表来进行判断的，在Percona Server 5.6.35-80.0则改为判断connection socket read timeout。这样优化的好处是，巡检可能会造成CPU空跑，而基于socket select超时则发生超时才会触发，使代码的运行更有效率。
另外，percona现在提供了两个参数：innodb_kill_idle_transaction（后者的alias，5.7中已标记为deprecated）和kill_idle_transaction。我们在port时只保留kill_idle_transaction。
2. 设计 #  复用net_wait_timeout：
 处于事务中（SERVER_STATUS_IN_TRANS）&amp;amp; min(kill_idle_transaction, net_wait_timeout) 其他场景还是返回net_wait_timeout  kill_idle_transaction配置项
   配置项 默认值 值范围     kill_idle_transaction 0（不开启） 0 ~ 1 year    3. 示例 #  1. 验证idle事务的连接会自动kill掉 mysql&amp;gt; show global variables like &#39;%idle%&#39;; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | kill_idle_transaction | 10 | +-----------------------+-------+ mysql&amp;gt; begin; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/log/</guid>
      <description>日志 #  MySQL server层日志有：
 general log slow log error log  日志的存储方式（log_output）有：
 文件 表  所有日志的配置参数如下：
log_output general log，slow log存放在何处（文件/表） log_timestamps general log, slow log, error log写入文件中的时间戳所用时区（UTC/SYSTEM），写入日志表中的不在此列。 general_log 是否开启general log sql_log_off 当前session是否关闭general log general_log_file general log文件名 slow_query_log 是否开启slow log slow_query_log_file slow log文件名 long_query_time slow query的判断时间（秒） log_queries_not_using_indexes 是否记录没有使用index的query log_throttle_queries_not_using_indexes log_queries_not_using_indexes配额（每分钟） log_slow_admin_statements 是否记录慢管理语句（ALTER TABLE, ANALYZE TABLE, CHECK TABLE, CREATE INDEX, DROP INDEX, OPTIMIZE TABLE, and REPAIR TABLE） log_error error log文件名 log_error_verbosity error, warning, and note messages log_warnings deprecated，用log_error_verbosity替代 log_syslog log_syslog_facility log_syslog_include_pid log_syslog_tag log-slow-slave-statements 记录从库上回放时的慢SQL（SBR/MIXED） mysqld startup options --log-isam[=file_name] 记录所有MyISAM的变化（debug） --log-raw 记录query rewrite plugin改写前的SQL 日志实现机制 #  general log和slow log #  实现 #  如下图所示：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/lower_case_table_names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/lower_case_table_names/</guid>
      <description>在MySQL中，表是和操作系统中的文件对应的，而文件名在有的操作系统下是区分大小写的（比如linux），有的是不区分大小写（比如Windows），表名与文件名的大小写对应关系，MySQL 是通过lower_case_table_names这个变量来控制的。
这个变量的有效取值是0，1，2，按照官方文档 的解释：
 0：表在文件系统存储的时候，对应的文件名是按建表时指定的大小写存的，MySQL 内部对表名的比较也是区分大小写的 1：表在文件系统存储的时候，对应的文件名都小写的，MySQL 内部对表名的比较是转成小写的，即不区分大小写 2：表在文件系统存储的时候，对应的文件名是按建表时指定的大小写存的，但是 MySQL 内部对表名的比较是转成小写的，即不区分大小写  0适用于区分大小写的系统，1都适用，2适用于不区分大小写的系统。
如果在开始使用MySQL选定了一个合适的值后，就不要改变，不然的话在之后使用中就会出现问题。
MGR用因为要根据db+table+pk生成write_set，还有一个bug fix。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/mariadb_maxscale_proxy_protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/mariadb_maxscale_proxy_protocol/</guid>
      <description>（转载自阿里内核月报）
MariaDB MaxScale 是一款数据库中间件，可以按照语义分发语句到多个数据库服务器上。它对应用程序透明，可以提供读写分离、负载均衡和高可用服务。
proxy protocol 是 MaxScale 引入，为了解决使用proxy作为中间件连接mysql时，mysql获取client ip用 client通过proxy中间价连接mysql时，mysql server接收到认证报文中，包含的是proxy节点的IP。如果mysql.user表中指定了client的IP，无法通过认证。
一种传统处理方式是在proxy节点上保存client的ip和密码，用于client的认证，而在mysql server上使用另一套ip和密码用于proxy 节点到mysql server的认证。
MariaDB MaxScale引入了proxy protocol来解决client ip透传的问题。proxy节点获取到client ip后，把client ip包装在proxy protocol报文中发给server，server解析到了proxy protocol报文，再用报文中的ip替换proxy节点的ip
因为 proxy protocol 本身不包含鉴权，同时可能影响数据库的鉴权行为，所以在数据库 server 端设置了一个ip白名单，只有白名单ip发送的 proxy protocol 报文才会被接受。
报文格式 #  proxy protocol 有两个版本 v1 和 v2 通过报文签名区分
v1 #  v1 报文是字符串形式 “PROXY %s %s %s %d %d”
   字段 内容     签名 PROXY   %s.1 address family   %s.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/mdl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/mdl/</guid>
      <description>历史 #  为了解这个著名的bug#989：
DML和DDL如果并发执行，binlog序错乱：主库并发执行了DDL（T → T&#39;）和DML（T’），但是提交到了binlog中顺序是DDL+DML，这样在从库上回放时，先执行DDL，后执行DML，但此时表结构已经变为T‘，DML执行失败  因此，在MySQL 5.5中，引入了MDL（Meta Data Lock）来控制DDL和DML的并发，保证元数据的一致性。
设计思理：
 WL#3726：DDL locking for all metadata objects WL#4284：Transactional DDL locking  谈到MDL，需要先谈谈MySQL的锁定机制设计以及thr_lock
MySQL locking #  为了保证数据的一致性和完整性，数据库系统普遍存在封锁机制，而封锁机制的优劣直接关系到数据库系统的并发处理能力和性能，所以封锁机制的实现也成为了各种数据库的核心技术之一。
MySQL的封锁机制有三种：
 row-level locking：InnoDB、NDB Cluster table-level locking：MyISAM、MEMORY、MERGE、CSV等非事务存储引擎 page-level locking：BerkeleyDB  MySQL采用如此多样的封锁机制是由其产品定位和发展历史共同决定的。首先，MySQL的产品定位是通过plugin机制可以接入多个存储引擎。在早期的存储引擎（MyISAM和MEMORY）设计中，设计原则建立在&amp;quot;任何表在同一时刻都只允许单个线程（无论读写）对其访问&amp;quot;之上。随后，MySQL3.23修正了之前的假设：MyISAM支持Concurrent Insert：如果没有hole，可以多个读线程并发读同一张表，同时多个写线程以队列的形式进行尾部insert。之后，BerkeleyDB和InnoDB的引入也挑战了之前的设计假设，要求page-level、和row-level locking。此时，之前的设计方式已经和存储引擎所提供的能力不相衬了。因此MySQL做出了改变，允许存储引擎自己改变MySQL 通过接口传入的锁定类型（也就是上面的3种）而自行决定该怎样封锁数据。
MySQL加锁的顺序
SQL → open table → 加MDL锁 → 加表锁 → 加InnoDB锁 → SQL执行 → 释放MDL锁 → 释放表锁 → 释放InnoDB锁
其中表锁是通过thr_lock提供的，在MySQL 5.7.5中，thr_lock被MDL替换：
Scalability for InnoDB tables was improved by avoiding THR_LOCK locks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/memory/</guid>
      <description>在MySQL中，为了高效，Server层也有自己的内存管理。
首先先介绍最简单的单链表内存管理，然后再介绍基于此优化的MEM_ROOT内存管理。
单链表内存管理 #  在server层中，对于字符集处理，使用单链表的内存管理来处理内存资源。
正如Monty在comments中写的：
Wed Jun 21 01:34:04 1989 Monty (monty at monty)
** Added two new malloc-functions: my_once_alloc() and* *my_once_free(). These give easyer and quicker startup.*
 分配内存、释放全部内存由my_once_alloc、my_once_free负责，my_once_strdup和my_once_memdup则是wrapper，内部封装了alloc+memcpy。
alloc策略如下：
 采用单向链表的方式将多个malloc的内存块管理起来 每个内存块采用malloc_chunk + raw的方式，即内存控制块+实际数据使用块两部分 raw部分如果剩余可用，则直接从其中划分，减少malloc开销 如果申请量小且现有的left小于4k，则对齐到4k  从这里可以看出，#3，#4一方面可以减少malloc的系统调用次数和碎片，同时，尽量按照4k对齐申请。
另外，可以通过my_flags设定分配属性：
 MY_FAE /* Fatal if any error */ 内存分配失败就退出整个进程 MY_WME /* Write message on error */ 记录到日志中 MY_ZEROFILL /* Fill array with zero */ 分配内存后初始化为0  相关代码和示例如下：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/net/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/net/</guid>
      <description>MySQL packet的结构如下：
packet length (3 bytes) // 数据
packet number (1 byte) // 保序
compression length (3 bytes) optional // 压缩
compression packet number （1 byte） optional // 保序
packet data
 因为采用3个字节存储包的长度，所以支持的包最大为 MAX_PACKET_LENGTH (256L256L256L-1)。如果数据流超过包最大值（16M），则通过packet number（ne→pkt_nr）保序。
发包 #  my_net_write #  发包，Write a logical packet with packet header.
net_write_buff #  发送缓冲区，Caching the data in a local buffer before sending it.
每个Net对象有一个buffer(net-&amp;gt;buff)，即将发送的数据被拷贝到这个buffer中。如果buffer未满则进行memcpy，并更新写入点位（net-&amp;gt;write_pos）；满了当Buffer满时需要立刻发出到客户端（net_write_packet）。
net_write_packet #  socket写数据，Write a MySQL protocol packet to the network handler.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/protocol/</guid>
      <description>MySQL client-server protocol：https://dev.mysql.com/doc/internals/en/client-server-protocol.html
MySQL 5.7重构了Protocol模块
我们在这里主要聚焦在command phase，即MySQL server和client如何处理query的交互。
我们从MySQL协议可以知道，在query的交互上，一般采用ping-pong模型，即：
 client-&amp;gt;server：发query server-&amp;gt;client：回包  所以我们在下面详细拆解这两个阶段。
读取query #  当client发送一条query后，server对query进行以下处理：
 读包 解析包体 根据命令指派执行  数据报文包括包头+包体，包头已在读包内部验证后丢弃（read_packet），然后包体返回给Protocol_classic::get_command封装为raw_packet。从raw_packet[0]中判断query的命令号，进行报文解析（parse_packet），拆解为COM_DATA（根据命令号封装了不同的struct）。
do_command // conn_handler Protocol_classic::get_command // 读包 Protocol_classic::read_packet my_net_read // 处理多包、压缩包 net_read_packet // 将读到的数据填充到NET中 Protocol_classic::parse_packet // 解析包体 dispatch_command // 根据命令指派执行 回包 #  返回的报文类型有：OK Packet，Error Packet和结果集包（Data Packet，EOF Packet）。
OK Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_ok // 回OK包 Error Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_error // 回错误包 结果集包 #  结果集包的结构如下:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/read_only/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/read_only/</guid>
      <description>MySQL通过5个步骤来设置read_only：
 获取global read lock，阻塞所有的写入请求 flush opened table cache，阻塞所有的显式读写锁 获取commit lock，阻塞commit写入binlog 设置read_only=1 释放global read lock和commit lock  设置read_only阻塞用户写入，但只能阻塞普通用户的更新，MySQL为了最大可能的保护数据一致性，增强了read_only功能，通过设置super read only，阻塞除了slave线程以外以为的所有用户的写入，包括super用户。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/returning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/returning/</guid>
      <description>（转载自阿里内核月报）
背景 #  MySQL对于statement执行结果报文通常分为两类：Resultset和OK/ERR，针对 DML语句则返回OK/ERR报文，其中包括几个影响记录，扫描记录等属性。但在很多业务场景下，通常 INSERT/UPDATE/DELETE 这样的DML语句后，都会跟随SELECT查询当前记录内容，以进行接下来的业务处理， 为了减少一次 Client &amp;lt;-&amp;gt; DB Server 交互，类似 PostgreSQL / Oracle 都提供了 returning clause 支持 DML 返回 Resultset。
AliSQL 为了减少对 MySQL 语法兼容性的侵入，并支持 returning 功能， 采用了 native procedure 的方式，使用DBMS_TRANS package，统一使用 returning procedure 来支持 DML 语句返回 Resultset。
语法 #  DBMS_TRANS.returning(Field_list=&amp;gt;, Statement=&amp;gt;); 其中:
 Field list : 代表期望的返回字段，以 “,” 进行分割，支持 * 号表达； Statement ：表示要执行的DML 语句， 支持 INSERT / UPDATE / DELETE；  INSERT Returning #  针对 insert 语句， returning proc 返回插入到表中的记录内容；</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/signal_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/signal_handler/</guid>
      <description>引出问题 #  在之前MySQL发版测试后，QA发现一个问题，用mysql.server stop脚本无法使mysqld进程退出，只会无限等待。
通过查看mysql.server脚本，发现使用stop选项时执行了如下操作：
 检查mysql/var/mysql.pid文件是否存在，若不存在说明mysqld进程未启动；若存在，读出文件中记录的mysqld进程号pid； 发送kill -0 pid，检查是否真的存在进程号为pid的进程。若进程不存在则无需stop，直接删除mysql/var/mysql.pid文件； 若pid进程存在，发送kill pid（即kill -15 pid），随后循环等待直到mysql/var/mysql.pid文件被删除（意味着mysqld已经退出）。  由此逻辑可知，mysql.server stop脚本无限等待大概率是因为第3步发送kill pid后，mysqld并未走退出流程，mysql/var/mysql.pid迟迟不被删所致。通过观察mysql/log/mysql.err文件中的日志，发现执行mysql.server stop后只有这么一条记录：
Got signal 15 from thread 0Got signal 15 from thread 0 说明mysqld进程确实有收到SIGTERM信号，但是并未发起shutdown流程，因此需要了解Linux信号处理机制及MySQL中信号处理逻辑才好判断是哪里出了问题。
Linux信号处理机制 #  在Linux系统中，我们可以通过kill -信号名 进程ID的方式向指定进程发送各种信号。比如常用的kill pid其实等价于kill -15 pid，会向pid进程发送SIGTERM信号；在一个shell前台程序运行中按Ctrl+C，等价于kill -2 pid，会向pid进程发送SIGINT信号；而kill -9 pid则会向pid进程发送SIGKILL信号。
当进程收到信号时如何处理？通常有几种处理方式：
 默认：如果不自定义处理函数，则每个信号都有默认的处理方式。很多信号的默认处理方式都是进程中断+直接退出，极其暴力，这是我们不希望的，因此经常针对某些信号设置自定义处理函数； 捕获：利用signal函数或sigaction函数可以注册用户自定义的信号处理函数（进程级生效）。比如在程序中使用signal(SIGINT, handle_shutdown)，可以注册进程收到SIGINT信号时调用用户自定义函数handle_shutdown，然后用户就可以在此函数中实现一些优雅退出的代码，比如保存工作进度、打印日志等等，不至于退出得过于暴力。需要注意的是，并不是所有信号都允许被捕获并进入自定义处理函数，比如SIGKILL（kill -9）就不允许； 忽略：将某信号的回调函数设置为SIG_IGN(ignore)。进程收到此信号后直接丢弃，不作任何处理。一般涉及网络通信的服务端程序至少都会忽略坑爹信号SIGPIPE（当试图向对方发送数据时发现对方已断连就会触发，默认处理方式是进程退出，极其坑爹……）。需要注意的是，并不是所有信号都允许被忽略，比如SIGKILL（kill -9）就不允许； 屏蔽：通过pthread_sigmask函数可以针对某一线程设置一个信号屏蔽集合，比如选择屏蔽SIGTERM，那么该线程在收到此信号是只是将信号丢入一个pending队列，并不做处理。在此要强调，屏蔽和忽略是有区别的，忽略是直接将信号丢弃，而屏蔽是可以通过pthread_sigmask函数解除的，当解除以后pending队列里的信号就会再次弹出。每个线程可以设置不同的屏蔽规则，但是线程创建时默认继承父线程的屏蔽规则。  在多线程程序中，向进程发送的信号除硬件故障导致的信号外，是可能被随机转发到任何一个线程的。不仅如此，连续发送多个信号，可能在多个子线程中被并发触发，这使得信号处理逻辑变得异常复杂。试想一下，假如我们在进程中对SIGTERM信号注册了优雅退出的处理函数，当用户对进程执行了kill命令，你的线程1捕获到SIGTERM正在优雅退出时，用户等得不耐烦又发了一遍kill命令，此时线程2就有可能捕获到SIGTERM，和线程1并发进行退出，这可能会导致各种非预期行为发生。
因此，**大部分多线程程序常用的信号处理模式是使用单独的信号处理线程，将可能在多个线程中并发出现的信号，转化为只在信号处理线程中排队依次出现，同步处理。**具体实现方式为：对于程序中绝大多数不关注信号的线程，都通过设置信号屏蔽规则在整个线程生命周期中将某些信号屏蔽；建立一个单独的信号处理线程，用一个无限循环调用sigwait函数等待所有关注的信号，阻塞式等待在别的线程“碰壁”后被加入pending队列的信号，每次取出一个信号，进行对应处理，再调用sigwait取下一个信号。这样就将多线程异步信号转为了单线程同步处理，使编写多线程程序的信号处理逻辑变得非常简单。当采用单独的信号处理线程后，不管哪个线程收到SIGTERM，都会在信号处理线程的sigwait函数中返回，这样同时就只可能由信号处理线程执行优雅退出，此时就算向进程发送别的信号，只要信号处理线程不将前一个信号处理完后再次调用sigwait，都是感知不到的。在下文中我们看到，MySQL正是使用了这种单独信号处理线程的模式。
MySQL信号处理逻辑 #  在sql/mysqld.cc的主入口函数mysqld_main中靠前的位置，我们可以找到设置MySQL信号处理规则的函数my_init_signals：
// sql/mysqld.cc mysqld_main() if (init_common_variables()) unireg_abort(MYSQLD_ABORT_EXIT); // Will do exit  my_init_signals(); 在my_init_signals函数中首先设置了进程级的信号处理规则：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/startup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/startup/</guid>
      <description>MySQL启动过程
main() // 入口 sql/main.cc mysqld_main() // sql/mysqld.cc // 记录入参 my_progname = argv[0]; orig_argc = argc; orig_argv = argv; // 处理配置文件my.cnf及启动参数 load_defaults(MYSQL_CONFIG_NAME, load_default_groups, &amp;amp;argc, &amp;amp;argv, &amp;amp;argv_alloc); // 继续处理启动参数，为初始化系统表做准备 sys_var::m_parse_flag == PARSE_EARLY handle_early_options(); // 为status统计计数做准备 init_sql_statement_names(); // 初始化system variables哈希表,链表sys_var_chain sys_var,遍历链表后,加入到system_variable_hash哈希表 // sys_var_chain链表已经通过sys_vars.cc的sys_var()构造函数static初始化 sys_var_init(); // 计算打开文件数并初始化table cache adjust_related_options(&amp;amp;requested_open_files); // init error log global variables init_error_log(); // init audit global variables mysql_audit_initialize(); // 初始化query log和slow log query_logger.init(); // 初始化system variables init_common_variables(); default_storage_engine= const_cast&amp;lt;char *&amp;gt;(&amp;quot;InnoDB&amp;quot;); // 设置默认storage engine add_status_vars(status_vars); // 初始化status变量(show status), status_vars为全局变量 set_server_version(); get_options(&amp;amp;remaining_argc, &amp;amp;remaining_argv); // sys_var::m_parse_flag == PARSE_NORMAL // 设置thread_cache_size init_client_errs(); // 读出给client返回出错信息的文件 lex_init(); // 初始化词法分析 item_create_init(); // 初始化函数列表 func_array为全局变量 // 设置默认字符集和校验字符集 global_system_variables.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/thd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/thd/</guid>
      <description>THD对象 #  THD封装了线程相关的数据，可以视作一个处理单元。
The size of the THD is ~10K and its definition is found in sql_class.h.
The THD is a large data structure which is used to keep track of various aspects of execution state. Memory rooted in the THD will grow significantly during query execution, but exactly how much it grows will depend upon the query. For memory planning purposes we recommend to plan for ~10MB per connection on average.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/ThreadPool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/ThreadPool/</guid>
      <description>背景 #  高并发场景 #  在高并发场景（访问共享资源）下，随着用户（并发）的增加，有以下两个挑战：
  latency在后期成指数型增长  吞吐下降严重
  造成这种现象的根本原因是通信、处理和同步成本大幅升高，最终达到处理极限，导致数据库的服务能力大幅下降，甚至无法响应请求。
为了处理这种情况，有两种思路：
  在系统达到预设性能指标时，采用管制措施保护数据库，使之可以持续提供稳定的服务。 这种方式称之为限流（aka “on-ramp metering”），由交通信号灯来控制多少车辆可以在峰值时通过。如下图所示：
  另一种方式是线程池机制，减少内部的线程上下文切换开销、热点资源的竞争，提升CPU上有效代码的执行效率，同时也具备控制流量的能力。
  我们最终期望实现的效果是：技术选型 #  MySQL的处理模型 #  现有的MySQL的请求处理架构采用的是单进程多线程方案，每个用户连接对应一个MySQL处理线程（后面称为工作线程），在这种情况下，随着用户连接数的增多，MySQL进程会创建大量的工作线程，系统性能在高并发场景下会有大幅的下降。
而导致性能下降主要是这三个原因造成的：
 CPU cache miss 线程的上下文切换 热点共享资源的竞争（latch、锁&amp;hellip;）  采用线程池，则可以有针对性的对上述三点进行优化：将MySQL的工作线程和用户连接解绑，同一个工作线程应对多个用户连接上的请求：当前的用户请求处理完成后，工作线程再选择其他的用户请求进行处理。保证合理数量的工作线程提供可持续的处理能力，并且CPU cache的使用更高效，可以有效的降低线程的上下文切换代价，同时热点资源竞争的开销也随之降低，也降低了死锁发生的概率。
线程池机制更加适用于OLTP场景（short CPU-bound queries），对于OLAP场景可能会产生护航（convey）问题。
从某种程度上来看，线程池分离了连接资源（请求）和线程资源（处理）。
不适用场景 #  线程池并不是万能的，对于以下几类场景并不适用：
 间歇性的workload：这会导致不断的分配/回收线程资源。 OLTP大查询：大量并发、长时间的复杂查询，如果占满了所有处理线程，后续的请求会进行排队，造成latency的增加。 大量的消耗极小的简单查询：比如select 1，大量瞬间涌入的请求，如果进行排队可能也会造成latency的增加。 极高并发的prepared statement：prepared statement所使用的MySQL Binary Protocol会使交互往返多次，可能会造成请求的堆积。  效果 #  线程池的性能对比，这里参考官方给出的性能数据：
60x Better Scalability: Read/Write (8192/128)</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/timeout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/timeout/</guid>
      <description>背景 #  在分布式环境下，异步网络是一个挑战，当遇到网络问题时，提供超时机制可以提升系统的可用性。并且，对于事务系统，锁机制也需要超时机制来保证资源可以在有限时间内释放，避免饥饿现象的产生。
为此，MySQL在多种场景下提供了timeout机制。
简单一句话，MySQL Protocol ping-pong模型各个节点都有超时检测  MySQL timeout配置 #  MySQL内有多种timeout，我们先看一下有多少：
mysql&amp;gt; show global variables like &#39;%timeout%&#39;; +-----------------------------+----------+ | Variable_name | Value | +-----------------------------+----------+ | connect_timeout | 5 | | net_read_timeout | 30 | | net_write_timeout | 60 | | wait_timeout | 28800 | | interactive_timeout | 28800 | | lock_wait_timeout | 31536000 | | innodb_lock_wait_timeout | 3 | | innodb_rollback_on_timeout | OFF | +-----------------------------+----------+ 通过阅读官方文档，结合我们在下面对于timeout实现的论证，这里先放上结论：
网络超时</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/user_connection_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/user_connection_handler/</guid>
      <description>（转载自阿里内核月报）
建立连接过程 #  MySQL建立连接过程如下
// 初始化网络 network_init() set_ports(); // 设置port  Mysqld_socket_listener *mysqld_socket_listener= new (std::nothrow) Mysqld_socket_listener(bind_addr_str, mysqld_port, back_log, mysqld_port_timeout, unix_sock_name); Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt; *mysqld_socket_acceptor= new (std::nothrow) Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt;(mysqld_socket_listener); mysqld_socket_acceptor-&amp;gt;init_connection_acceptor(); ... // 监听socket事件 mysqld_socket_acceptor-&amp;gt;connection_event_loop() { Connection_handler_manager *mgr= Connection_handler_manager::get_instance(); while (!abort_loop) { Channel_info *channel_info= m_listener-&amp;gt;listen_for_connection_event(); if (channel_info != NULL) mgr-&amp;gt;process_new_connection(channel_info); } } Channel_info* Mysqld_socket_listener::listen_for_connection_event() { int retval= poll(&amp;amp;m_poll_info.m_fds[0], m_socket_map.size(), -1); // POLL  for (uint i= 0; i &amp;lt; m_socket_map.size(); ++i) { if (m_poll_info.m_fds[i].revents &amp;amp; POLLIN) { listen_sock= m_poll_info.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/vio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/vio/</guid>
      <description>VIO模块 #  为不同的protocol提供network I/O wrapper，类似于winsock。
Virtual I/O Library.
The VIO routines are wrappers for the various network I/O calls that happen with different protocols. The idea is that in the main modules one won&amp;rsquo;t have to write separate bits of code for each protocol. Thus vio&amp;rsquo;s purpose is somewhat like the purpose of Microsoft&amp;rsquo;s winsock library. https://dev.mysql.com/doc/internals/en/vio-directory.html
 SOCKET封装了socket fd，里面只有fd信息。
目前支持的protocol：
 TCP/IP Unix domain socket Named Pipes（Windows only） Shared Memory（Windows only） Secure Sockets（SSL）  Unix domain socket</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/menu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/menu/</guid>
      <description> MySQL  Server  MySQL启动过程 MySQL的连接和请求处理  THD Protocol  Returning（转）   NET VIO MySQL 8.0 对网络模块的优化（转） MySQL 8.0 通过Resource Group来控制线程计算资源（转） MariaDB MaxScale Proxy Protocol（转） 用户建链（转）   Timeout机制  kill_idle_transaction   Thread Pool MDL IO_CACHE 内存管理 信号处理机制 日志 read_only lower_case_table_names Invisible Index lazy drop/truncate table   InnoDB  overview source code record page storage buffer pool latch B+ tree change buffer lock  MySQL 5.7.26锁问题   redo log transaction   Replication    </description>
    </item>
    
    <item>
      <title>B&#43; tree</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/8_b&#43;_tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/8_b&#43;_tree/</guid>
      <description>在InnoDB中，数据的存储组织为IoT，采用B+ tree的数据结构提供高效访问数据的方式（存取路径）。
在B+ tree实现中，两块内容最为重要，一块是concurrency control，一块是SMO（Struct Modification Operations）。
演进 #  B+ tree是由二叉查找树、平衡二叉树、B-tree演进而来的。
二叉查找树 BST（Binary Search Tree）
平衡二叉树 AVL（Balanced Binary Tree）
在计算机科学中，AVL树是最早被发明的自平衡二叉查找树。在AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是O(logn)。增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。AVL 树得名于它的发明者 G. M. Adelson-Velsky 和 Evgenii Landis，他们在1962年的论文《An algorithm for the organization of information》中公开了这一数据结构。
 二叉查找树 BST（Binary Search Tree） #  我们在介绍B+ tree之前，先了解一下binary search tree。在BST中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。因此可以通过中序遍历得到键值的排序输出。
中序遍历（LDR - Inorder Traversal）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。
比如有如下二叉查找树：
中序遍历后输出：2、3、5、6、7、8。
二叉查找树的平均查找速度比顺序查找来得更快：顺序查找的平均查找次数为(1+2+3+4+5+6)/6=3.3次，二叉查找树的平均查找次数为(3+3+3+2+2+1)/6=2.3次。
但是，二叉查找树可以任意地构造，如果构造成下面的二叉查找树：
则平均查找次数为(1+2+3+4+5+5)/6=3.16次，和顺序查找差不多。而二叉查找树的查找效率取决于树的高度，因此若想最大性能地构造一个二叉查找树，需要这棵二叉查找树是平衡的（即树的高度最小），因此引出了平衡二叉树，或称为AVL tree。
平衡二叉树 AVL tree（Balanced Binary Tree） #  平衡二叉树的定义如下：首先符合二叉查找树的定义，其次必须满足任何节点的两个儿子子树的高度最大差为1。显然，上图不满足平衡二叉树的定义，而下图是一棵平衡二叉树。平衡二叉树对于查找的性能是比较高的，但不是最高的，只是接近最高性能。最好的性能需要建立一棵最优二叉树，但是最优二叉树的建议和维护需要大量的操作，因此，用户一般只需建立一棵平衡二叉树即可。
平衡二叉树对于查询速度的确很快，但是维护一棵平衡二叉树的代价是需要付出代价的。通常来说，需要1次或多次左旋和右旋来得到插入或更新后树的平衡性。
比如插入9，需要左旋以保证平衡：
有的情况可能需要多次：
上面2个图都是插入的例子，更新和删除操作同理，也是通过左旋或者右旋来完成的。因此对于一棵平衡树的维护是有一定开销的，不过平衡二叉树多用于内存结构对象中，因此维护的开销相对较小。
平衡因子 = 左子树深度/高度 - 右子树深度/高度</description>
    </item>
    
    <item>
      <title>buffer pool</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/6_buffer_pool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/6_buffer_pool/</guid>
      <description>基于磁盘的数据库系统通常都是用缓冲池（buffer pool）技术来弥补CPU和磁盘之间的速度鸿沟。
通过以下机制来达成目标：
spatial control 空间控制
 where to write pages on disk. the goal is to keep pages that are used together often as physically close together as possible on disk.  temporal control 时间控制
 when to read pages into memory, and when to write them to disk. the goal is minimize the number of stalls from having to read data from disk.  在以下章节中，InnoDB数据结构中的buf_block_t，buf_page_t、frame按照Jim Gray的命名进行转换，称为block（以下称为PCB，包含meta+data）、meta和frame（data）。
概述 #  buffer pool #  InnoDB是基于磁盘存储的存储引擎，磁盘中的记录以页为单位进行管理。</description>
    </item>
    
    <item>
      <title>change buffer</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/9_change_buffer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/9_change_buffer/</guid>
      <description>change buffer是InnoDB所特有的。
设计 #  change buffer目的是减少随机访问磁盘，提升non-unique secondary index（以下简称NUSI）的变更效率，在IO-bound workload下很有必要。
在InnoDB中，数据顺序存储在clustered index的leaf node，secondary index leaf node则是离散的，因此，对seconary index leaf node的变更操作是随机IO。为了提升secondary index的磁盘IO效率，InnoDB的做法是采用写缓冲机制，将NUSI的变更操作缓冲下来（leaf page oriented），减少随机IO，并在合适的时机将多次对同一页的操作进行merge，这块缓存称为change buffer。
当导入大量数据时，DBA常见的一个做法是，先disable keys，然后倒入数据后再enable keys，这也是减少随机IO手段的一个体现。  这里借用官方一张图，可以给大家带来直观的理解：
在MySQL 5.5之前，因为只支持缓存insert操作，所以叫做insert buffer，后面支持了更多的操作类型（一共有insert、delete mark、delete），才改叫change buffer。
那为什么只对non-unique进行cache呢？这是因为unique index要保证唯一性约束，在插入记录时要判断是否唯一，势必要读取secondary page leaf node，而这样做违反了change buffer的设计目的。但是，对于unique secondary index的delete操作，是可以缓存在change buffer中的。
change buffer也是一颗B+ tree，这颗B+ tree的page也会使用buffer pool的内存空间（但是会限制其占用的比例，最多25% CHANGE_BUFFER_DEFAULT_SIZE）。
在更新NUSI时，首先判断leaf page是否在buffer pool中，如果在，则直接在内存中更新page；否则满足缓存条件后将变更缓存到change buffer中（保存位置+op+data），然后在后台异步将change buffer缓存写回NUSI的leaf page中，GC并推进LWN。
从这里可以看到，secondary index的变更的路径分为两个分支：
 如果NUSI的leaf page在buffer pool中：这个和之前B+ tree中页的更新完全一样，不再详述，可以保证A、D，也可以保证index tree页操作的一致性（SMO） 如果不在，变更先缓存到change buffer中，然后再写回原处：这里要保证change buffer的A、D  这里更新NUSI的场景有：
 用户线程的DML 后台purge线程  对于读取来说，直接通过物理读读取NUSI的leaf page后，需要判断change buffer中是否已缓存变更操作（缓存该页的change buffer record），如果进行了缓存，要先merge change buffer，然后再读取leaf page中的record。</description>
    </item>
    
    <item>
      <title>latch</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/7_latch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/7_latch/</guid>
      <description>latch数据结构 #  先看一下整体的latch数据结构，以及之间的关系：
下面逐个展开。
latch基本信息 #  latch ID #  用于标识latch，数据结构为latch_id_t。
latch ordering #  在数据库中，从狭义视角看，latch用于保护修改的内存对象；从全局视角看，全局操作不同对象也需要遵循特定的顺序，因此有了latching order。数据结构为latch_level_t。
比如
enum latch_level_t { ... SYNC_BUF_BLOCK, SYNC_BUF_PAGE_HASH, ... } latch counter #  LatchCounter负责进行latch计数，计数信息包括：spin、waits、calls，并可以动态开启/关闭计数功能（MutexMonitor），也可以通过传入的callback函数用计数值进行运算（比如在innodb中统计latch信息）。
数据结构说明
   变量/函数 说明     变量/函数 说明   Count spin waits calls enabled 是否开启计数   vector&amp;lt;Count*&amp;gt; m_counters m_counters   bool m_active 是否开启计数   enable/disable/reset 开启/关闭/重置计数   single_register/single_deregister 注册/注销单例计数器   sum_register/sum_deregister 注册/注销聚合计数器   iterate 迭代计数器，调用callback函数    latch元信息 #  latch元信息由以上3类数据聚合而成（ID、ordering、counter），数据结构为latch_meta_t。</description>
    </item>
    
    <item>
      <title>lazy drop/truncate table</title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/lazy_drop_table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/lazy_drop_table/</guid>
      <description>背景 #  DBA在线上进行运维时，会遇到drop table，truncate table出现卡顿（维持数秒），在这期间，如果业务访问量大，请求会在短时间内急剧堆积，对线上的稳定性造成很大的挑战。
现有DBA需要drop/truncate table的运维场景有：
 业务需要调整schema，发起DDL操作（drop） 业务清理过期表（按照日期定期滚动）（drop） 业务废弃（drop） 业务重用表（drop + create） 业务清理数据（truncate）  其中DDL过程如下：
DBA在线上进行DDL的时候，采用gh-ost的旁路方式进行schema变更，最终会drop table。
 create ghost table like origin table alter ghost table copy origin table data and apply its binlog to ghost table &amp;hellip; lock origin table with write lock, until all binlog applied rename origin table rename ghost to origin drop origin table  root cause #  drop table、truncate table的目的都是为了清理数据，除了清理磁盘上的数据外，内存中的高速缓存（buffer pool）也需要清理，以免用户访问到了失效的缓存而得到错误的结果。</description>
    </item>
    
    <item>
      <title>lock</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/10_lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/10_lock/</guid>
      <description>在InnoDB中，采用悲观并发控制结合多版本技术，即MV2PL来提供事务的并发控制。并且，通过nextkey locking在RR级别下解决了幻读。最后，InnoDB没有锁升级机制，这得益于其行锁对象及implicit lock的设计。
1 锁与事务 #  我们在前面谈过latch，并且比较过在并发控制上二者的区别，但是，锁的用途不仅仅如此，锁和事务戚戚相关。
1.1 隔离性 #  与锁相关的概念有：
 并发控制 concurrency control 序列化 serializability 隔离性 isolation  这里用ACID特性中的隔离性（I）来阐述锁。锁是用来实现事务一致性和隔离性的一种常用技术。
事务的隔离性要求每个读/写事务对象对其他事务的操作可以互相分离，即该事务提交前对其他事务不可见。
First Law of Concurrency Control ：
Concurrent execution should not cause application programs to malfunction.
 这也是事务隔离性的要求，即当数据库系统中的事务并发运行时，每个事务的运行不会受到其他事务的影响，好像每个并发事务都是&amp;quot;单线程&amp;quot;的在运行。
实现隔离性有许多种方式，最为广泛使用的就是加锁（locking）技术。不过，即使采用加锁技术，仍然可以有多种实现方式，因此就有了并发控制的第二准则：
Second Law of Concurrency Control ：
Concurrent execution should not have lower throughput or much higher response times than serial execution.
 如果采用加锁技术实现的数据库并发系统的影响时间大于串行运行的方式，那么这也不是一种能被接受的加锁方式，即并发控制的第二准则要求一种简单的算法或者开销较小的方式来实现加锁技术。
最简单的加锁技术是对每个要访问的对象加上一个锁。当事务访问一个对象，数据库自动请求并加上一个锁，在事务结束后释放该锁。若请求时该对象上已经被其他事务持有锁，则该事务等待对象上锁的释放。由此可见，锁提供了一种串行机制，用来保证同一时刻一个对象仅能被一个事务访问。
通过多粒度（fine granular）锁可以用来提高数据库系统的并发性。比如，可以让不同事务访问同一页中的不同记录，从而提高数据库的并发度。
InnoDB中锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持，但InnoDB中的行级锁没有相关额外的开销，可以在保证数据一致性的基础上同时获得较高的并发性。
1.2 事务的隔离级别 #  在DBMS发展初期，大部分的数据库系统都没有提供真正的隔离性，最初是因为系统的设计者并没有真正理解这些问题。现在各种读写异常的场景已经清晰，但DBMS需要在正确性和性能之间做出妥协。ISO和ANSI SQL标准制定了四种事务隔离级别的标准，但是很少有数据库厂商遵循这些标准，比如Oracle数据库就不支持READ UNCOMMITTED和REPEATABLE READ的事务隔离级别。</description>
    </item>
    
    <item>
      <title>overview</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/1_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/1_overview/</guid>
      <description>Heikki Tuuri是InnoDB存储引擎的创始人，1964年生于芬兰赫尔辛基。与著名Linux操作系统的创始人Linus一样毕业于芬兰赫尔辛基大学。从入学时间来看，Heikki Tuuri还是Linus的学长。在1990年取得赫尔辛基大学的数理逻辑博士学位后。
所以，innodb的代码大部分都是Created mm/dd/YYYY Heikki Tuuri。
MySQL大事时间表：
 1995：Heikki Tuuri成立Innobase Oy公司并担任CEO。同年，由David Axmark、Allan Larsson和Michael Monty Widenius在瑞典创办MySQL AB公司。 2001：Innobase公司开始与MySQL AB公司进行合作并开源InnoDB存储引擎的代码。 2005：Oracle公司收购了Innobase公司。 2008：Sun收购MySQL AB公司。 2009：2009年4月20日，Sun 公司董事会通过决议，同意以每股9.5美元的价格将公司出售给Oracle。  </description>
    </item>
    
    <item>
      <title>page</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/4_page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/4_page/</guid>
      <description>InnoDB使用的是索引组织表，因此聚簇索引的叶子节点中存放完整的数据记录，辅助索引页的叶子节点中存放指向聚簇索引页叶子节点的书签（bookmark），也可以称为路标。
主要是两部分：
 page layout scan rec with cursor, and then insert, update, delete  页 #  页是InnoDB存储数据的基本单位。页的大小可以设置为4K~64K（4K的倍数），默认为16K。页的大小设置要从IO性能考虑。
/* Define the Min, Max, Default page sizes. */ /** Minimum Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_MIN 12 /** Maximum Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_MAX 16 /** Default Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_DEF 14 static MYSQL_SYSVAR_ULONG(page_size, srv_page_size, PLUGIN_VAR_OPCMDARG | PLUGIN_VAR_READONLY, &amp;quot;Page size to use for all InnoDB tablespaces.</description>
    </item>
    
    <item>
      <title>record</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/3_record/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/3_record/</guid>
      <description>设计 #  行存 #  MySQL主要面向的是OLTP场景，所以InnoDB中存储的数据采用行存（NSM - n-ary storage model）。
基于行进行存储有以下几个好处：
 记录存放在一个页中，存储一条记录需要访问的页面较少 符合传统机械硬盘的访问方式 易于理解，数据的存取就像是对一张二维表进行访问  在整体上看，表中的数据是按照如下形式组织的：
记录 #  那我们如何来理解记录呢？
首先，在关系数据库系统理论中，通常用元组（tuple）描述记录，用字段（field）描述列，每个tuple由多个field组成，每个表由多个tuple组成。
行和tuple在意义上是相等的。但是更愿意将行（row）理解为物理记录，将元组（tuple）理解为逻辑记录。物理记录为行实际存放在物理存储中的格式，其内容由二进制字符串组成，可读性差。逻辑记录则容易理解的多，每张表中的多条记录就像是一个数组。由于其只是“逻辑”上的含义，因此逻辑记录只是物理记录在内存中的表现形式，实际并不占用任何的物理存储空间。
关系如下图所示：
物理记录和逻辑记录的差异如下：
    物理记录 逻辑记录     可读性 差 好   存储位置 磁盘 内存   亲和性 对存储友好（更紧凑） 对查找友好（更易寻址）   存储内容 记录中各个列的数据+一些额外信息 元组（用于比较、展现而组织的列数据）    这两种记录之间可以互相转换。比如，在插入一条记录时，原来没有数据，首先需要根据插入的记录构造一个逻辑记录，然后再转换成物理记录存放到磁盘上。对于读取，要从磁盘上seek出相应的数据页，再将页中的物理记录转换成逻辑记录展现给用户。
除此之外，在MySQL server层需要在binlog中记录数据的变化，这也是一种行格式（RBR-logging）。因此，在MySQL中，行格式一共有3种存储方式：
 Server层格式：与存储引擎无关，server层的binlog行格式（Row-Base Replication下的binlog格式） 逻辑记录格式：tuple，也称为索引元组格式（因为InnoDB是IOT）。在同一个表中，不同索引对应的元组是不同的 物理记录格式：record，也称为physical record  物理记录的设计 #  物理记录承载着数据的最终存储，因此，我们首先讨论物理记录。</description>
    </item>
    
    <item>
      <title>redo log</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/11_redo_log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/11_redo_log/</guid>
      <description>日志或者说logging schema主要是为crash recovery algorithms服务的，即为了保证事务的ACD特性。crash recovery是通过多种机制协调解决的，这里面包括buffer pool的flush策略，WAL、logging schema和checkpoint。并且，InnoDB采用MV2PL，还通过undo log在MVCC中实现delta storage用于存储行的多版本快照。
从这里可以看出，日志在事务处理中的重要性。这里的日志主要分为undo log和redo log，undo log在下一章事务中详细介绍，本章聚焦在redo log。crash_recovery在事务一章介绍。
设计 #  crash recovery algorithms由IBM在90年代发表的一篇ARIES论文提出（Algorithms for Recovery and Isolation Exploiting Semantics）。InnoDB也借鉴了ARIES的思想。思想的核心是利用日志（undo+redo）来实现可恢复性。
redo log #  redo log是在数据库的运行时，随着数据的更改而产生的变更日志，其目的是两个：
 体现数据的变更序 通过变更序持久化的能力，可以让数据库系统在crash recovery后恢复到内存态  因此，我们分别来详细描述如何做到这两点。
首先是体现数据的变更序。
在数据库中，数据都是通过page为单位组织的。因此，在体现数据变更的时候，这个变更序首先是page的变更序。并且，在InnoDB中，page被组成成B+ tree结构，因此，还要体现SMO，也就是说，还要考虑一个逻辑操作可能会设计B+ tree的多个页面，以及不同B+ tree之间的操作关系，这个关系的组织通过mini-transaction来实现，即提供原子粒度的一组redo log（只保证forwrd）保证动作-页面的一致性。。这些操作组合起来形成了事务，换句话说，事务中的每个逻辑操作产生了一系列page的变更序列，即一组redo log。
在整体上，数据库中并发事务之间也需要在整体上进行page排序，这一方面依靠FIX Rules保证page间的并发控制，另一方面B+ tree concurrency control protocol也要从数据结构维度维护并发序，加上MV2PL机制，整体上这个page变更序列就确定了。这个全局page的变更序以一个全局的redo log buffer呈现。
第二点，持久化实际上就是把redo log biffer sync到持久化存储（磁盘）中，sync到磁盘的时机我们称之为sync point。一般来讲，sync point同时也是事务commit点，即WAL机制（force log at commit），也就是保证事务的所有日志（redo+undo）sync到磁盘完成后，事务提交才真正完成，这意味着sync point = commit point。
这个sync point也有group commit的体现，每个用户线程在各自事务中的一个逻辑操作通过mini-transaction提交到redo log buffer，然后再在sync point时一起持久化。换句话说，每次sync都会把当前sync point之前的所有redo log都持久化到磁盘，这一组（group）持久化的日志包含了各个事务并发修改的数据。</description>
    </item>
    
    <item>
      <title>storage</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/5_storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/5_storage/</guid>
      <description>存储管理是数据库系统最基本的功能，本章将介绍InnoDB存储引擎中数据在外存中的组织形式（即数据文件）、数据文件在内存中的管理方式以及数据在文件层次的读/写。
存储组织 #  存储管理需要解决以下2个问题：
 如何在存储设备上表示和组织数据库中的数据 如何在内存和外存上控制数据的存取  一般来说，DBMS不直接使用操作系统提供的文件系统作为直接的存储，而是在文件系统之上封装了一层自己对于存储设备的管理，以保证数据的完整性和存取效率。目前大部分的文件系统即使提供了日志的支持，可以保证写的原子性，但是数据库的数据页可能大于文件系统中的block大小，仍然避免不了出现的半写（partial-write）问题，所以数据库也要解决半写问题。
存储层次 #  为了解决以上两个问题，根据分层和抽象的思想，存储的组织和管理可以划分为3个层次：
 文件存储（file storage） 页（page layout） 记录（tuple layout）  暂不讨论raw device，这里假设数据库的文件存放在操作系统提供的文件系统之上。  文件存储负责将文件系统上的一组物理文件进行逻辑组织，按照使用场景（日志、数据、临时数据&amp;hellip;）、以及数据IO特征的不同（日志是append-only的，数据可能是原地写/append-only），将物理文件进行划分，抽象出表空间，并形成统一的数据库层的逻辑文件子系统。
根据局部性原理，为了I/O的高效，我们需要将数据聚簇并划块，这就形成了页，所以第二层可以理解为页的集合，负责按照页为单位从外存、内存读写数据，并分配使用空间。
对于用户来说，操作的是数据，也就是记录的集合，那么在微观上需要对记录进行操作。这也是最后一层，我们在这层实现数据的更改和查询。
所以，存储引擎中内部存储单元（页）和操作系统、以及磁盘上的物理存储单元关系如下图所示：
文件存储 #  文件存储负责将操作系统文件系统上的数据库相关物理文件组织在一起，形成数据库的逻辑文件子系统，整体结构如下图所示：
从上图可以看到，不同的物理文件组成了多个表空间，然后一起形成file system子系统。官方表空间的描述在这里。
InnoDB存储引擎对于文件的管理通过fil_system_t、fil_space_t、fil_node_t进行描述，并定义了四种文件空间（file space）类型：
 FIL_TYPE_TABLESPACE：持久表空间类型，包括系统表空间、独立表空间、undo表空间（innodb_system、user、innodb_undo&amp;lt;000&amp;gt;） FIL_TYPE_LOG：重做日志（ib_logfile&amp;lt;0~100&amp;gt;） FIL_TYPE_TEMPORARY：临时表空间（innodb_temporary） FIL_TYPE_IMPORT：只在导入表空间时使用（导入前为FIL_TYPE_IMPORT，导入完成后为FIL_TYPE_TABLESPACE）  每个文件空间可以包含若干个文件节点（file node）。file node是文件存储的最小单元。逻辑存储模块管理文件系统（file system）下的各个文件空间（file space），并对文件空间下的file node的读/写操作进行管理。
fil_system_t、fil_space_t、fil_node_t的关系如图所示：
在file system中的name：
 在file_space→name为文件名（1）或者文件名统称（n） file_node→name为具体的文件路径+文件名  比如重做日志中的file_space→name和file_node分别为：innodb_redo_log和path/ib_logfile&amp;lt;0 ~ 100&amp;gt;。
表空间 #  首先先让我们从用户和系统管理的角度来了解表空间的使用场景，以便对表空间有一个直观的认识。
使用场景 #  在MySQL 5.7中，表空间按照使用场景分为五种：
 系统表空间 独立表空间 通用表空间 undo表空间 临时表空间  系统表空间 #  系统表空间位于datadir下，存放了InnoDB存储引擎的核心信息，包括数据字典、事务系统信息、double write buffer、change buffer。如果没有配置独立的undo表空间，则undo日志也存放在这里（临时表空间也是如此）。同样，如果没有开启独立表空间（file-per-table），则用户表的数据和索引也存放在这里。因此，系统表空间也被称为共享表空间。</description>
    </item>
    
    <item>
      <title>transaction</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/12_transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/12_transaction/</guid>
      <description>事务 #  概述 #  事务是访问数据库中数据的一个程序执行单元。在一个事务中的操作，要么都做，要么不做，这是事务的目的，也是事务模型区别于文件系统的重要特征之一。
从理论上来说，事务有着极其严格的定义，必须同时满足ACID四个特性。但是数据库厂商出于各种目的，并没有严格满足事务的ACID标准。比如对于MySQL的NDB Cluster，没有满足D；对于Oracle，默认的事务隔离级别是Read Committed，不满足I。在InnoDB中，默认的事务隔离级别是Read Repeatable，完全遵循和满足事务的ACID特性。
这里要注意，D保证的是事务系统的高可靠性（High Reliability），而不是高可用性（High Availability）。对于高可用性，事务本身并不能保证，需要一些系统共同配合来完成。
分类 #  参见Jim Gray
隔离级别 #  令人惊讶的是，大部分数据库系统都没有提供真正的隔离性，最初或许是因为系统实现者并没有真正理解这些问题。如今这些问题已经弄清楚了，但是数据库的实现者在正确性和性能之间做了妥协。ISO和ANSI SQL标准制定了四种事务隔离级别的标准，但是很少有数据库厂商遵循这些标准，比如Oracle不支持Read Uncommitted和Repeatable Read的事务隔离级别。
SQL标准定义的四个隔离级别为：
 Read Uncommitted Read Committed Repeatable Read Serializable  SQL和SQL2标准的默认事务隔离级别是Serializable。
InnoDB支持的默认事务隔离级别是Repeatable Read，但是和SQL标准不同的是，InnoDB在此隔离级别下，通过使用next-key locking算法，避免了幻读的产生，即可以完全保证事务的隔离性要求，达到了SQL标准的Serializable隔离级别。在append-only storage上，采用snapshot isolation也是避免幻读的一种实现方式。
这里给读者留一个扩展性的思考：
采用MV可以实现snapshot isolation进而避免幻读吗？
InnoDB既然也有采用了MV，不用next-key locking而用Percolator的方式能不能做到？
 关于事务可以洋洋洒洒写很多，这里主要聚焦InnoDB中的事务子系统的实现，详细的事务概念和事务控制技术这里略过。
事务子系统 #  事务子系统中的数据包括事务信息、undo log、binlog信息以及doublewrite信息。
这些信息由trx_sys page牵头，存储在各自的segment中：
   segment 存储内容 segment header     txn segment 事务信息 trx_sys page   rollback segment undo segment、history链表、undo slots rollback segment page   undo segment undo log undo segment page   doublewrite segment doublewrite数据 trx_sys_page    整体层次如下：</description>
    </item>
    
  </channel>
</rss>
