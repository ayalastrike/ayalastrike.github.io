<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rick&#39;s Blog</title>
    <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/</link>
    <description>Recent content on Rick&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://ayalastrike.github.io/docs/MySQL/InnoDB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/2_source/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/2_source/</guid>
      <description>typora-root-url: ../../../../static
在MySQL源代码中，每个模块都有自己单独的目录存放，里面按照模块名0子模块名.cc来组织。所有头文件都放在include目录下，同时include目录下还有*.ic的文件，这个文件中存放定义的内联函数。
如果要在*.ic中使用宏UNIV_INLINE定义内联，需要#include &amp;ldquo;univ.i&amp;rdquo;，即
#include &amp;#34;univ.i&amp;#34;UNIV_INLINE return_value function foo(param1, ...) ``// 函数声明或实现 { ``... } 注意，这种风格只是适用于c函数，对于ic文件中的类成员函数定义，还是需要手动写inline  univ.i中UNIV_INLINE的宏定义
#ifndef UNIV_MUST_NOT_INLINE /* Definition for inline version */ #define UNIV_INLINE static inline #else /* !UNIV_MUST_NOT_INLINE *//* If we want to compile a noninlined version we use the following macro definitions: */ #define UNIV_NONINL #define UNIV_INLINE #endif /* !UNIV_MUST_NOT_INLINE */阅读源码层次
推荐从下至上进行逐层阅读
最下一层是基础管理模块：
 File Manager主要封装了InnoDB对于文件的各类操作，如读、写、异步I/O等。 Concurrency Manager模块主要封装了引擎内部使用的各类mutex和latch。 Common Utility模块用于一些基本数据结构与算法的定义，如链表、哈希表等。  图中间虚线标注的部分为InnoDB的内核实现，也就是InnoDB存储引擎中的事务、锁、缓冲区、日志、存储管理、资源管理、索引、change buffer模块，这部分是整个存储引擎的核心。</description>
    </item>
    
    <item>
      <title>B&#43; tree</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/8_b&#43;_tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/8_b&#43;_tree/</guid>
      <description>在InnoDB中，数据的存储组织为IoT，采用B+ tree的数据结构提供高效访问数据的方式（存取路径）。
在B+ tree实现中，两块内容最为重要，一块是concurrency control，一块是SMO（Struct Modification Operations）。
演进 #  B+ tree是由二叉查找树、平衡二叉树、B-tree演进而来的。
二叉查找树 BST（Binary Search Tree）
平衡二叉树 AVL（Balanced Binary Tree）
在计算机科学中，AVL树是最早被发明的自平衡二叉查找树。在AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是O(logn)。增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。AVL 树得名于它的发明者 G. M. Adelson-Velsky 和 Evgenii Landis，他们在1962年的论文《An algorithm for the organization of information》中公开了这一数据结构。
 二叉查找树 BST（Binary Search Tree） #  我们在介绍B+ tree之前，先了解一下binary search tree。在BST中，左子树的键值总是小于根的键值，右子树的键值总是大于根的键值。因此可以通过中序遍历得到键值的排序输出。
中序遍历（LDR - Inorder Traversal）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。
比如有如下二叉查找树：
中序遍历后输出：2、3、5、6、7、8。
二叉查找树的平均查找速度比顺序查找来得更快：顺序查找的平均查找次数为(1+2+3+4+5+6)/6=3.3次，二叉查找树的平均查找次数为(3+3+3+2+2+1)/6=2.3次。
但是，二叉查找树可以任意地构造，如果构造成下面的二叉查找树：
则平均查找次数为(1+2+3+4+5+5)/6=3.16次，和顺序查找差不多。而二叉查找树的查找效率取决于树的高度，因此若想最大性能地构造一个二叉查找树，需要这棵二叉查找树是平衡的（即树的高度最小），因此引出了平衡二叉树，或称为AVL tree。
平衡二叉树 AVL tree（Balanced Binary Tree） #  平衡二叉树的定义如下：首先符合二叉查找树的定义，其次必须满足任何节点的两个儿子子树的高度最大差为1。显然，上图不满足平衡二叉树的定义，而下图是一棵平衡二叉树。平衡二叉树对于查找的性能是比较高的，但不是最高的，只是接近最高性能。最好的性能需要建立一棵最优二叉树，但是最优二叉树的建议和维护需要大量的操作，因此，用户一般只需建立一棵平衡二叉树即可。
平衡二叉树对于查询速度的确很快，但是维护一棵平衡二叉树的代价是需要付出代价的。通常来说，需要1次或多次左旋和右旋来得到插入或更新后树的平衡性。
比如插入9，需要左旋以保证平衡：
有的情况可能需要多次：
上面2个图都是插入的例子，更新和删除操作同理，也是通过左旋或者右旋来完成的。因此对于一棵平衡树的维护是有一定开销的，不过平衡二叉树多用于内存结构对象中，因此维护的开销相对较小。
平衡因子 = 左子树深度/高度 - 右子树深度/高度</description>
    </item>
    
    <item>
      <title>buffer pool</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/6_buffer_pool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/6_buffer_pool/</guid>
      <description>基于磁盘的数据库系统通常都是用缓冲池（buffer pool）技术来弥补CPU和磁盘之间的速度鸿沟。
通过以下机制来达成目标：
spatial control 空间控制
 where to write pages on disk. the goal is to keep pages that are used together often as physically close together as possible on disk.  temporal control 时间控制
 when to read pages into memory, and when to write them to disk. the goal is minimize the number of stalls from having to read data from disk.  在以下章节中，InnoDB数据结构中的buf_block_t，buf_page_t、frame按照Jim Gray的命名进行转换，称为block（以下称为PCB，包含meta+data）、meta和frame（data）。
概述 #  buffer pool #  InnoDB是基于磁盘存储的存储引擎，磁盘中的记录以页为单位进行管理。</description>
    </item>
    
    <item>
      <title>change buffer</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/9_change_buffer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/9_change_buffer/</guid>
      <description>change buffer是InnoDB所特有的，设计思想非常先进，首先详细介绍change buffer的设计机制和实现细节，然后介绍其为了避免死锁所做的考虑。
设计 #  change buffer目的是减少随机访问磁盘，提升non-unique secondary index（以下简称NUSI）的变更效率，在IO-bound workload下很有必要。
在InnoDB中，数据顺序存储在clustered index的leaf node，secondary index leaf node则是离散的，因此，对seconary index leaf node的变更操作是随机IO。为了提升secondary index的磁盘IO效率，InnoDB的做法是采用写缓冲机制，将NUSI的变更操作缓冲下来（leaf page oriented），减少随机IO，并在合适的时机将多次对同一页的操作进行merge，这块缓存称为change buffer。
当导入大量数据时，DBA常见的一个做法是，先disable keys，然后倒入数据后再enable keys，这也是减少随机IO手段的一个体现。  这里借用官方一张图，可以给大家带来直观的理解：
在MySQL 5.5之前，因为只支持缓存insert操作，所以叫做insert buffer，后面支持了更多的操作类型（一共有insert、delete mark、delete），才改叫change buffer。
那为什么只对non-unique进行cache呢？这是因为unique index要保证唯一性约束，在插入记录时要判断是否唯一，势必要读取secondary page leaf node，而这样做违反了change buffer的设计目的。但是，对于unique secondary index的delete操作，是可以缓存在change buffer中的。
change buffer也是一颗B+ tree，这颗B+ tree的page也会使用buffer pool的内存空间（但是会限制其占用的比例，最多25% CHANGE_BUFFER_DEFAULT_SIZE）。
在更新NUSI时，首先判断leaf page是否在buffer pool中，如果在，则直接在内存中更新page；否则满足缓存条件后将变更缓存到change buffer中（保存位置+op+data），然后在后台异步将change buffer缓存写回NUSI的leaf page中，GC并推进LWN。
从这里可以看到，secondary index的变更的路径分为两个分支：
 如果NUSI的leaf page在buffer pool中：这个和之前B+ tree中页的更新完全一样，不再详述，可以保证A、D，也可以保证index tree页操作的一致性（SMO） 如果不在，变更先缓存到change buffer中，然后再写回原处：这里要保证change buffer的A、D  这里更新NUSI的场景有：
 用户线程的DML 后台purge线程  对于读取来说，直接通过物理读读取NUSI的leaf page后，需要判断change buffer中是否已缓存变更操作（缓存该页的change buffer record），如果进行了缓存，要先merge change buffer，然后再读取leaf page中的record。</description>
    </item>
    
    <item>
      <title>latch</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/7_latch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/7_latch/</guid>
      <description>latch数据结构 #  先看一下整体的latch数据结构，以及之间的关系：
下面逐个展开。
latch基本信息 #  latch ID #  用于标识latch，数据结构为latch_id_t。
latch ordering #  在数据库中，从狭义视角看，latch用于保护修改的内存对象；从全局视角看，全局操作不同对象也需要遵循特定的顺序，因此有了latching order。数据结构为latch_level_t。
比如
enum latch_level_t { ... SYNC_BUF_BLOCK, SYNC_BUF_PAGE_HASH, ... } latch counter #  LatchCounter负责进行latch计数，计数信息包括：spin、waits、calls，并可以动态开启/关闭计数功能（MutexMonitor），也可以通过传入的callback函数用计数值进行运算（比如在innodb中统计latch信息）。
数据结构说明
   变量/函数 说明     变量/函数 说明   Count spin waits calls enabled 是否开启计数   vector&amp;lt;Count*&amp;gt; m_counters m_counters   bool m_active 是否开启计数   enable/disable/reset 开启/关闭/重置计数   single_register/single_deregister 注册/注销单例计数器   sum_register/sum_deregister 注册/注销聚合计数器   iterate 迭代计数器，调用callback函数    latch元信息 #  latch元信息由以上3类数据聚合而成（ID、ordering、counter），数据结构为latch_meta_t。</description>
    </item>
    
    <item>
      <title>lock</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/10_lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/10_lock/</guid>
      <description>在InnoDB中，采用悲观并发控制结合多版本技术，即MV2PL来提供事务的并发控制。并且，通过nextkey locking在RR级别下解决了幻读。最后，InnoDB没有锁升级机制，这得益于其行锁对象及implicit lock的设计。
1 锁与事务 #  我们在前面谈过latch，并且比较过在并发控制上二者的区别，但是，锁的用途不仅仅如此，锁和事务戚戚相关。
1.1 隔离性 #  与锁相关的概念有：
 并发控制 concurrency control 序列化 serializability 隔离性 isolation  这里用ACID特性中的隔离性（I）来阐述锁。锁是用来实现事务一致性和隔离性的一种常用技术。
事务的隔离性要求每个读/写事务对象对其他事务的操作可以互相分离，即该事务提交前对其他事务不可见。
First Law of Concurrency Control ：
Concurrent execution should not cause application programs to malfunction.
 这也是事务隔离性的要求，即当数据库系统中的事务并发运行时，每个事务的运行不会受到其他事务的影响，好像每个并发事务都是&amp;quot;单线程&amp;quot;的在运行。
实现隔离性有许多种方式，最为广泛使用的就是加锁（locking）技术。不过，即使采用加锁技术，仍然可以有多种实现方式，因此就有了并发控制的第二准则：
Second Law of Concurrency Control ：
Concurrent execution should not have lower throughput or much higher response times than serial execution.
 如果采用加锁技术实现的数据库并发系统的影响时间大于串行运行的方式，那么这也不是一种能被接受的加锁方式，即并发控制的第二准则要求一种简单的算法或者开销较小的方式来实现加锁技术。
最简单的加锁技术是对每个要访问的对象加上一个锁。当事务访问一个对象，数据库自动请求并加上一个锁，在事务结束后释放该锁。若请求时该对象上已经被其他事务持有锁，则该事务等待对象上锁的释放。由此可见，锁提供了一种串行机制，用来保证同一时刻一个对象仅能被一个事务访问。
通过多粒度（fine granular）锁可以用来提高数据库系统的并发性。比如，可以让不同事务访问同一页中的不同记录，从而提高数据库的并发度。
InnoDB中锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持，但InnoDB中的行级锁没有相关额外的开销，可以在保证数据一致性的基础上同时获得较高的并发性。
1.2 事务的隔离级别 #  在DBMS发展初期，大部分的数据库系统都没有提供真正的隔离性，最初是因为系统的设计者并没有真正理解这些问题。现在各种读写异常的场景已经清晰，但DBMS需要在正确性和性能之间做出妥协。ISO和ANSI SQL标准制定了四种事务隔离级别的标准，但是很少有数据库厂商遵循这些标准，比如Oracle数据库就不支持READ UNCOMMITTED和REPEATABLE READ的事务隔离级别。</description>
    </item>
    
    <item>
      <title>overview</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/1_overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/1_overview/</guid>
      <description>Heikki Tuuri是InnoDB存储引擎的创始人，1964年生于芬兰赫尔辛基。与著名Linux操作系统的创始人Linus一样毕业于芬兰赫尔辛基大学。从入学时间来看，Heikki Tuuri还是Linus的学长。在1990年取得赫尔辛基大学的数理逻辑博士学位后。
所以，innodb的代码大部分都是Created mm/dd/YYYY Heikki Tuuri。
MySQL大事时间表：
 1995：Heikki Tuuri成立Innobase Oy公司并担任CEO。同年，由David Axmark、Allan Larsson和Michael Monty Widenius在瑞典创办MySQL AB公司。 2001：Innobase公司开始与MySQL AB公司进行合作并开源InnoDB存储引擎的代码。 2005：Oracle公司收购了Innobase公司。 2008：Sun收购MySQL AB公司。 2009：2009年4月20日，Sun 公司董事会通过决议，同意以每股9.5美元的价格将公司出售给Oracle。  </description>
    </item>
    
    <item>
      <title>page</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/4_page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/4_page/</guid>
      <description>InnoDB使用的是索引组织表，因此聚簇索引的叶子节点中存放完整的数据记录，辅助索引页的叶子节点中存放指向聚簇索引页叶子节点的书签（bookmark），也可以称为路标。
主要是两部分：
 page layout scan rec with cursor, and then insert, update, delete  页 #  页是InnoDB存储数据的基本单位。页的大小可以设置为4K~64K（4K的倍数），默认为16K。页的大小设置要从IO性能考虑。
/* Define the Min, Max, Default page sizes. */ /** Minimum Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_MIN 12 /** Maximum Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_MAX 16 /** Default Page Size Shift (power of 2) */ #define UNIV_PAGE_SIZE_SHIFT_DEF 14 static MYSQL_SYSVAR_ULONG(page_size, srv_page_size, PLUGIN_VAR_OPCMDARG | PLUGIN_VAR_READONLY, &amp;quot;Page size to use for all InnoDB tablespaces.</description>
    </item>
    
    <item>
      <title>record</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/3_record/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/3_record/</guid>
      <description>设计 #  行存 #  MySQL主要面向的是OLTP场景，所以InnoDB中存储的数据采用行存（NSM - n-ary storage model）。
基于行进行存储有以下几个好处：
 记录存放在一个页中，存储一条记录需要访问的页面较少 符合传统机械硬盘的访问方式 易于理解，数据的存取就像是对一张二维表进行访问  在整体上看，表中的数据是按照如下形式组织的：
记录 #  那我们如何来理解记录呢？
首先，在关系数据库系统理论中，通常用元组（tuple）描述记录，用字段（field）描述列，每个tuple由多个field组成，每个表由多个tuple组成。
行和tuple在意义上是相等的。但是更愿意将行（row）理解为物理记录，将元组（tuple）理解为逻辑记录。物理记录为行实际存放在物理存储中的格式，其内容由二进制字符串组成，可读性差。逻辑记录则容易理解的多，每张表中的多条记录就像是一个数组。由于其只是“逻辑”上的含义，因此逻辑记录只是物理记录在内存中的表现形式，实际并不占用任何的物理存储空间。
关系如下图所示：
物理记录和逻辑记录的差异如下：
    物理记录 逻辑记录     可读性 差 好   存储位置 磁盘 内存   亲和性 对存储友好（更紧凑） 对查找友好（更易寻址）   存储内容 记录中各个列的数据+一些额外信息 元组（用于比较、展现而组织的列数据）    这两种记录之间可以互相转换。比如，在插入一条记录时，原来没有数据，首先需要根据插入的记录构造一个逻辑记录，然后再转换成物理记录存放到磁盘上。对于读取，要从磁盘上seek出相应的数据页，再将页中的物理记录转换成逻辑记录展现给用户。
除此之外，在MySQL server层需要在binlog中记录数据的变化，这也是一种行格式（RBR-logging）。因此，在MySQL中，行格式一共有3种存储方式：
 Server层格式：与存储引擎无关，server层的binlog行格式（Row-Base Replication下的binlog格式） 逻辑记录格式：tuple，也称为索引元组格式（因为InnoDB是IOT）。在同一个表中，不同索引对应的元组是不同的 物理记录格式：record，也称为physical record  物理记录的设计 #  物理记录承载着数据的最终存储，因此，我们首先讨论物理记录。</description>
    </item>
    
    <item>
      <title>redo log</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/11_redo_log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/11_redo_log/</guid>
      <description>日志或者说logging schema主要是为crash recovery algorithms服务的，即为了保证事务的ACD特性。crash recovery是通过多种机制协调解决的，这里面包括buffer pool的flush策略，WAL、logging schema和checkpoint。并且，InnoDB采用MV2PL，还通过undo log在MVCC中实现delta storage用于存储行的多版本快照。
从这里可以看出，日志在事务处理中的重要性。这里的日志主要分为undo log和redo log，undo log在下一章事务中详细介绍，本章聚焦在redo log。crash_recovery在事务一章介绍。
设计 #  crash recovery algorithms由IBM在90年代发表的一篇ARIES论文提出（Algorithms for Recovery and Isolation Exploiting Semantics）。InnoDB也借鉴了ARIES的思想。思想的核心是利用日志（undo+redo）来实现可恢复性。
redo log #  redo log是在数据库的运行时，随着数据的更改而产生的变更日志，其目的是两个：
 体现数据的变更序 通过变更序持久化的能力，可以让数据库系统在crash recovery后恢复到内存态  因此，我们分别来详细描述如何做到这两点。
首先是体现数据的变更序。
在数据库中，数据都是通过page为单位组织的。因此，在体现数据变更的时候，这个变更序首先是page的变更序。并且，在InnoDB中，page被组成成B+ tree结构，因此，还要体现SMO，也就是说，还要考虑一个逻辑操作可能会设计B+ tree的多个页面，以及不同B+ tree之间的操作关系，这个关系的组织通过mini-transaction来实现，即提供原子粒度的一组redo log（只保证forwrd）保证动作-页面的一致性。。这些操作组合起来形成了事务，换句话说，事务中的每个逻辑操作产生了一系列page的变更序列，即一组redo log。
在整体上，数据库中并发事务之间也需要在整体上进行page排序，这一方面依靠FIX Rules保证page间的并发控制，另一方面B+ tree concurrency control protocol也要从数据结构维度维护并发序，加上MV2PL机制，整体上这个page变更序列就确定了。这个全局page的变更序以一个全局的redo log buffer呈现。
第二点，持久化实际上就是把redo log biffer sync到持久化存储（磁盘）中，sync到磁盘的时机我们称之为sync point。一般来讲，sync point同时也是事务commit点，即WAL机制（force log at commit），也就是保证事务的所有日志（redo+undo）sync到磁盘完成后，事务提交才真正完成，这意味着sync point = commit point。
这个sync point也有group commit的体现，每个用户线程在各自事务中的一个逻辑操作通过mini-transaction提交到redo log buffer，然后再在sync point时一起持久化。换句话说，每次sync都会把当前sync point之前的所有redo log都持久化到磁盘，这一组（group）持久化的日志包含了各个事务并发修改的数据。</description>
    </item>
    
    <item>
      <title>storage</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/5_storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/5_storage/</guid>
      <description>存储管理是数据库系统最基本的功能，本章将介绍InnoDB存储引擎中数据在外存中的组织形式（即数据文件）、数据文件在内存中的管理方式以及数据在文件层次的读/写。
存储组织 #  存储管理需要解决以下2个问题：
 如何在存储设备上表示和组织数据库中的数据 如何在内存和外存上控制数据的存取  一般来说，DBMS不直接使用操作系统提供的文件系统作为直接的存储，而是在文件系统之上封装了一层自己对于存储设备的管理，以保证数据的完整性和存取效率。目前大部分的文件系统即使提供了日志的支持，可以保证写的原子性，但是数据库的数据页可能大于文件系统中的block大小，仍然避免不了出现的半写（partial-write）问题，所以数据库也要解决半写问题。
存储层次 #  为了解决以上两个问题，根据分层和抽象的思想，存储的组织和管理可以划分为3个层次：
 文件存储（file storage） 页（page layout） 记录（tuple layout）  暂不讨论raw device，这里假设数据库的文件存放在操作系统提供的文件系统之上。  文件存储负责将文件系统上的一组物理文件进行逻辑组织，按照使用场景（日志、数据、临时数据&amp;hellip;）、以及数据IO特征的不同（日志是append-only的，数据可能是原地写/append-only），将物理文件进行划分，抽象出表空间，并形成统一的数据库层的逻辑文件子系统。
根据局部性原理，为了I/O的高效，我们需要将数据聚簇并划块，这就形成了页，所以第二层可以理解为页的集合，负责按照页为单位从外存、内存读写数据，并分配使用空间。
对于用户来说，操作的是数据，也就是记录的集合，那么在微观上需要对记录进行操作。这也是最后一层，我们在这层实现数据的更改和查询。
所以，存储引擎中内部存储单元（页）和操作系统、以及磁盘上的物理存储单元关系如下图所示：
文件存储 #  文件存储负责将操作系统文件系统上的数据库相关物理文件组织在一起，形成数据库的逻辑文件子系统，整体结构如下图所示：
从上图可以看到，不同的物理文件组成了多个表空间，然后一起形成file system子系统。官方表空间的描述在这里。
InnoDB存储引擎对于文件的管理通过fil_system_t、fil_space_t、fil_node_t进行描述，并定义了四种文件空间（file space）类型：
 FIL_TYPE_TABLESPACE：持久表空间类型，包括系统表空间、独立表空间、undo表空间（innodb_system、user、innodb_undo&amp;lt;000&amp;gt;） FIL_TYPE_LOG：重做日志（ib_logfile&amp;lt;0~100&amp;gt;） FIL_TYPE_TEMPORARY：临时表空间（innodb_temporary） FIL_TYPE_IMPORT：只在导入表空间时使用（导入前为FIL_TYPE_IMPORT，导入完成后为FIL_TYPE_TABLESPACE）  每个文件空间可以包含若干个文件节点（file node）。file node是文件存储的最小单元。逻辑存储模块管理文件系统（file system）下的各个文件空间（file space），并对文件空间下的file node的读/写操作进行管理。
fil_system_t、fil_space_t、fil_node_t的关系如图所示：
在file system中的name：
 在file_space→name为文件名（1）或者文件名统称（n） file_node→name为具体的文件路径+文件名  比如重做日志中的file_space→name和file_node分别为：innodb_redo_log和path/ib_logfile&amp;lt;0 ~ 100&amp;gt;。
表空间 #  首先先让我们从用户和系统管理的角度来了解表空间的使用场景，以便对表空间有一个直观的认识。
使用场景 #  在MySQL 5.7中，表空间按照使用场景分为五种：
 系统表空间 独立表空间 通用表空间 undo表空间 临时表空间  系统表空间 #  系统表空间位于datadir下，存放了InnoDB存储引擎的核心信息，包括数据字典、事务系统信息、double write buffer、change buffer。如果没有配置独立的undo表空间，则undo日志也存放在这里（临时表空间也是如此）。同样，如果没有开启独立表空间（file-per-table），则用户表的数据和索引也存放在这里。因此，系统表空间也被称为共享表空间。</description>
    </item>
    
    <item>
      <title>transaction</title>
      <link>https://ayalastrike.github.io/docs/MySQL/InnoDB/12_transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/InnoDB/12_transaction/</guid>
      <description>1 事务 #  1.1 概述 #  事务是访问数据库中数据的一个程序执行单元。在一个事务中的操作，要么都做，要么不做，这是事务的目的，也是事务模型区别于文件系统的重要特征之一。
从理论上来说，事务有着极其严格的定义，必须同时满足ACID四个特性。但是数据库厂商出于各种目的，并没有严格满足事务的ACID标准。比如对于MySQL的NDB Cluster，没有满足D；对于Oracle，默认的事务隔离级别是Read Committed，不满足I。在InnoDB中，默认的事务隔离级别是Read Repeatable，完全遵循和满足事务的ACID特性。
这里要注意，D保证的是事务系统的高可靠性（High Reliability），而不是高可用性（High Availability）。对于高可用性，事务本身并不能保证，需要一些系统共同配合来完成。
1.2 分类 #  参见Jim Gray
1.3 隔离级别 #  令人惊讶的是，大部分数据库系统都没有提供真正的隔离性，最初或许是因为系统实现者并没有真正理解这些问题。如今这些问题已经弄清楚了，但是数据库的实现者在正确性和性能之间做了妥协。ISO和ANSI SQL标准制定了四种事务隔离级别的标准，但是很少有数据库厂商遵循这些标准，比如Oracle不支持Read Uncommitted和Repeatable Read的事务隔离级别。
SQL标准定义的四个隔离级别为：
 Read Uncommitted Read Committed Repeatable Read Serializable  SQL和SQL2标准的默认事务隔离级别是Serializable。
InnoDB支持的默认事务隔离级别是Repeatable Read，但是和SQL标准不同的是，InnoDB在此隔离级别下，通过使用next-key locking算法，避免了幻读的产生，即可以完全保证事务的隔离性要求，达到了SQL标准的Serializable隔离级别。在append-only storage上，采用snapshot isolation也是避免幻读的一种实现方式。
关于事务可以洋洋洒洒写很多，这里主要聚焦InnoDB中的事务子系统的实现，详细事务的概念和事务控制技术这里略过。
2 事务子系统 #  事务子系统中的数据包括事务信息、undo log、binlog信息以及doublewrite信息。
这些信息由trx_sys page牵头，存储在各自的segment中：
   segment 存储内容 segment header     txn segment 事务信息 trx_sys page   rollback segment undo segment、history链表、undo slots rollback segment page   undo segment undo log undo segment page   doublewrite segment doublewrite数据 trx_sys_page    整体层次如下：</description>
    </item>
    
  </channel>
</rss>
