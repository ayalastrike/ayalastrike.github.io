<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rick&#39;s Blog</title>
    <link>https://ayalastrike.github.io/docs/MySQL/Server/</link>
    <description>Recent content on Rick&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://ayalastrike.github.io/docs/MySQL/Server/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/8.0_net_optimize/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/8.0_net_optimize/</guid>
      <description>（转载自阿里内核月报）
Administrative Connection Management #  如果MySQL连接连接被打满，有时甚至连root也无法登录去kill。
对于这个问题，目前已有的解法有：
 各家的线程池提供了extra_port。 Alibaba RDS MySQL的做法是把connection的个数拆分成不同的使用目的，例如系统维护账户占用一部分，用户账户占用一部分，两者不互相影响。  MySQL 8.0提供了administrative-connection-interface的机制（由facebook贡献），即提供单独的network interface并且可以单独配置一个pthread用于listen。
参数如下：
 admin_address admin_port create_admin_listener_thread：是否创建一个单独的listener线程来监听admin的链接请求（默认OFF，建议打开）  worklog：WL#12138: Add Admin Port
代码
Multiple addresses for the –bind-address #  bind-address支持绑定多个网络地址。比如：
// The server listens on the 198.51.100.20 IPv4 address and the 2001:db8:0:f101::1 IPv6 address. bind_address=198.51.100.20,2001:db8:0:f101::1 worklog：WL#11652: Support multiple addresses for the &amp;ndash;bind-address command option
代码
connect/disconnect performance #  目前MySQL里是使用一个全局大锁（LOCK_thd_list、LOCK_thd_remove）来保护thd_list。
优化的思路其实很简单直接：分区，将LOCK_thd_list、LOCK_thd_remove根据thread id来分成8个分区（hardcode）来减少冲突，负面影响就是PS的监控数据需要聚合。
worklog：WL#9250: Split LOCK_thd_list and LOCK_thd_remove mutexes</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/8.0_resource_group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/8.0_resource_group/</guid>
      <description>（转载自阿里内核月报）
ＭySQL8.0增加了一个新功能resource group，可以对不同的用户进行资源控制，例如对用户线程和后台系统线程给予不同的CPU优先级。
用户可以通过SQL接口创建不同的分组，这些分组可以作为sql的hit，也可以动态的绑定过去。本文主要简单介绍下用法，至于底层如何实现的，其实比较简单：创建的分组被存储到系统表中；在linux系统底层通过CPU_SET来绑定CPU，通过setpriority来设置线程的nice值
worklog: WL#9467: Resource Groups
创建resource group #  系统自带两个resource group（不可修改）：
 FOREGROUND (FG) - &amp;ldquo;user&amp;rdquo; threads BACKGROUND (BG) - &amp;ldquo;system&amp;rdquo; threads (internal Engine threads, e.g. &amp;ldquo;purge&amp;quot;in InnoDB, etc.)  mysql&amp;gt; SELECT * FROM INFORMATION_SCHEMA.RESOURCE_GROUPS\G *************************** 1. row *************************** RESOURCE_GROUP_NAME: USR_default RESOURCE_GROUP_TYPE: USER RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 *************************** 2. row *************************** RESOURCE_GROUP_NAME: SYS_default RESOURCE_GROUP_TYPE: SYSTEM RESOURCE_GROUP_ENABLED: 1 VCPU_IDS: 0-63 THREAD_PRIORITY: 0 2 rows in set (0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/connection_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/connection_handler/</guid>
      <description>概述 #  在MySQL中，对于client发来的请求，其处理流程分为建链和请求处理两部分，这两个阶段分别称为connection phase和command phase。
MySQL的server-client protocol交互如下：
从上图中可以看出，connection phase负责连接的建立，而日常的query处理，则称为command phase，command phase的结束，以COM_QUIT query的到来作为标志。
一般典型的交互过程是connect，query，query，query&amp;hellip; quit，其中query可以是dml、ddl、multi-statement或是prepared statement。
下面我们先看一下connection phase。
建链 #  connection phase用于在client-server间建立连接，而建链分为TCP建链和应用建链。
TCP建链是指TCP socket的listen、accept。
应用建链是在TCP建链的基础上，通过应用层协议进行认证：server发送handshake（initial handshake）、客户端回username/pwd（handshake response），server回应是否通过认证（OK/Error）。
我们接下来首先看一下connection phase，即在MySQL中如何处理TCP建链和应用建链的。
TCP建链 #  TCP连接处理分为两步：
 初始化，创建conn_mgr和conn_handler，acceptor和listener 监听建链，由acceptor+listener负责 对已建链连接进行线程分发处理，由conn_mgr+conn_handler负责  整体流程如下图所示：
代码实现
mysqld_main init_common_variables Connection_handler_manager::init() // 初始化conn_mgr和conn_handler  network_init()	// 初始化网络 	set_ports();	// 设置port  // 初始化acceptor、listener 	Mysqld_socket_listener *mysqld_socket_listener= new (std::nothrow) Mysqld_socket_listener(bind_addr_str, mysqld_port, back_log, mysqld_port_timeout, unix_sock_name); Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt; *mysqld_socket_acceptor= new (std::nothrow) Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt;(mysqld_socket_listener); mysqld_socket_acceptor-&amp;gt;init_connection_acceptor(); .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/invisible_index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/invisible_index/</guid>
      <description>是否使用索引对性能影响很大。在数据库运维过程中，索引的删除总是慎重的，一方面是因为实际的DDL变更代价，一方面是评估对性能的影响。
为了减少删除索引的代价，MySQL 8.0引入了invisible index，用于解决这个问题。
即在索引上增加一个invisible的属性，用于optimizer可以将其忽略掉。
从这里也可以看到，引入的带动在server层，不涉及到存储引擎，所以所有的存储引擎都适用。
MySQL的实现基本参考的是Oracle 12c。
MySQL 8.0.0 Release Notes
 Optimizer Notes  MySQL now supports invisible indexes. An invisible index is not used by the optimizer at all, but is otherwise maintained normally. Indexes are visible by default. Invisible indexes make it possible to test the effect of removing an index on query performance, without making a destructive change that must be undone should the index turn out to be required.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/io_cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/io_cache/</guid>
      <description>设计理念：
 对于碎片化的IO会减少实际文件IO读写 写缓冲：对于写，可以合并IO操作，并在写缓冲满时自动调用write写入文件 读缓冲：对于读，多余读出来的数据可以给下次读使用 对于文件设备支持字符设备和块设备 支持多种IO模式，比如缓冲IO/direct IO/aio 对文件操作进行了抽象：4k对齐（按照块粒度读取IO效率最高），缓冲封装在文件操作内部  IO_CACHE初始化
// 1. seek 如果文件不支持seek，则seek_offset要求为0 // 2. 设置最小对齐块min_cache（16k/8k） // 3. 缩小cachesize：READ_CACHE/SEQ_READ_APPEND下，如果读取范围足够小，则重置cachesize为该范围，并关闭aio // 4. cachesize按照min_cache对齐，如果为SEQ_READ_APPEND，则申请2块，malloc如果失败则缩小3/4重试(128k-&amp;gt;96k)，少于等于min_cache则报错返回  int init_io_cache_ext(IO_CACHE *info, File file, size_t cachesize, enum cache_type type, my_off_t seek_offset, pbool use_async_io, myf cache_myflags, PSI_file_key file_key) { size_t min_cache; my_off_t pos; my_off_t end_of_file= ~(my_off_t) 0; info-&amp;gt;file= file; info-&amp;gt;file_key= file_key; info-&amp;gt;type= TYPE_NOT_SET; // 直到创建append_buffer_lock后才设置type  info-&amp;gt;pos_in_file= seek_offset; info-&amp;gt;pre_close = info-&amp;gt;pre_read = info-&amp;gt;post_read = 0; info-&amp;gt;arg = 0; info-&amp;gt;alloced_buffer = 0; info-&amp;gt;buffer=0; info-&amp;gt;seek_not_done= 0; if (file &amp;gt;= 0) { pos= mysql_file_tell(file, MYF(0)); // 定位文件位置  if ((pos == (my_off_t) -1) &amp;amp;&amp;amp; (my_errno() == ESPIPE)) // 文件不支持seek，再试一次，如果还不行就失败，这种情况下传入的seek_offset要求为0  { info-&amp;gt;seek_not_done= 0; DBUG_ASSERT(seek_offset == 0); } else info-&amp;gt;seek_not_done= MY_TEST(seek_offset !</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/kill_idle_transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/kill_idle_transaction/</guid>
      <description>1. 背景 #  我们在线上遇到5.7.26的锁问题，需要解决idle事务长时间挂起的问题。同时也调研了现有的mysql timeout机制，以确保其和现有的timeout机制可以吻合。
Percona从5.1.59-13.0引入了innodb_kill_idle_transaction，用于解决长事务场景，即对idle事务设定一个超时时间，对超过该时间的事务所在的用户连接进行断开。
引入该参数也可以防止purge线程的长时间阻塞（长事务会一直保持在活跃状态，则会导致purge长时间的等待，从而导致undo无法清理从而造成磁盘空间的不断增加）。
在实现上，开始是通过扫描InnoDB事务列表来进行判断的，在Percona Server 5.6.35-80.0则改为判断connection socket read timeout。这样优化的好处是，巡检可能会造成CPU空跑，而基于socket select超时则发生超时才会触发，使代码的运行更有效率。
另外，percona现在提供了两个参数：innodb_kill_idle_transaction（后者的alias，5.7中已标记为deprecated）和kill_idle_transaction。我们在port时只保留kill_idle_transaction。
2. 设计 #  复用net_wait_timeout：
 处于事务中（SERVER_STATUS_IN_TRANS）&amp;amp; min(kill_idle_transaction, net_wait_timeout) 其他场景还是返回net_wait_timeout  kill_idle_transaction配置项
   配置项 默认值 值范围     kill_idle_transaction 0（不开启） 0 ~ 1 year    3. 示例 #  1. 验证idle事务的连接会自动kill掉 mysql&amp;gt; show global variables like &#39;%idle%&#39;; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | kill_idle_transaction | 10 | +-----------------------+-------+ mysql&amp;gt; begin; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/log/</guid>
      <description>日志 #  MySQL server层日志有：
 general log slow log error log  日志的存储方式（log_output）有：
 文件 表  所有日志的配置参数如下：
log_output general log，slow log存放在何处（文件/表） log_timestamps general log, slow log, error log写入文件中的时间戳所用时区（UTC/SYSTEM），写入日志表中的不在此列。 general_log 是否开启general log sql_log_off 当前session是否关闭general log general_log_file general log文件名 slow_query_log 是否开启slow log slow_query_log_file slow log文件名 long_query_time slow query的判断时间（秒） log_queries_not_using_indexes 是否记录没有使用index的query log_throttle_queries_not_using_indexes log_queries_not_using_indexes配额（每分钟） log_slow_admin_statements 是否记录慢管理语句（ALTER TABLE, ANALYZE TABLE, CHECK TABLE, CREATE INDEX, DROP INDEX, OPTIMIZE TABLE, and REPAIR TABLE） log_error error log文件名 log_error_verbosity error, warning, and note messages log_warnings deprecated，用log_error_verbosity替代 log_syslog log_syslog_facility log_syslog_include_pid log_syslog_tag log-slow-slave-statements 记录从库上回放时的慢SQL（SBR/MIXED） mysqld startup options --log-isam[=file_name] 记录所有MyISAM的变化（debug） --log-raw 记录query rewrite plugin改写前的SQL 日志实现机制 #  general log和slow log #  实现 #  如下图所示：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/lower_case_table_names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/lower_case_table_names/</guid>
      <description>在MySQL中，表是和操作系统中的文件对应的，而文件名在有的操作系统下是区分大小写的（比如linux），有的是不区分大小写（比如Windows），表名与文件名的大小写对应关系，MySQL 是通过lower_case_table_names这个变量来控制的。
这个变量的有效取值是0，1，2，按照官方文档 的解释：
 0：表在文件系统存储的时候，对应的文件名是按建表时指定的大小写存的，MySQL 内部对表名的比较也是区分大小写的 1：表在文件系统存储的时候，对应的文件名都小写的，MySQL 内部对表名的比较是转成小写的，即不区分大小写 2：表在文件系统存储的时候，对应的文件名是按建表时指定的大小写存的，但是 MySQL 内部对表名的比较是转成小写的，即不区分大小写  0适用于区分大小写的系统，1都适用，2适用于不区分大小写的系统。
如果在开始使用MySQL选定了一个合适的值后，就不要改变，不然的话在之后使用中就会出现问题。
MGR用因为要根据db+table+pk生成write_set，还有一个bug fix。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/mariadb_maxscale_proxy_protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/mariadb_maxscale_proxy_protocol/</guid>
      <description>（转载自阿里内核月报）
MariaDB MaxScale 是一款数据库中间件，可以按照语义分发语句到多个数据库服务器上。它对应用程序透明，可以提供读写分离、负载均衡和高可用服务。
proxy protocol 是 MaxScale 引入，为了解决使用proxy作为中间件连接mysql时，mysql获取client ip用 client通过proxy中间价连接mysql时，mysql server接收到认证报文中，包含的是proxy节点的IP。如果mysql.user表中指定了client的IP，无法通过认证。
一种传统处理方式是在proxy节点上保存client的ip和密码，用于client的认证，而在mysql server上使用另一套ip和密码用于proxy 节点到mysql server的认证。
MariaDB MaxScale引入了proxy protocol来解决client ip透传的问题。proxy节点获取到client ip后，把client ip包装在proxy protocol报文中发给server，server解析到了proxy protocol报文，再用报文中的ip替换proxy节点的ip
因为 proxy protocol 本身不包含鉴权，同时可能影响数据库的鉴权行为，所以在数据库 server 端设置了一个ip白名单，只有白名单ip发送的 proxy protocol 报文才会被接受。
报文格式 #  proxy protocol 有两个版本 v1 和 v2 通过报文签名区分
v1 #  v1 报文是字符串形式 “PROXY %s %s %s %d %d”
   字段 内容     签名 PROXY   %s.1 address family   %s.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/mdl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/mdl/</guid>
      <description>历史 #  为了解这个著名的bug#989：
DML和DDL如果并发执行，binlog序错乱：主库并发执行了DDL（T → T&#39;）和DML（T’），但是提交到了binlog中顺序是DDL+DML，这样在从库上回放时，先执行DDL，后执行DML，但此时表结构已经变为T‘，DML执行失败  因此，在MySQL 5.5中，引入了MDL（Meta Data Lock）来控制DDL和DML的并发，保证元数据的一致性。
设计思理：
 WL#3726：DDL locking for all metadata objects WL#4284：Transactional DDL locking  谈到MDL，需要先谈谈MySQL的锁定机制设计以及thr_lock
MySQL locking #  为了保证数据的一致性和完整性，数据库系统普遍存在封锁机制，而封锁机制的优劣直接关系到数据库系统的并发处理能力和性能，所以封锁机制的实现也成为了各种数据库的核心技术之一。
MySQL的封锁机制有三种：
 row-level locking：InnoDB、NDB Cluster table-level locking：MyISAM、MEMORY、MERGE、CSV等非事务存储引擎 page-level locking：BerkeleyDB  MySQL采用如此多样的封锁机制是由其产品定位和发展历史共同决定的。首先，MySQL的产品定位是通过plugin机制可以接入多个存储引擎。在早期的存储引擎（MyISAM和MEMORY）设计中，设计原则建立在&amp;quot;任何表在同一时刻都只允许单个线程（无论读写）对其访问&amp;quot;之上。随后，MySQL3.23修正了之前的假设：MyISAM支持Concurrent Insert：如果没有hole，可以多个读线程并发读同一张表，同时多个写线程以队列的形式进行尾部insert。之后，BerkeleyDB和InnoDB的引入也挑战了之前的设计假设，要求page-level、和row-level locking。此时，之前的设计方式已经和存储引擎所提供的能力不相衬了。因此MySQL做出了改变，允许存储引擎自己改变MySQL 通过接口传入的锁定类型（也就是上面的3种）而自行决定该怎样封锁数据。
MySQL加锁的顺序
SQL → open table → 加MDL锁 → 加表锁 → 加InnoDB锁 → SQL执行 → 释放MDL锁 → 释放表锁 → 释放InnoDB锁
其中表锁是通过thr_lock提供的，在MySQL 5.7.5中，thr_lock被MDL替换：
Scalability for InnoDB tables was improved by avoiding THR_LOCK locks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/memory/</guid>
      <description>在MySQL中，为了高效，Server层也有自己的内存管理。
首先先介绍最简单的单链表内存管理，然后再介绍基于此优化的MEM_ROOT内存管理。
单链表内存管理 #  在server层中，对于字符集处理，使用单链表的内存管理来处理内存资源。
正如Monty在comments中写的：
Wed Jun 21 01:34:04 1989 Monty (monty at monty)
** Added two new malloc-functions: my_once_alloc() and* *my_once_free(). These give easyer and quicker startup.*
 分配内存、释放全部内存由my_once_alloc、my_once_free负责，my_once_strdup和my_once_memdup则是wrapper，内部封装了alloc+memcpy。
alloc策略如下：
 采用单向链表的方式将多个malloc的内存块管理起来 每个内存块采用malloc_chunk + raw的方式，即内存控制块+实际数据使用块两部分 raw部分如果剩余可用，则直接从其中划分，减少malloc开销 如果申请量小且现有的left小于4k，则对齐到4k  从这里可以看出，#3，#4一方面可以减少malloc的系统调用次数和碎片，同时，尽量按照4k对齐申请。
另外，可以通过my_flags设定分配属性：
 MY_FAE /* Fatal if any error */ 内存分配失败就退出整个进程 MY_WME /* Write message on error */ 记录到日志中 MY_ZEROFILL /* Fill array with zero */ 分配内存后初始化为0  相关代码和示例如下：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/net/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/net/</guid>
      <description>MySQL packet的结构如下：
packet length (3 bytes) // 数据
packet number (1 byte) // 保序
compression length (3 bytes) optional // 压缩
compression packet number （1 byte） optional // 保序
packet data
 因为采用3个字节存储包的长度，所以支持的包最大为 MAX_PACKET_LENGTH (256L256L256L-1)。如果数据流超过包最大值（16M），则通过packet number（ne→pkt_nr）保序。
发包 #  my_net_write #  发包，Write a logical packet with packet header.
net_write_buff #  发送缓冲区，Caching the data in a local buffer before sending it.
每个Net对象有一个buffer(net-&amp;gt;buff)，即将发送的数据被拷贝到这个buffer中。如果buffer未满则进行memcpy，并更新写入点位（net-&amp;gt;write_pos）；满了当Buffer满时需要立刻发出到客户端（net_write_packet）。
net_write_packet #  socket写数据，Write a MySQL protocol packet to the network handler.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/protocol/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/protocol/</guid>
      <description>MySQL client-server protocol：https://dev.mysql.com/doc/internals/en/client-server-protocol.html
MySQL 5.7重构了Protocol模块
我们在这里主要聚焦在command phase，即MySQL server和client如何处理query的交互。
我们从MySQL协议可以知道，在query的交互上，一般采用ping-pong模型，即：
 client-&amp;gt;server：发query server-&amp;gt;client：回包  所以我们在下面详细拆解这两个阶段。
读取query #  当client发送一条query后，server对query进行以下处理：
 读包 解析包体 根据命令指派执行  数据报文包括包头+包体，包头已在读包内部验证后丢弃（read_packet），然后包体返回给Protocol_classic::get_command封装为raw_packet。从raw_packet[0]中判断query的命令号，进行报文解析（parse_packet），拆解为COM_DATA（根据命令号封装了不同的struct）。
do_command // conn_handler Protocol_classic::get_command // 读包 Protocol_classic::read_packet my_net_read // 处理多包、压缩包 net_read_packet // 将读到的数据填充到NET中 Protocol_classic::parse_packet // 解析包体 dispatch_command // 根据命令指派执行 回包 #  返回的报文类型有：OK Packet，Error Packet和结果集包（Data Packet，EOF Packet）。
OK Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_ok // 回OK包 Error Packet #  do_command dispatch_command THD::send_statement_status // 根据这条statement执行的情况确定回包类型 Protocol_classic::send_error // 回错误包 结果集包 #  结果集包的结构如下:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/read_only/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/read_only/</guid>
      <description>MySQL通过5个步骤来设置read_only：
 获取global read lock，阻塞所有的写入请求 flush opened table cache，阻塞所有的显式读写锁 获取commit lock，阻塞commit写入binlog 设置read_only=1 释放global read lock和commit lock  设置read_only阻塞用户写入，但只能阻塞普通用户的更新，MySQL为了最大可能的保护数据一致性，增强了read_only功能，通过设置super read only，阻塞除了slave线程以外以为的所有用户的写入，包括super用户。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/returning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/returning/</guid>
      <description>（转载自阿里内核月报）
背景 #  MySQL对于statement执行结果报文通常分为两类：Resultset和OK/ERR，针对 DML语句则返回OK/ERR报文，其中包括几个影响记录，扫描记录等属性。但在很多业务场景下，通常 INSERT/UPDATE/DELETE 这样的DML语句后，都会跟随SELECT查询当前记录内容，以进行接下来的业务处理， 为了减少一次 Client &amp;lt;-&amp;gt; DB Server 交互，类似 PostgreSQL / Oracle 都提供了 returning clause 支持 DML 返回 Resultset。
AliSQL 为了减少对 MySQL 语法兼容性的侵入，并支持 returning 功能， 采用了 native procedure 的方式，使用DBMS_TRANS package，统一使用 returning procedure 来支持 DML 语句返回 Resultset。
语法 #  DBMS_TRANS.returning(Field_list=&amp;gt;, Statement=&amp;gt;); 其中:
 Field list : 代表期望的返回字段，以 “,” 进行分割，支持 * 号表达； Statement ：表示要执行的DML 语句， 支持 INSERT / UPDATE / DELETE；  INSERT Returning #  针对 insert 语句， returning proc 返回插入到表中的记录内容；</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/signal_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/signal_handler/</guid>
      <description>引出问题 #  在之前MySQL发版测试后，QA发现一个问题，用mysql.server stop脚本无法使mysqld进程退出，只会无限等待。
通过查看mysql.server脚本，发现使用stop选项时执行了如下操作：
 检查mysql/var/mysql.pid文件是否存在，若不存在说明mysqld进程未启动；若存在，读出文件中记录的mysqld进程号pid； 发送kill -0 pid，检查是否真的存在进程号为pid的进程。若进程不存在则无需stop，直接删除mysql/var/mysql.pid文件； 若pid进程存在，发送kill pid（即kill -15 pid），随后循环等待直到mysql/var/mysql.pid文件被删除（意味着mysqld已经退出）。  由此逻辑可知，mysql.server stop脚本无限等待大概率是因为第3步发送kill pid后，mysqld并未走退出流程，mysql/var/mysql.pid迟迟不被删所致。通过观察mysql/log/mysql.err文件中的日志，发现执行mysql.server stop后只有这么一条记录：
Got signal 15 from thread 0Got signal 15 from thread 0 说明mysqld进程确实有收到SIGTERM信号，但是并未发起shutdown流程，因此需要了解Linux信号处理机制及MySQL中信号处理逻辑才好判断是哪里出了问题。
Linux信号处理机制 #  在Linux系统中，我们可以通过kill -信号名 进程ID的方式向指定进程发送各种信号。比如常用的kill pid其实等价于kill -15 pid，会向pid进程发送SIGTERM信号；在一个shell前台程序运行中按Ctrl+C，等价于kill -2 pid，会向pid进程发送SIGINT信号；而kill -9 pid则会向pid进程发送SIGKILL信号。
当进程收到信号时如何处理？通常有几种处理方式：
 默认：如果不自定义处理函数，则每个信号都有默认的处理方式。很多信号的默认处理方式都是进程中断+直接退出，极其暴力，这是我们不希望的，因此经常针对某些信号设置自定义处理函数； 捕获：利用signal函数或sigaction函数可以注册用户自定义的信号处理函数（进程级生效）。比如在程序中使用signal(SIGINT, handle_shutdown)，可以注册进程收到SIGINT信号时调用用户自定义函数handle_shutdown，然后用户就可以在此函数中实现一些优雅退出的代码，比如保存工作进度、打印日志等等，不至于退出得过于暴力。需要注意的是，并不是所有信号都允许被捕获并进入自定义处理函数，比如SIGKILL（kill -9）就不允许； 忽略：将某信号的回调函数设置为SIG_IGN(ignore)。进程收到此信号后直接丢弃，不作任何处理。一般涉及网络通信的服务端程序至少都会忽略坑爹信号SIGPIPE（当试图向对方发送数据时发现对方已断连就会触发，默认处理方式是进程退出，极其坑爹……）。需要注意的是，并不是所有信号都允许被忽略，比如SIGKILL（kill -9）就不允许； 屏蔽：通过pthread_sigmask函数可以针对某一线程设置一个信号屏蔽集合，比如选择屏蔽SIGTERM，那么该线程在收到此信号是只是将信号丢入一个pending队列，并不做处理。在此要强调，屏蔽和忽略是有区别的，忽略是直接将信号丢弃，而屏蔽是可以通过pthread_sigmask函数解除的，当解除以后pending队列里的信号就会再次弹出。每个线程可以设置不同的屏蔽规则，但是线程创建时默认继承父线程的屏蔽规则。  在多线程程序中，向进程发送的信号除硬件故障导致的信号外，是可能被随机转发到任何一个线程的。不仅如此，连续发送多个信号，可能在多个子线程中被并发触发，这使得信号处理逻辑变得异常复杂。试想一下，假如我们在进程中对SIGTERM信号注册了优雅退出的处理函数，当用户对进程执行了kill命令，你的线程1捕获到SIGTERM正在优雅退出时，用户等得不耐烦又发了一遍kill命令，此时线程2就有可能捕获到SIGTERM，和线程1并发进行退出，这可能会导致各种非预期行为发生。
因此，**大部分多线程程序常用的信号处理模式是使用单独的信号处理线程，将可能在多个线程中并发出现的信号，转化为只在信号处理线程中排队依次出现，同步处理。**具体实现方式为：对于程序中绝大多数不关注信号的线程，都通过设置信号屏蔽规则在整个线程生命周期中将某些信号屏蔽；建立一个单独的信号处理线程，用一个无限循环调用sigwait函数等待所有关注的信号，阻塞式等待在别的线程“碰壁”后被加入pending队列的信号，每次取出一个信号，进行对应处理，再调用sigwait取下一个信号。这样就将多线程异步信号转为了单线程同步处理，使编写多线程程序的信号处理逻辑变得非常简单。当采用单独的信号处理线程后，不管哪个线程收到SIGTERM，都会在信号处理线程的sigwait函数中返回，这样同时就只可能由信号处理线程执行优雅退出，此时就算向进程发送别的信号，只要信号处理线程不将前一个信号处理完后再次调用sigwait，都是感知不到的。在下文中我们看到，MySQL正是使用了这种单独信号处理线程的模式。
MySQL信号处理逻辑 #  在sql/mysqld.cc的主入口函数mysqld_main中靠前的位置，我们可以找到设置MySQL信号处理规则的函数my_init_signals：
// sql/mysqld.cc mysqld_main() if (init_common_variables()) unireg_abort(MYSQLD_ABORT_EXIT); // Will do exit  my_init_signals(); 在my_init_signals函数中首先设置了进程级的信号处理规则：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/startup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/startup/</guid>
      <description>MySQL启动过程
main() // 入口 sql/main.cc mysqld_main() // sql/mysqld.cc // 记录入参 my_progname = argv[0]; orig_argc = argc; orig_argv = argv; // 处理配置文件my.cnf及启动参数 load_defaults(MYSQL_CONFIG_NAME, load_default_groups, &amp;amp;argc, &amp;amp;argv, &amp;amp;argv_alloc); // 继续处理启动参数，为初始化系统表做准备 sys_var::m_parse_flag == PARSE_EARLY handle_early_options(); // 为status统计计数做准备 init_sql_statement_names(); // 初始化system variables哈希表,链表sys_var_chain sys_var,遍历链表后,加入到system_variable_hash哈希表 // sys_var_chain链表已经通过sys_vars.cc的sys_var()构造函数static初始化 sys_var_init(); // 计算打开文件数并初始化table cache adjust_related_options(&amp;amp;requested_open_files); // init error log global variables init_error_log(); // init audit global variables mysql_audit_initialize(); // 初始化query log和slow log query_logger.init(); // 初始化system variables init_common_variables(); default_storage_engine= const_cast&amp;lt;char *&amp;gt;(&amp;quot;InnoDB&amp;quot;); // 设置默认storage engine add_status_vars(status_vars); // 初始化status变量(show status), status_vars为全局变量 set_server_version(); get_options(&amp;amp;remaining_argc, &amp;amp;remaining_argv); // sys_var::m_parse_flag == PARSE_NORMAL // 设置thread_cache_size init_client_errs(); // 读出给client返回出错信息的文件 lex_init(); // 初始化词法分析 item_create_init(); // 初始化函数列表 func_array为全局变量 // 设置默认字符集和校验字符集 global_system_variables.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/thd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/thd/</guid>
      <description>THD对象 #  THD封装了线程相关的数据，可以视作一个处理单元。
The size of the THD is ~10K and its definition is found in sql_class.h.
The THD is a large data structure which is used to keep track of various aspects of execution state. Memory rooted in the THD will grow significantly during query execution, but exactly how much it grows will depend upon the query. For memory planning purposes we recommend to plan for ~10MB per connection on average.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/ThreadPool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/ThreadPool/</guid>
      <description>背景 #  高并发场景 #  在高并发场景（访问共享资源）下，随着用户（并发）的增加，有以下两个挑战：
  latency在后期成指数型增长  吞吐下降严重
  造成这种现象的根本原因是通信、处理和同步成本大幅升高，最终达到处理极限，导致数据库的服务能力大幅下降，甚至无法响应请求。
为了处理这种情况，有两种思路：
  在系统达到预设性能指标时，采用管制措施保护数据库，使之可以持续提供稳定的服务。 这种方式称之为限流（aka “on-ramp metering”），由交通信号灯来控制多少车辆可以在峰值时通过。如下图所示：
  另一种方式是线程池机制，减少内部的线程上下文切换开销、热点资源的竞争，提升CPU上有效代码的执行效率，同时也具备控制流量的能力。
  我们最终期望实现的效果是：技术选型 #  MySQL的处理模型 #  现有的MySQL的请求处理架构采用的是单进程多线程方案，每个用户连接对应一个MySQL处理线程（后面称为工作线程），在这种情况下，随着用户连接数的增多，MySQL进程会创建大量的工作线程，系统性能在高并发场景下会有大幅的下降。
而导致性能下降主要是这三个原因造成的：
 CPU cache miss 线程的上下文切换 热点共享资源的竞争（latch、锁&amp;hellip;）  采用线程池，则可以有针对性的对上述三点进行优化：将MySQL的工作线程和用户连接解绑，同一个工作线程应对多个用户连接上的请求：当前的用户请求处理完成后，工作线程再选择其他的用户请求进行处理。保证合理数量的工作线程提供可持续的处理能力，并且CPU cache的使用更高效，可以有效的降低线程的上下文切换代价，同时热点资源竞争的开销也随之降低，也降低了死锁发生的概率。
线程池机制更加适用于OLTP场景（short CPU-bound queries），对于OLAP场景可能会产生护航（convey）问题。
从某种程度上来看，线程池分离了连接资源（请求）和线程资源（处理）。
不适用场景 #  线程池并不是万能的，对于以下几类场景并不适用：
 间歇性的workload：这会导致不断的分配/回收线程资源。 OLTP大查询：大量并发、长时间的复杂查询，如果占满了所有处理线程，后续的请求会进行排队，造成latency的增加。 大量的消耗极小的简单查询：比如select 1，大量瞬间涌入的请求，如果进行排队可能也会造成latency的增加。 极高并发的prepared statement：prepared statement所使用的MySQL Binary Protocol会使交互往返多次，可能会造成请求的堆积。  效果 #  线程池的性能对比，这里参考官方给出的性能数据：
60x Better Scalability: Read/Write (8192/128)</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/timeout/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/timeout/</guid>
      <description>背景 #  在分布式环境下，异步网络是一个挑战，当遇到网络问题时，提供超时机制可以提升系统的可用性。并且，对于事务系统，锁机制也需要超时机制来保证资源可以在有限时间内释放，避免饥饿现象的产生。
为此，MySQL在多种场景下提供了timeout机制。
简单一句话，MySQL Protocol ping-pong模型各个节点都有超时检测  MySQL timeout配置 #  MySQL内有多种timeout，我们先看一下有多少：
mysql&amp;gt; show global variables like &#39;%timeout%&#39;; +-----------------------------+----------+ | Variable_name | Value | +-----------------------------+----------+ | connect_timeout | 5 | | net_read_timeout | 30 | | net_write_timeout | 60 | | wait_timeout | 28800 | | interactive_timeout | 28800 | | lock_wait_timeout | 31536000 | | innodb_lock_wait_timeout | 3 | | innodb_rollback_on_timeout | OFF | +-----------------------------+----------+ 通过阅读官方文档，结合我们在下面对于timeout实现的论证，这里先放上结论：
网络超时</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/user_connection_handler/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/user_connection_handler/</guid>
      <description>（转载自阿里内核月报）
建立连接过程 #  MySQL建立连接过程如下
// 初始化网络 network_init() set_ports(); // 设置port  Mysqld_socket_listener *mysqld_socket_listener= new (std::nothrow) Mysqld_socket_listener(bind_addr_str, mysqld_port, back_log, mysqld_port_timeout, unix_sock_name); Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt; *mysqld_socket_acceptor= new (std::nothrow) Connection_acceptor&amp;lt;Mysqld_socket_listener&amp;gt;(mysqld_socket_listener); mysqld_socket_acceptor-&amp;gt;init_connection_acceptor(); ... // 监听socket事件 mysqld_socket_acceptor-&amp;gt;connection_event_loop() { Connection_handler_manager *mgr= Connection_handler_manager::get_instance(); while (!abort_loop) { Channel_info *channel_info= m_listener-&amp;gt;listen_for_connection_event(); if (channel_info != NULL) mgr-&amp;gt;process_new_connection(channel_info); } } Channel_info* Mysqld_socket_listener::listen_for_connection_event() { int retval= poll(&amp;amp;m_poll_info.m_fds[0], m_socket_map.size(), -1); // POLL  for (uint i= 0; i &amp;lt; m_socket_map.size(); ++i) { if (m_poll_info.m_fds[i].revents &amp;amp; POLLIN) { listen_sock= m_poll_info.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://ayalastrike.github.io/docs/MySQL/Server/vio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ayalastrike.github.io/docs/MySQL/Server/vio/</guid>
      <description>VIO模块 #  为不同的protocol提供network I/O wrapper，类似于winsock。
Virtual I/O Library.
The VIO routines are wrappers for the various network I/O calls that happen with different protocols. The idea is that in the main modules one won&amp;rsquo;t have to write separate bits of code for each protocol. Thus vio&amp;rsquo;s purpose is somewhat like the purpose of Microsoft&amp;rsquo;s winsock library. https://dev.mysql.com/doc/internals/en/vio-directory.html
 SOCKET封装了socket fd，里面只有fd信息。
目前支持的protocol：
 TCP/IP Unix domain socket Named Pipes（Windows only） Shared Memory（Windows only） Secure Sockets（SSL）  Unix domain socket</description>
    </item>
    
  </channel>
</rss>
